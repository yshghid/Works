{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10 Class\n",
    "classes = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    CIFAR-10 데이터셋을 로드하여 훈련 및 테스트 데이터로더를 반환하는 함수\n",
    "    :param batch_size: 배치 크기\n",
    "    :return: train_loader, test_loader\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    train_set = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=True, download=False, transform=transform\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    test_set = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=False, download=False, transform=transform\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_set, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN Architecture 정의 클래스\n",
    "    CIFAR-10 분류를 위해 설계된 합성곱 신경망\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            3, 32, kernel_size=3, padding=1\n",
    "        )  # CONV, 입력 채널 3(RGB), 출력 채널 32\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # Pooling, 2x2 필터, 스트라이드 2\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            32, 64, kernel_size=3, padding=1\n",
    "        )  # CONV, 입력 채널 32, 출력 채널 64\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)  # FC, 입력 64x8x8 -> 128 뉴런\n",
    "        self.fc2 = nn.Linear(128, 10)  # FC, 입력 128 -> 출력 10(클래스 개수)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward 정의\n",
    "        :param x: 입력 이미지 텐서\n",
    "        :return: 각 클래스에 대한 점수(logit)\n",
    "        \"\"\"\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)  # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, train_loader, device, criterion, optimizer, num_epochs=NUM_EPOCHS\n",
    "):\n",
    "    \"\"\"\n",
    "    모델을 주어진 데이터로 학습시키는 함수\n",
    "    :param model: 학습할 CNN 모델\n",
    "    :param train_loader: 훈련 데이터 로더\n",
    "    :param device: 사용 디바이스 (CPU/GPU)\n",
    "    :param criterion: 손실 함수\n",
    "    :param optimizer: 최적화 알고리즘\n",
    "    :param num_epochs: 학습 반복 횟수\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    모델을 테스트 데이터로 평가하여 정확도를 출력하는 함수\n",
    "    :param model: 평가할 CNN 모델\n",
    "    :param testloader: 테스트 데이터 로더\n",
    "    :param device: 사용 디바이스 (CPU/GPU)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    전체 실행 흐름을 제어하는 메인 함수\n",
    "    데이터 로딩 -> 모델 정의 -> 학습 -> 평가 순으로 진행\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    train_loader, test_loader = get_dataloaders()\n",
    "    model = CNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_model(model, train_loader, device, criterion, optimizer)\n",
    "    evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2793\n",
      "Epoch 2, Loss: 0.9013\n",
      "Epoch 3, Loss: 0.7395\n",
      "Epoch 4, Loss: 0.6207\n",
      "Epoch 5, Loss: 0.5070\n",
      "Epoch 6, Loss: 0.4143\n",
      "Epoch 7, Loss: 0.3312\n",
      "Epoch 8, Loss: 0.2575\n",
      "Epoch 9, Loss: 0.2045\n",
      "Epoch 10, Loss: 0.1643\n",
      "Test Accuracy: 70.56%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
