{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY Loading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH21-LangGraph\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH21-LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Agent 개발 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 정의 \n",
    "tool = TavilySearch(max_results=5)\n",
    "\n",
    "# 도구 목록 반영\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial', 'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?', 'content': 'LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. LangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.', 'score': 0.91137725, 'raw_content': '# LangGraph Tutorial: What Is LangGraph and How to Use It?\\n\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\n\\nJun 26, 2024 \\xa0· 12 min read\\n\\nImagine you\\'re building a complex, multi-agent large language model (LLM) application. It\\'s exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\n\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\\n\\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems.\\n\\nIf you want to learn more about the LangChain ecosystem, I recommend this [introduction to LangChain](https://www.datacamp.com/tutorial/introduction-to-langchain-for-data-engineering-and-data-applications). You can also check out our [LangGraph video tutorial](https://www.youtube.com/watch?v=UklCxmEvz2w) below.\\n\\n## What Is LangGraph?\\n\\nLangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\\n\\n### Graph structure\\n\\nImagine your application as a directed graph. In LangGraph, each node represents an LLM agent, and the edges are the communication channels between these agents. This structure allows for clear and manageable workflows, where each agent performs specific tasks and passes information to other agents as needed.\\n\\n### State management\\n\\nOne of LangGraph\\'s standout features is its automatic state management. This feature enables us to track and persist information across multiple interactions. As agents perform their tasks, the state is dynamically updated, ensuring the system maintains context and responds appropriately to new inputs.\\n\\n### Coordination\\n\\nLangGraph ensures agents execute in the correct order and that necessary information is exchanged seamlessly. This coordination is vital for complex applications where multiple agents need to work together to achieve a common goal. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination.\\n\\n## Why LangGraph?\\n\\nAs I mentioned above, LangGraph offers several significant advantages for developers working with complex LLM applications. Here are some of the real-world benefits LangGraph offers.\\n\\n### Simplified development\\n\\nLangGraph abstracts away the complexities associated with state management and agent coordination. This means developers can define their workflows and logic without worrying about the underlying mechanisms that ensure data consistency and proper execution order. This simplification accelerates the development process and reduces the likelihood of errors. It’s a game-changer!\\n\\n### Flexibility\\n\\nWith LangGraph, developers have the flexibility to define their own agent logic and communication protocols. This allows for highly customized applications tailored to specific use cases. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. It’s all about giving you the power to create.\\n\\n### Scalability\\n\\nLangGraph is built to support the execution of large-scale multi-agent applications. Its robust architecture can handle a high volume of interactions and complex workflows, enabling the development of scalable systems that can grow with your needs. This makes it suitable for enterprise-level applications and scenarios where performance and reliability are critical.\\n\\n### Fault tolerance\\n\\nReliability is a core consideration in the design of LangGraph. The library includes mechanisms for gracefully handling errors, ensuring that your application can continue to operate even when individual agents encounter issues. This fault tolerance is essential for maintaining the stability and robustness of complex multi-agent systems. Peace of mind is just a feature away.\\n\\n## Getting Started With LangGraph\\n\\nLet’s see how we can set up LangGraph and what the basic concepts are.\\n\\n### Installation\\n\\nTo install LangGraph, you can use `pip`:\\n\\n```\\npip install -U langgraph\\n```\\n\\n### Basic Concepts\\n\\nNodes: Nodes represent units of work within your LangGraph. They are typically Python functions that perform a specific task, such as:\\n\\n* Interacting with an LLM\\n* Calling a tool or API\\n* Performing some data manipulation\\n* Receiving user input\\n* Executing business logic\\n\\nIn LangGraph, you can add nodes using the `graph.add_node(name, value)` syntax.\\n\\nEdges: Edges are communication channels between nodes. They define the flow of information and the order of execution. You can add edges using the `graph.add_edge(node1, node2)` syntax.\\n\\nState: The state is a central object updated over time by the nodes in the graph. It manages the internal state of your application and can be overridden or added to, depending on the application\\'s requirements. This state can hold things such as:\\n\\n* Conversation history: A list of messages between the agent and the user.\\n* Contextual data: Information relevant to the current task or interaction.\\n* Internal variables: Flags, counters, or other variables to track the agent\\'s progress and behavior.\\n\\n## Building a Simple LangGraph Application\\n\\nHere’s a step-by-step example of creating a basic chatbot application using LangGraph.\\n\\n### Step 1: Define the StateGraph\\n\\nDefine a `StateGraph` object to structure the chatbot as a state machine. The `State` is a class object defined with a single key `messages` of type `List` and uses the `add_messages()` function to append new messages rather than overwrite them.\\n\\n```\\nfrom typing import Annotated from typing_extensions import TypedDict from langgraph.graph import StateGraph from langgraph.graph.message import add_messages class State(TypedDict): # messages have the type \"list\". # The add_messages function appends messages to the list, rather than overwriting them messages: Annotated[list, add_messages] graph_builder = StateGraph(State)\\n```\\n\\n### Step 2: Initialize an LLM and add it as a Chatbot node\\n\\nHere, we initialize the AzureChatOpenAI model and create a simple chatbot function that takes in the state messages as input and generates a message response (which is subsequently appended to the state).\\n\\nThis chatbot function is added as a node named “chatbot” to the graph.\\n\\n```\\nfrom langchain_openai import AzureChatOpenAI llm = AzureChatOpenAI( openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"], azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"], ) def chatbot(state: State): return {\"messages\": [llm.invoke(state[\"messages\"])]} ‘’’The first argument is the unique node name # The second argument is the function or object that will be called whenever the node is used.’’’ graph_builder.add_node(\"chatbot\", chatbot)\\n```\\n\\n### Step 3: Set edges\\n\\nSince we are building a simple chatbot, we set the `chatbot` node as both the entry and finish points of the graph to indicate where to start and end the process.\\n\\n```\\n# Set entry and finish points graph_builder.set_entry_point(\"chatbot\") graph_builder.set_finish_point(\"chatbot\")\\n```\\n\\nStep 4: Compile and Visualize the Graph\\n\\nCompile the graph to create a CompiledGraph object, and optionally, we can visualize the graph structure using the code below:\\n\\n```\\ngraph = graph_builder.compile() from IPython.display import Image, display try: display(Image(graph.get_graph().draw_mermaid_png())) except Exception: pass\\n```\\n\\n### Step 5: Run the chatbot\\n\\nFinally, we implement a loop to continuously prompt the user for input, process it through the graph, and print the assistant\\'s response. The loop exits when the user types `\"quit\"`, `\"exit\"`, or `\"q\"`.\\n\\n```\\n# Run the chatbot while True: user_input = input(\"User: \") if user_input.lower() in [\"quit\", \"exit\", \"q\"]: print(\"Goodbye!\") break for event in graph.stream({\"messages\": [(\"user\", user_input)]}): for value in event.values(): print(\"Assistant:\", value[\"messages\"][-1].content)\\n```\\n\\n## Advanced LangGraph Features\\n\\nNow that we\\'ve covered the basics, let’s take a look at some advanced features.\\n\\n### Custom node types\\n\\nLangGraph allows you to create custom node types to implement complex agent logic. This provides flexibility and control over your application\\'s behavior.\\n\\n```\\nfrom typing import Annotated from langchain_anthropic import ChatAnthropic from langgraph.graph import StateGraph from langgraph.graph.message import add_messages class MyCustomNode: def __init__(self, llm): self.llm = llm def __call__(self, state): # Implement your custom logic here # Access the state and perform actions messages = state[\"messages\"] response = self.llm.invoke(messages) return {\"messages\": [response]} graph_builder = StateGraph(State) llm = ChatAnthropic(model=\"claude-3-haiku-20240307\") custom_node = MyCustomNode(llm) graph_builder.add_node(\"custom_node\", custom_node)\\n```\\n\\nHere, we define a class `MyCustomNode` that encapsulates custom logic and interacts with the LLM. This provides a more structured and maintainable way to implement complex node behaviors.\\n\\n### Edge types\\n\\nLangGraph supports different edge types to handle various communication patterns between nodes. One useful type is the conditional edge, which allows for decision-making based on a node\\'s output.\\n\\nTo create a conditional edge, you need three components:\\n\\n1. The upstream node: The node\\'s output decides the next step.\\n2. A function: This function evaluates the upstream node\\'s output and determines the next node to execute, returning a string that represents the decision.\\n3. A mapping: This mapping links the possible outcomes of the function to the corresponding nodes to be executed.\\n\\nHere\\'s an example in pseudocode:\\n\\n```\\ngraph.add_conditional_edge( \"model\", should_continue, { \"end\": END, \"continue\": \"tools\" } )\\n```\\n\\nHere, after the “model” node is called, we can either exit the graph (”end”) and return to the user, or we can continue (”continue”) and call a tool—depending on what the user decides!\\n\\n### State management\\n\\nLangGraph offers powerful state management techniques, which include using external databases like SQLite, PostgreSQL, and MongoDB, or cloud storage solutions like Amazon S3, Google Cloud Storage, and Azure Blob Storage to store and retrieve your agent\\'s state, enabling reliability and scalability.\\n\\nHere\\'s an example of using a SQLite database for state management:\\n\\n```\\nfrom langgraph.checkpoint.sqlite import SqliteSaver # Connect to the SQLite database memory = SqliteSaver.from_conn_string(\":memory:\") # Compile the graph with the checkpointer graph = graph_builder.compile(checkpointer=memory)\\n```\\n\\n### Error handling\\n\\nLangGraph also provides mechanisms for error handling:\\n\\n* Exceptions: Node functions can raise exceptions to signal errors during execution. You can catch and handle these exceptions to prevent your graph from crashing.\\n* Retry mechanisms: You can implement retry logic within your nodes to handle transient errors, such as network issues or API timeouts.\\n* Logging: Use logging to record errors and track the execution of your graph.\\n\\n## Real-World Applications of LangGraph\\n\\nLangGraph can be used to build a wide range of applications.\\n\\n### Chatbots\\n\\nLangGraph is ideal for developing sophisticated chatbots that can handle a wide array of user requests. By leveraging multiple LLM agents, these chatbots can process natural language queries, provide accurate responses, and seamlessly switch between different conversation topics. The ability to manage state and coordinate interactions ensures that the chatbot maintains context and delivers a coherent user experience.\\n\\n### Autonomous agents\\n\\nFor applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\n\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph\\'s structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\\n\\n### Multi-Agent systems\\n\\nLangGraph excels in building applications where multiple agents collaborate to achieve a common goal. For example, different agents can manage inventory, process orders, and coordinate deliveries in a supply chain management system. LangGraph\\'s coordination capabilities ensure that each agent communicates effectively, sharing information and making decisions in a synchronized manner. This leads to more efficient operations and better overall system performance.\\n\\n### Workflow automation tools\\n\\nWith LangGraph, automating business processes and workflows becomes straightforward. Intelligent agents can be designed to handle tasks such as document processing, approval workflows, and data analysis. By defining clear workflows and leveraging LangGraph\\'s state management, these tools can execute complex sequences of actions without human intervention, reducing errors and increasing productivity.\\n\\n### Recommendation systems\\n\\nPersonalized recommendation systems can greatly benefit from LangGraph\\'s capabilities. By employing multiple agents to analyze user behavior, preferences, and contextual data, these systems can deliver tailored suggestions for products, content, or services. LangGraph\\'s flexibility allows for integrating various data sources and algorithms, enhancing the accuracy and relevance of recommendations.\\n\\n### Personalized learning environments\\n\\nIn educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student\\'s progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner\\'s performance and preferences, enabling a more personalized and effective educational experience.\\n\\n## Conclusion\\n\\nLangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\\n\\nPotential developments for LangGraph include integration with other LangChain components, support for new LLM models, and the introduction of more advanced agent runtimes from academia.\\n\\nIf you want to learn more about developing applications within the LangChain ecosystem, I recommend this course on [developing LLM applications with LangChain](https://www.datacamp.com/courses/developing-llm-applications-with-langchain).\\n\\n## Multi-Agent Systems with LangGraph\\n\\nBuild powerful multi-agent systems by applying emerging agentic design patterns in the LangGraph framework.\\n\\n[Explore Course](https://www.datacamp.com/courses/multi-agent-systems-with-langgraph)\\n\\nAuthor\\n\\nRyan Ong\\n\\nRyan is a lead data scientist specialising in building AI applications using LLMs. He is a PhD candidate in Natural Language Processing and Knowledge Graphs at Imperial College London, where he also completed his Master’s degree in Computer Science. Outside of data science, he writes a weekly Substack newsletter,\\xa0[The Limitless Playbook](https://ryanocm.substack.com/), where he shares one actionable idea from the world\\'s top thinkers and occasionally writes about core AI concepts.\\n\\nTopics\\n\\n[Artificial Intelligence](/tutorial/category/ai)[AI Agents](/tutorial/category/ai-agents)\\n\\nLearn AI with these courses!\\n\\nCourse\\n\\n### [Developing LLM Applications with LangChain](/courses/developing-llm-applications-with-langchain)\\n\\n3 hr\\n\\n29.8K\\n\\nDiscover how to build AI-powered applications using LLMs, prompts, chains, and agents in LangChain.\\n\\n[See Details](/courses/developing-llm-applications-with-langchain)[Start Course](/users/sign_up?redirect=%2Fcourses%2Fdeveloping-llm-applications-with-langchain%2Fcontinue)\\n\\nCourse\\n\\n### [Building AI Agents with Google ADK](/courses/building-ai-agents-with-google-adk)\\n\\n1 hr\\n\\n2.2K\\n\\nBuild a customer-support assistant step-by-step with Google’s Agent Development Kit (ADK).\\n\\n[See Details](/courses/building-ai-agents-with-google-adk)[Start Course](/users/sign_up?redirect=%2Fcourses%2Fbuilding-ai-agents-with-google-adk%2Fcontinue)\\n\\nCourse\\n\\n### [Multi-Agent Systems with LangGraph](/courses/multi-agent-systems-with-langgraph)\\n\\n2 hr 45 min\\n\\n1.6K\\n\\nBuild powerful multi-agent systems by applying emerging agentic design patterns in the LangGraph framework.\\n\\n[See Details](/courses/multi-agent-systems-with-langgraph)[Start Course](/users/sign_up?redirect=%2Fcourses%2Fmulti-agent-systems-with-langgraph%2Fcontinue)\\n\\n[See More](/courses-all)\\n\\nRelated\\n\\n[Tutorial\\n\\n### LangGraph Studio Guide: Installation, Set Up, Use Cases](/tutorial/langgraph-studio)\\n\\nLangGraph Studio is a visual development environment for LangChain’s LangGraph framework, simplifying the development of complex agentic applications built with LangChain components.\\n\\nDr Ana Rojo-Echeburúa\\n\\n[Tutorial\\n\\n### Introduction to LangChain for Data Engineering & Data Applications](/tutorial/introduction-to-langchain-for-data-engineering-and-data-applications)\\n\\nLangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you can do with LangChain, including the problems that LangChain solves and examples of data use cases.\\n\\nRichie Cotton\\n\\n[Tutorial\\n\\n### How to Build LLM Applications with LangChain Tutorial](/tutorial/how-to-build-llm-applications-with-langchain)\\n\\nExplore the untapped potential of Large Language Models with LangChain, an open-source Python framework for building advanced AI applications.\\n\\nMoez Ali\\n\\n[Tutorial\\n\\n### Building Context-Aware Chatbots: Leveraging LangChain Framework for ChatGPT](/tutorial/building-context-aware-chatbots-leveraging-langchain-framework-for-chatgpt)\\n\\nExplore how to build context-aware chatbots using the ChatGPT and LangChain framework.\\n\\nAndrea Valenzuela\\n\\n[Tutorial\\n\\n### Building LangChain Agents to Automate Tasks in Python](/tutorial/building-langchain-agents-to-automate-tasks-in-python)\\n\\nA comprehensive tutorial on building multi-tool LangChain agents to automate tasks in Python using LLMs and chat models using OpenAI.\\n\\nBex Tuychiev\\n\\n[code-along\\n\\n### Building AI Applications with LangChain and GPT](/code-along/building-ai-applications-with-langchain-and-gpt)\\n\\nIn the live training, you\\'ll use LangChain to build a simple AI application, including preparing and indexing data, prompting the AI, and generating responses.\\n\\nEmmanuel Pire\\n\\n[See More](/tutorial/category/ai)[See More](/tutorial/category/ai)'}, {'url': 'https://langchain-ai.github.io/langgraph/concepts/why-langgraph/', 'title': 'Learn LangGraph basics - Overview', 'content': \"* Learn LangGraph basics LangGraph is built for developers who want to build powerful, adaptable AI agents. * **Reliability and controllability.** Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course. * **First-class streaming support.** With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time. To get acquainted with LangGraph's key concepts and features, complete the following LangGraph basics tutorials series: 4. Add human-in-the-loop controls In completing this series of tutorials, you will build a support chatbot in LangGraph that can: * ✅ **Maintain conversation state** across calls * ✅ **Use custom state** to control its behavior\", 'score': 0.82288796, 'raw_content': '[Skip to content](#overview)\\n\\n\\n\\n* [Learn LangGraph basics](#learn-langgraph-basics)\\n\\n# Overview[¶](#overview \"Permanent link\")\\n\\nLangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for:\\n\\n* **Reliability and controllability.** Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course.\\n* **Low-level and extensible.** Build custom agents with fully descriptive, low-level primitives free from rigid abstractions that limit customization. Design scalable multi-agent systems, with each agent serving a specific role tailored to your use case.\\n* **First-class streaming support.** With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time.\\n\\n## Learn LangGraph basics[¶](#learn-langgraph-basics \"Permanent link\")\\n\\nTo get acquainted with LangGraph\\'s key concepts and features, complete the following LangGraph basics tutorials series:\\n\\n1. [Build a basic chatbot](../../tutorials/get-started/1-build-basic-chatbot/)\\n2. [Add tools](../../tutorials/get-started/2-add-tools/)\\n3. [Add memory](../../tutorials/get-started/3-add-memory/)\\n4. [Add human-in-the-loop controls](../../tutorials/get-started/4-human-in-the-loop/)\\n5. [Customize state](../../tutorials/get-started/5-customize-state/)\\n6. [Time travel](../../tutorials/get-started/6-time-travel/)\\n\\nIn completing this series of tutorials, you will build a support chatbot in LangGraph that can:\\n\\n* ✅ **Answer common questions** by searching the web\\n* ✅ **Maintain conversation state** across calls\\n* ✅ **Route complex queries** to a human for review\\n* ✅ **Use custom state** to control its behavior\\n* ✅ **Rewind and explore** alternative conversation paths\\n\\n '}, {'url': 'https://blog.futuresmart.ai/langgraph-tutorial-for-beginners', 'title': 'LangGraph Tutorial: A Comprehensive Guide for Beginners', 'content': 'By representing workflows as cyclical graphs, LangGraph allows developers to orchestrate the interactions of multiple LLM agents, ensuring smooth communication and efficient execution of complex tasks. You can expand upon this by incorporating more sophisticated state management and different LLM models or by connecting to external tools and APIs. The key is to define clear nodes for different tasks and use edges to establish the desired flow of information and control within the chatbot. 6. **Loop Back:** After executing the tool, use `graph_builder.add_edge()` to direct the flow back to the `chatbot` node, allowing the conversation to continue. **LangGraph lets you build AI systems that are more complex and interactive than simple question-and-answer bots** by managing state, coordinating multiple agents, and allowing for human feedback.', 'score': 0.8016413, 'raw_content': '[FutureSmart AI Blog](/?source=top_nav_blog_home)\\n\\n[FutureSmart AI Blog](/?source=top_nav_blog_home)\\n\\nFollow\\n\\n# LangGraph Tutorial: A Comprehensive Guide for Beginners\\n\\n··\\n\\n12 min read\\n\\n## Table of contents\\n\\n* [Understanding LangGraph](#heading-understanding-langgraph)\\n* [Key Concepts](#heading-key-concepts)\\n  + [Graph Structures](#heading-graph-structures)\\n  + [State Management](#heading-state-management)\\n* [Getting Started with LangGraph](#heading-getting-started-with-langgraph)\\n  + [Installation](#heading-installation)\\n  + [Creating a Basic Chatbot in LangGraph](#heading-creating-a-basic-chatbot-in-langgraph)\\n* [Advanced LangGraph Techniques](#heading-advanced-langgraph-techniques)\\n  + [Tool Integration](#heading-tool-integration)\\n  + [Adding Memory to the Chatbot](#heading-adding-memory-to-the-chatbot)\\n  + [Human in the Loop](#heading-human-in-the-loop)\\n* [Real-World Uses for LangGraph](#heading-real-world-uses-for-langgraph)\\n* [Conclusion](#heading-conclusion)\\n\\n## Introduction\\n\\nBuilding applications with large language models (LLMs) offers exciting opportunities to create sophisticated, interactive systems. But as these applications grow in complexity, especially those involving multiple LLMs working in concert, new challenges arise. How do we manage the flow of information between these agents? How do we ensure they interact seamlessly and maintain a consistent understanding of the task at hand? This is where **LangGraph** comes in.\\n\\n## Understanding LangGraph\\n\\n[LangGraph](https://www.langchain.com/langgraph), a powerful library within the LangChain ecosystem, provides an elegant solution for building and managing multi-agent LLM applications. By representing workflows as cyclical graphs, LangGraph allows developers to orchestrate the interactions of multiple LLM agents, ensuring smooth communication and efficient execution of complex tasks.\\n\\nWhile LangChain excels in creating linear chains of computational tasks (known as Directed Acyclic Graphs or DAGs), LangGraph introduces the ability to incorporate cycles into these workflows. This innovation enables developers to construct more intricate and adaptable systems, mirroring the dynamic nature of intelligent agents that can revisit tasks and make decisions based on evolving information.\\n\\nIf you want to build projects in LangChain, then I would recommend watching this YouTube Video: [Mastering NL2SQL with LangChain and LangSmith](https://www.youtube.com/watch?v=fss6CrmQU2Y)\\n\\n## Key Concepts\\n\\n### Graph Structures\\n\\nAt the heart of LangGraph\\'s design lies a graph-based representation of the application\\'s workflow. This graph comprises two primary elements:\\n\\n* **Nodes - The Building Blocks of Work:** Each node in a LangGraph represents a distinct unit of work or action within the application. These nodes are essentially Python functions that encapsulate a specific task. This task could involve a diverse range of operations, such as:\\n\\n  + Direct communication with an LLM for text generation, summarization, or other language-based tasks.\\n  + Interacting with external tools and APIs to fetch data or perform actions in the real world.\\n  + Manipulating data through processes like formatting, filtering, or transformation.\\n  + Engaging with users to gather input or display information.\\n* **Edges - Guiding the Flow of Information and Control:** Edges serve as the connective tissue within a LangGraph, establishing pathways for information flow and dictating the sequence of operations. LangGraph supports multiple edge types:\\n\\n  + **Simple Edges:** These denote a direct and unconditional flow from one node to another. The output of the first node is fed as input to the subsequent node, creating a linear progression.\\n  + **Conditional Edges:** Introducing a layer of dynamism, conditional edges enable the workflow to branch based on the outcome of a specific node\\'s operation. For instance, based on a user\\'s response, the graph might decide to either terminate the interaction or proceed to invoke a tool. This decision-making capability is crucial for creating applications that can adapt to different situations. We will see an example of this in the later part of the article.\\n\\n### State Management\\n\\nA crucial aspect of managing multi-agent systems is ensuring that all agents operate with a shared understanding of the current state of the task. LangGraph addresses this through automatic state management. This means the library inherently handles the tracking and updating of a central state object as agents execute their tasks.\\n\\nThis state object acts as a repository for critical information that needs to be accessible across different points in the workflow. This might include:\\n\\n* **Conversation History:** In chatbot applications, the state could store the ongoing conversation between the user and the bot, allowing for context-aware responses.\\n* **Contextual Data:** Information pertinent to the current task, like user preferences, past behavior, or relevant external data, can be stored in the state for agents to use in decision-making.\\n* **Internal Variables:** Agents might use the state to keep track of internal flags, counters, or other variables that guide their behavior and decision-making.\\n\\n## Getting Started with LangGraph\\n\\n### Installation\\n\\nTo get started with LangGraph, you will need to install it.\\n\\nTo install LangGraph, open your terminal or command prompt and run the following command:\\n\\n```\\npip install -U langgraph \\n```\\n\\nThis command will download and install the latest version of LangGraph. The `-U` flag ensures you are getting the most up-to-date version.\\n\\n### Creating a Basic Chatbot in LangGraph\\n\\nThis example is a good starting point for understanding the fundamental concepts of LangGraph.\\n\\n1. **Import Necessary Libraries:** Begin by importing the required classes and modules from LangGraph and other relevant libraries.\\n\\n   ```\\n   from import from import from import from import\\n   ```\\n2. **Define the State Structure:** Create a class that defines the structure of the state object, which will hold information that needs to be shared and updated between nodes in the graph.\\n\\n   ```\\n   class State(TypedDict): class State TypedDict# \\'messages\\' will store the chatbot conversation history.# The \\'add_messages\\' function ensures new messages are appended to the list.# Create an instance of the StateGraph, passing in the State class\\n   ```\\n3. **Initialize the LLM:** Instantiate your chosen LLM model, providing any necessary API keys or configuration parameters. This LLM will be used to power the chatbot\\'s responses.\\n\\n   ```\\n   #pip install -U langchain_anthropic from import\"claude-3-5-sonnet-20240620\"\\n   ```\\n4. **Create the Chatbot Node:** Define a Python function that encapsulates the logic of the chatbot node. This function will take the current state as input and generate a response based on the LLM\\'s output.\\n\\n   ```\\n   def chatbot(state: State): def chatbotstate: State# Use the LLM to generate a response based on the current conversation history. \"messages\" # Return the updated state with the new message appended return \"messages\"# Add the \\'chatbot\\' node to the graph, \"chatbot\"\\n   ```\\n5. **Define Entry and Finish Points:** Specify the starting and ending points of the workflow within the graph.\\n\\n   ```\\n   # For this basic chatbot, the \\'chatbot\\' node is both the entry and finish point \"chatbot\" \"chatbot\"\\n   ```\\n6. **Compile the Graph:** Create a runnable instance of the graph by compiling it.\\n\\n   ```\\n    graph = graph_builder.compile() \\n   ```\\n7. **Visualize the Graph:** By running a simple Python code, you can visualize the graph with nodes and edges.\\n\\n   ```\\n   from import try except # This requires some extra dependencies and is optional pass\\n   ```\\n8. **Run the Chatbot:** Implement a loop to interact with the user, feeding their input to the graph and displaying the chatbot\\'s response.\\n\\n   ```\\n   while True\"User: \" if in \"quit\" \"exit\" \"q\"\"Goodbye!\" break # Process user input through the LangGraph for in \"messages\" \"user\" for in\"Assistant:\" \"messages\" -1\\n   ```\\n\\nThis code snippet provides a basic structure for a LangGraph chatbot. You can expand upon this by incorporating more sophisticated state management and different LLM models or by connecting to external tools and APIs. The key is to define clear nodes for different tasks and use edges to establish the desired flow of information and control within the chatbot.\\n\\n## Advanced LangGraph Techniques\\n\\n### Tool Integration\\n\\nIntegrating tools into your LangGraph chatbot can significantly enhance its capabilities by allowing it to access and process information the way you like.\\n\\n**Enhancing our Basic Chatbot with Tool Integration**\\n\\nLet\\'s modify the basic chatbot created in the previous section to include a tool that can search the web for information. We\\'ll use the `TavilySearchResults` tool from `langchain_`[`community.tools`](http://community.tools)`.tavily_search` . You will need [Tavily API key](https://tavily.com/) for this example.\\n\\n```\\n#pip install -U tavily-python langchain_community from import from import from import from import from import from import from import from importclass State(TypedDict): class State TypedDict 2\"claude-3-5-sonnet-20240620\"def chatbot(state: State): def chatbotstate: State return \"messages\" \"messages\" \"chatbot\" \"tools\" \"chatbot\"# Any time a tool is called, we return to the chatbot to decide the next step \"tools\" \"chatbot\" \"chatbot\"\\n```\\n\\n**Explanation:**\\n\\n1. **Import the Tool:** Import the necessary tool class, in this case `TavilySearchResults`.\\n2. **Define and Bind the Tool:** Create an instance of the tool and bind it to the LLM using `llm.bind_tools()`. This informs the LLM about the available tools and their usage.\\n3. **Create a ToolNode:** Instantiate a `ToolNode`, passing in the list of available tools.\\n4. **Add the ToolNode to the Graph:** Incorporate the `ToolNode` into the LangGraph using `graph_builder.add_node()`.\\n5. **Conditional Routing:** Utilize `graph_builder.add_conditional_edges()` to set up routing logic based on whether the LLM decides to call a tool. The `tools_condition` function checks if the LLM\\'s response includes tool invocation instructions.\\n6. **Loop Back:** After executing the tool, use `graph_builder.add_edge()` to direct the flow back to the `chatbot` node, allowing the conversation to continue.\\n\\nNow, when you run the chatbot and ask a question that requires external information, the LLM can choose to invoke the web search tool, retrieve relevant data, and incorporate it into its response.\\n\\n### Adding Memory to the Chatbot\\n\\nMemory is crucial for creating chatbots that can engage in meaningful conversations by remembering past interactions.\\n\\n**LangGraph\\'s Checkpointing System**\\n\\n1. **Checkpointer:** When you compile your LangGraph, you can provide a `checkpointer` object. This object is responsible for saving the state of the graph at different points in time.\\n2. **Thread ID:** Each time you invoke your graph, you provide a `thread_id`. This ID is used by the `checkpointer` to keep track of different conversation threads.\\n3. **Automatic Saving and Loading:** LangGraph automatically saves the state after each step of the graph\\'s execution for a given `thread_id`. When you invoke the graph again with the same `thread_id`, it automatically loads the saved state, enabling the chatbot to continue the conversation where it left off.\\n\\n**Implementing Memory with Checkpointing**\\n\\nBuilding upon the previous code, here\\'s how to add memory using LangGraph\\'s checkpointing:\\n\\n```\\n# ... (Previous code to define State, graph_builder, nodes, and edges) from import # Create a MemorySaver object to act as the checkpointer# Compile the graph, passing in the \\'memory\\' object as the checkpointer# ... (Rest of the code to run the chatbot)\\n```\\n\\n**Explanation:**\\n\\n1. **Import** `MemorySaver`: Import the `MemorySaver` class from `langgraph.checkpoint.memory`.\\n2. **Create a** `MemorySaver` Object: Instantiate a `MemorySaver` object, which will handle saving and loading the graph\\'s state.\\n3. **Pass to** `compile()`: When compiling the graph, pass the `memory` object as the `checkpointer` argument.\\n\\nNow, when you run the chatbot, first, use a `thread_id` to use as the key for this conversation:\\n\\n```\\n\"configurable\" \"thread_id\" \"1\"\\n```\\n\\nEach unique `thread_id` will have its conversation history stored.\\n\\nNow begin the conversation:\\n\\n```\\nwhile True\"User: \" if in \"quit\" \"exit\" \"q\"\"Goodbye!\" break # Process user input through the LangGraph for in \"messages\" \"user\" for in\"Assistant:\" \"messages\" -1\\n```\\n\\n> **Note:** The config was provided as the **second positional argument** when calling our graph.\\n\\n### Human in the Loop\\n\\nHuman-in-the-loop workflows are essential for situations where you want to incorporate human oversight, verification, or decision-making within your AI application.\\n\\n**Implementing Human-in-the-Loop with Interrupts**\\n\\nThe below code illustrates human-in-the-loop implementation using LangGraph\\'s `interrupt_before` or `interrupt_after` functionality. Here\\'s a breakdown:\\n\\n```\\nfrom import from import from import from import from import from import from import from import from importclass State(TypedDict): class State TypedDict 2\"claude-3-5-sonnet-20240620\"def chatbot(state: State): def chatbotstate: State return \"messages\" \"messages\" \"chatbot\" \"tools\" \"chatbot\" \"tools\" \"chatbot\" \"chatbot\"# This is new! \"tools\"# Note: can also interrupt __after__ actions, if desired.# interrupt_after=[\"tools\"]\\n```\\n\\n**Explanation:**\\n\\nIn this particular example, the graph will pause just before executing the `tools` node. This `tools` node is responsible for running any tools that the LLM might have requested during its turn. By interrupting at this point, you can essentially allow a human to either:\\n\\n* **Approve the Tool Call:** The human can review the tool call the LLM wants to make and its input. If they deem it appropriate, they can simply allow the graph to continue, and the tool will be executed.\\n* **Modify the Tool Call:** If the human sees a need to adjust the LLM\\'s tool call (e.g., refine the search query), they can modify the state of the graph and then resume execution.\\n* **Bypass the Tool Call:** The human might decide the tool isn\\'t necessary. Perhaps they have the answer the LLM was trying to look up. In this case, they can update the graph state with the appropriate information, and the LLM will receive it as if the tool had returned that information.\\n\\n> **Resources:** Here is the Notebook to gain a more detailed understanding about the Human in the Loop: <https://github.com/langchain-ai/langgraph/blob/main/docs/docs/how-tos/human_in_the_loop/review-tool-calls.ipynb>\\n\\n## Real-World Uses for LangGraph\\n\\n**LangGraph lets you build AI systems that are more complex and interactive than simple question-and-answer bots** by managing state, coordinating multiple agents, and allowing for human feedback. Here are some of the ways LangGraph could be used:\\n\\n* **Smarter Customer Service:** Imagine a chatbot for online shopping that can remember your past orders and preferences. It could answer questions about products, track your shipments, and even connect you with a human representative if needed.\\n* **AI Research Assistant:** Need help with a research project? A LangGraph-powered assistant could search through tons of academic papers and articles, summarize the key findings, and even help you organize your notes.\\n* **Personalized Learning:** LangGraph could power the next generation of educational platforms. Imagine a system that adapts to your learning style, identifies areas where you need extra help, and recommends personalized resources.\\n* **Streamlined Business:** Many business processes involve multiple steps and people. LangGraph could automate parts of these workflows, like routing documents for approval, analyzing data, or managing projects.\\n\\nThese examples highlight how **LangGraph helps bridge the gap between AI capabilities and the complexities of real-world situations**.\\n\\n## Conclusion\\n\\nThis concludes our LangGraph tutorial! As you\\'ve learned, LangGraph enables the creation of AI applications that go beyond simple input-output loops by offering a framework for building stateful, agent-driven systems. You\\'ve gained hands-on experience defining graphs, managing state, and incorporating tools.\\n\\nIf you found this guide helpful and you\\'re looking to learn more then don’t forget to [follow us](https://www.youtube.com/@AIDemosVideos).\\n\\nIf you want to trace LLM calls of your Langchain project, then you can check out this blog [Guide to LangSmith](https://blog.futuresmart.ai/guide-to-langsmith)\\n\\nAt **FutureSmart AI**, we specialize in helping companies build cutting-edge AI solutions similar to the ones discussed in this blog. To explore how we can assist your business, feel free to reach out to us at [**[contact@futuresmart.ai](mailto:contact@futuresmart.ai)**](http://contact@futuresmart.ai).\\n\\nFor real-world examples of our work, take a look at our [case studies](https://www.futuresmart.ai/case-studies), where we showcase the practical value of our expertise.\\n\\n[langchain](/tag/langchain?source=tags_bottom_blogs)[AI](/tag/ai?source=tags_bottom_blogs)[langgraph](/tag/langgraph?source=tags_bottom_blogs)[llm](/tag/llm?source=tags_bottom_blogs)[#agent](/tag/agent?source=tags_bottom_blogs)\\n\\nShare this'}, {'url': 'https://www.getzep.com/ai-agents/langgraph-tutorial/', 'title': \"LangGraph Tutorial: Building Agents with LangChain's ...\", 'content': \"Learn how LangGraph, an AI agent framework built by LangChain, allows developers to create complex and flexible agent workflows using stateful graphs and built-in memory management. Now that you know how Zep's long-term memory works, let's look at how to develop an agent using LangGraph agents that employ Zep's long-term memory to store user facts. We will define a graph state that stores messages originating from different nodes, user names, and session IDs. Next, we will create the **search\\\\_facts** tool, which uses the Zep client's **memory.search\\\\_sessions()** method to find user facts relevant to the query. Finally, we define the **graph\\\\_invoke()** function, which accepts user query, user name, and session name (**thread\\\\_id** in the following script) and returns the LangGraph agent's response.\", 'score': 0.8003337, 'raw_content': '[Log in](https://app.getzep.com/)\\n\\n[Sign Up](https://app.getzep.com/api/auth/register)\\n\\n# LangGraph Tutorial: Building Agents with LangChain\\'s Agent Framework\\n\\nLearn how LangGraph, an AI agent framework built by LangChain, allows developers to create complex and flexible agent workflows using stateful graphs and built-in memory management.\\n\\nPublished March 1, 2025\\n\\nUpdated March 1, 2025\\n\\nThe idea behind the agent in LangChain is to use an LLM and a sequence of actions; the agent then uses a reasoning engine to decide which action to take. LangChain was useful for simple agents with straightforward chains and retrieval flows, but building more complex agentic systems was overly complicated-memory management, persistence, and human-in-the-loop components were implemented manually, rendering chains and agents less flexible.\\n\\nThis is where [LangGraph](https://www.langchain.com/langgraph) comes into play. LangGraph is an orchestration framework built by [LangChain](https://www.langchain.com/). LangGraph allows you to develop agentic LLM applications using a graph structure, which can be used with or without LangChain.\\n\\nThis article focuses on building agents with LangGraph rather than LangChain. It provides a tutorial for building LangGraph agents, beginning with a discussion of LangGraph and its components. These concepts are reinforced by building a LangGraph agent from scratch and managing conversation memory with LangGraph agents. Finally, we use [Zep\\'s long-term memory for egents](https://www.getzep.com/) to create an agent that remembers previous conversations and user facts.\\n\\n## **Summary of key LangGraph tutorial concepts**\\n\\nThe following are the main concepts covered in this article.\\n\\n| Concept | Description |\\n| --- | --- |\\n| What is LangGraph? | LangGraph is an AI agent framework that implements agent interactions as stateful graphs. Nodes represent functions or computational steps that are connected via edges. LangGraph maintains an agent state shared among all the nodes and edges. Unlike LangChain, LangGraph supports the implementation of more complex agentic workflows. Key features include built-in persistence, support for human intervention, and the ability to handle complex workflows with cycles and branches. |\\n| Building a LangGraph agent | Creating a LangGraph agent is the best way to understand the core concepts of nodes, edges, and state. The LangGraph Python libraries are modular and provide the functionality to build a stateful graph by incrementally adding nodes and edges. Incorporating tools enables an agent to perform specific tasks and access external information. For example, the **ArXiv** tool wrapper can return content from research papers. LangGraph offers a prebuilt reason and act (ReACT) agent that can help you get started. |\\n| Memory management in LangGraph | A LangGraph agent is stateless by default, meaning that it does not remember previous conversations, which limits its ability to have meaningful exchanges. To address this, LangGraph supports both short-term and long-term memory. Memory support in LangGraph can be extended further with Zep Memory. |\\n| Zep long-term memory | [Zep](https://www.getzep.com/) is a memory layer designed for AI agents that addresses several limitations of the default LangGraph short-term and long-term memory. Zep automatically extracts facts for user conservation and stores them as long-term memory objects. |\\n| Guidelines for building LangGraph agents | LangGraph overcomes LangChain\\'s limitations and is the recommended framework for building agentic architectures. You can integrate tools into your AI agents to provide functionality or fetch information that an LLM agent does not provide. Memory is integral to building production-ready AI agents, and third-party SDKs like Zep simplify adding long-term capabilities. |\\n\\n## **What is LangGraph?**\\n\\nLangGraph is an AI agent framework built on LangChain that allows developers to create more sophisticated and flexible agent workflows. Unlike traditional LangChain chains and agents, LangGraph implements agent interactions as cyclic graphs with multiple-step processing involving branching and loops. This eliminates the need to implement custom logic to control the flow of information between multiple agents in the workflow.\\n\\n### **How LangGraph works**\\n\\nAs the name suggests, LangGraph is a graph workflow consisting of nodes and edges. The nodes implement functionality within the workflow while the edges control its direction.\\n\\nThe following diagram best explains how LangGraph works at a high level.\\n\\nA high-level overview of a LangGraph agent and its components\\n\\nA LangGraph agent receives input, which can be a user input or input from another LangGraph agent. Typically, an LLM agent processes the input and decides whether it needs to call one or more tools, but it can directly generate a response and proceed to the next stage in the graph.\\n\\nIf the agent decides to call one or more tools, the tool processes the agent output and returns the response to the agent. The agent then generates its response based on the tool output. Once an agent finalizes its response, you can further add an optional \"human-in-the-loop\" step to refine the agent response before returning the final output.\\n\\nThis is just one example of how LangGraph agents work at a high level. You can create different combinations of nodes and edges to achieve your desired functionality.\\n\\n### **Persistence**\\n\\nOne key LangGraph feature that distinguishes it from traditional LangChain agents is its built-in persistence mechanism. LangGraph introduces the concept of an agent state shared among all the nodes and edges in a workflow. This allows automatic error recovery, enabling the workflow to resume where it left off.\\n\\nIn addition to the agent state memory, LangGraph supports persisting conversation histories using short-term and long-term memories, which are covered in detail later in the article.\\n\\n### **Cycles**\\n\\nLangGraph introduces cycling graphs, allowing agents to communicate with tools in a cyclic manner. For example, an agent may call a tool, retrieve information from the tool, and then call the same or another tool to retrieve follow-up information. Similarly, tools may call each other multiple times to share and refine information before passing it back to an agent. This differentiates it from DAG-based solutions.\\n\\n### **Human-in-the-loop capability**\\n\\nLangGraph supports human intervention in agent workflows, which interrupts graph execution at specific points, allowing humans to review, approve, or edit the agent\\'s proposed response. The workflow resumes after receiving human input.\\n\\nThis feature fosters greater control and oversight in critical decision-making processes in an agent\\'s workflow.\\n\\n### **LangGraph agents vs. LangChain agents**\\n\\nBefore LangGraph, LangChain chains and agents were the go-to techniques for creating agentic LLM applications. The following table briefly compares LangGraph agents with traditional LangChain chains and agents.\\n\\n| Feature | LangGraph agents | LangChain agents |\\n| --- | --- | --- |\\n| Structure | Graph-based | Linear or tree-like with custom implementation |\\n| Persistence | Built-in | Manual implementation required |\\n| State management | Automated | Manual implementation required |\\n| Human intervention | Native support | Manual implementation required |\\n| Cycles | Supported | No direct support |\\n| Flexibility | Highly flexible, with loops and branches | Limited compared to LangGraph |\\n| Complexity | Can handle complex workflows | Better for simpler tasks |\\n\\nTo summarize, LangGraph supports implementing more complex agentic workflows while allowing higher flexibility than traditional LangChain chains and agents.\\n\\n### **Understanding nodes, edges, and state**\\n\\nIf you are new to LangGraph, you must understand a few terms before creating an agent: nodes, edges, and state.\\n\\nA simple graph in LangGraph showing nodes, edges, and states ([source](https://medium.com/@kbdhunga/beginners-guide-to-langgraph-understanding-state-nodes-and-edges-part-1-897e6114fa48))\\n\\n**Nodes**\\n\\nNodes are the building blocks of your agents and represent a discrete computation unit within your agent\\'s workflow. A node can be as simple as a small Python function or as complex as an independent agent that calls external tools.\\n\\n**Edges**\\n\\nEdges connect nodes and define how your agent progresses from one step to the next. Edges can be of two types: direct and conditional. A direct edge simply connects two nodes without any condition, whereas a conditional node is similar to an if-else statement and connects two nodes based on a condition.\\n\\n**State**\\n\\nA state is LangGraph\\'s most underrated yet most essential component. It contains all the data and context available to different entities, such as nodes and edges. Simply put, the state shares data and context among all nodes and edges in a graph.\\n\\n## **Building a LangGraph agent**\\n\\nEnough with the theory-in this section, you will see all the building blocks of LangGraph agents in action. You will learn how to:\\n\\n* Create a LangGraph agent from scratch\\n* Incorporate tools into LangGraph agents\\n* Stream agent responses\\n* Use built-in agents\\n\\n### **Installing and importing required libraries**\\n\\nThis article uses the Python version of LangGraph for examples. To run scripts in this section and the upcoming sections, you need to install the following Python libraries, which allow you to access the various LangGraph functions and tools you will incorporate into your agents.\\n\\n```\\n%pip install langchain-core\\n%pip install langchain-openai\\n%pip install -U langgraph\\n%pip install langchain-community\\n%pip install --upgrade --quiet  wikipedia\\n%pip install arxiv\\n%pip install zep-cloud\\n\\n```\\n\\nLet\\'s import relevant functionalities from the modules above.\\n\\n```\\n[object Object] langchain_openai [object Object] ChatOpenAI\\n[object Object] langchain_core.messages [object Object] AnyMessage, SystemMessage, HumanMessage, ToolMessage, AIMessage, trim_messages\\n[object Object] langchain_core.tools [object Object] tool, ToolException, InjectedToolArg\\n[object Object] langchain_core.runnables [object Object] RunnableConfig\\n[object Object] langchain_community.utilities [object Object] ArxivAPIWrapper\\n[object Object] langchain_community.tools [object Object] ArxivQueryRun, HumanInputRun\\n[object Object] langgraph.graph [object Object] StateGraph,START,END, add_messages, MessagesState\\n[object Object] langgraph.prebuilt [object Object] create_react_agent, ToolNode\\n[object Object] langgraph.checkpoint.memory [object Object] MemorySaver\\n[object Object] langgraph.store.base [object Object] BaseStore\\n[object Object] langgraph.store.memory [object Object] InMemoryStore\\n[object Object] typing [object Object] Annotated, [object Object]\\n[object Object] typing_extensions [object Object] TypedDict\\n[object Object] pydantic [object Object] BaseModel, Field\\n[object Object] wikipedia\\n[object Object] uuid\\n[object Object] operator\\n[object Object] IPython.display [object Object] Image, display\\n[object Object] os\\n[object Object] google.colab [object Object] userdata\\n\\n```\\n\\n### **Creating a LangGraph agent from scratch**\\n\\nLet\\'s start with the state definition, which specifies what type of information will flow between different nodes and edges in a graph.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n  messages: Annotated[[object Object][AnyMessage], operator.add]\\n\\n```\\n\\nThis defines a simple state that stores a list of any type of LangChain message, such as ToolMessage, AIMessage, HumanMessage, etc. The **operator.add** operator will add new messages to the list instead of overwriting existing ones.\\n\\nNext, we will define a simple Python function to add a node in our LangGraph agent.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    messages = state[[object Object]]\\n    message = model.invoke(messages)\\n    [object Object] {[object Object]: [message]}\\n\\n```\\n\\nThe **run\\\\_llm()** function accepts an object of the **State** class that we defined before. When we add the **run\\\\_llm()** function to a LangGraph node, LangGraph will automatically pass the agent\\'s state to the **run\\\\_llm()** function.\\n\\nLet\\'s now create our graph.\\n\\n```\\ngraph_builder=StateGraph(State)\\ngraph_builder.add_node([object Object], run_llm)\\ngraph_builder.add_edge(START,[object Object])\\ngraph_builder.add_edge([object Object],END)\\n\\ngraph=graph_builder.[object Object]()\\n\\n```\\n\\nTo create a graph, we will create a **StateGraph** object and define the state type in the **StateGraph** constructor. Subsequently, we will add a node titled **llm** and add the **run\\\\_llm()** function to the node.\\n\\nWe add two edges that define the start and end of the agent execution. Our agent has a single node, so we start with the **llm** node and end the agent execution once we receive the response from the **llm** node.\\n\\nFinally, we must compile the graph using the **compile()** method.\\n\\nWe can visualize the graph using the following script:\\n\\n```\\ndisplay(Image(graph.get_graph().draw_mermaid_png()))\\n\\n```\\n\\nLet\\'s test the agent we just created. To do so, call the **invoke()** method on the **graph** object created.\\n\\n```\\nmessages = [HumanMessage(content=[object Object])]\\nresult = graph.invoke({[object Object]: messages})\\n[object Object](result[[object Object]][-[object Object]].content)\\n\\n```\\n\\nIn most cases, you will need LangGraph agents to use tools to respond appropriately. The following section explains how to incorporate tools into LangGraph agents.\\n\\n### **Incorporating tools into LangGraph agents**\\n\\nAn AI tool is a component that enhances the default functionalities of an AI agent, allowing it to perform a specific task or access external information. For example, you can use tools to access the web, connect to an external database, book a flight, etc.\\n\\nYou can incorporate custom and [built-in LangChain](https://python.langchain.com/v0.1/docs/integrations/tools/) tools into your LangGraph agents; the approaches remain very similar. In this section, we will see both tool types.\\n\\nIncorporating a tool into an agent is a highly flexible process. You can directly add a tool to an agent\\'s node or a function to a node that calls one or multiple tools. The latter approach is recommended because it allows for more customization.\\n\\nLet\\'s first see how to use a built-in LangChain tool in LangGraph. We will use the LangChain **ArXiv** tool wrapper to create a tool that returns research papers based on user queries.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    data = arxiv_tool.invoke(query)\\n    [object Object] data\\n\\n[object Object] [object Object]([object Object]):\\n  topic: [object Object] = Field(description=[object Object])\\n\\n[object Object]\\n[object Object] [object Object]([object Object]) -> [object Object]:\\n  [object Object]\\n  [object Object] get_arxiv_data(topic)\\n\\n```\\n\\nIn the script above, we define the function **get\\\\_arxiv\\\\_data()**, which accepts a user query and calls the LangChain ArXiv tool to return research paper information related to a user query.\\n\\nNext, we inherit the **BaseModel** class to define the data type our tool will accept as a parameter, which ensures that input to the tool always has a valid input data type.\\n\\nFinally, we use the **@tool** decorator and create an **arxiv\\\\_search** tool that calls the **get\\\\_arxiv\\\\_data** function. The tool description is critical in this case since the LLM agent selects a tool based on its description.\\n\\nIn the same way, we create a custom tool, as the following script shows:\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    data = wikipedia.summary(topic)\\n    [object Object] data\\n\\n[object Object] [object Object]([object Object]):\\n  topic: [object Object] = Field(description=[object Object])\\n\\n[object Object]\\n[object Object] [object Object]([object Object]) -> [object Object]:\\n  [object Object]\\n  [object Object] get_wiki_data(topic)\\n\\n```\\n\\nThe tool above uses the Python Wikipedia library to return Wikipedia article summaries based on user queries.\\n\\nOnce you create your tools, the next step is to bind them to the LLM you will use in your agent.\\n\\n```\\ntools = [arxiv_search, wikipedia_search]\\ntools_names = {t.name: t [object Object] t [object Object] tools}\\nmodel = model.bind_tools(tools)\\n\\n```\\n\\nIn the next step, we define a function that executes whenever an agent decides to call one or more tools.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    tool_calls = state[[object Object]][-[object Object]].tool_calls\\n    results = []\\n    [object Object] t [object Object] tool_calls:\\n\\n      [object Object] [object Object] t[[object Object]] [object Object] tools_names:\\n        result = [object Object]\\n      [object Object]:\\n        result = tools_names[t[[object Object]]].invoke(t[[object Object]])\\n\\n        results.append(\\n          ToolMessage(\\n            tool_call_id=t[[object Object]],\\n            name=t[[object Object]],\\n            content=[object Object](result)\\n          )\\n        )\\n\\n    [object Object] {[object Object]: results}\\n\\n```\\n\\nThe **execute\\\\_tools** function above will be added to a LangGraph agent\\'s node, automatically receiving the agent\\'s current state. We will only call the **execute\\\\_tools()** function if the agent decides to use one or more tools.\\n\\nInside the **execute\\\\_tools** function, we will iteratively call the tools and pass the arguments from the LLM\\'s last response to them. Finally, we will append the tool response to the **results[]** list and add the list to the model state using the state\\'s **messages** list.\\n\\nThe last and final step before creating a graph is to define a function that checks whether the agent\\'s latest state contains tool calls.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    result = state[[object Object]][-[object Object]]\\n    [object Object] [object Object](result.tool_calls) > [object Object]\\n\\n```\\n\\nWe will use this function to create a conditional edge, which decides whether to go to the **execute\\\\_tools()** function or the END node and returns the agent\\'s final response.\\n\\nNow let\\'s create a LangGraph agent that uses the tool we created. The following script defines the agent\\'s state and the **run\\\\_llm()** function as before.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n  messages: Annotated[[object Object][AnyMessage], operator.add]\\n\\n[object Object] [object Object]([object Object]):\\n    messages = state[[object Object]]\\n    message = model.invoke(messages)\\n    [object Object] {[object Object]: [message]}\\n\\n```\\n\\nThe script below defines and displays the complete agent graph.\\n\\n```\\ngraph_builder=StateGraph(State)\\ngraph_builder.add_node([object Object], run_llm)\\ngraph_builder.add_node([object Object], execute_tools)\\ngraph_builder.add_conditional_edges(\\n    [object Object],\\n     tool_exists,\\n    {[object Object]: [object Object], [object Object]: END}\\n    )\\n\\ngraph_builder.add_edge([object Object], [object Object])\\n\\ngraph_builder.set_entry_point([object Object])\\n\\n\\ngraph=graph_builder.[object Object]()\\n\\ndisplay(Image(graph.get_graph().draw_mermaid_png()))\\n\\n```\\n\\nHere is how the graph looks:\\n\\nWe have two nodes in the graph: the **llm**, which runs the **run\\\\_llm()** function, and the **tools** node, which runs the **execute\\\\_tools()** function. The conditional node connects the **llm** node with the **tool** or the END node depending upon the output of the **llm** node. We also add an edge back from the **tools** to the **llm** node because we want the **llm** node to generate the final response with or without the help of the tool.\\n\\nNow let\\'s test the agent we created. We will first ask the agent to return a research paper.\\n\\n```\\nmessages = [HumanMessage(content=[object Object])]\\nresult = graph.invoke({[object Object]: messages})\\nresult\\n\\n```\\n\\nThe output above shows that the model has called the **arxiv\\\\_tool** to generate the response. The model is intelligent enough to infer any query about research papers must be routed to the **arxiv\\\\_search** tool.\\n\\nLet\\'s search for something on Wikipedia.\\n\\n```\\nmessages = [HumanMessage(content=[object Object])]\\nresult = graph.invoke({[object Object]: messages})\\nresult\\n\\n```\\n\\nYou can see that the model used the **wikipedia\\\\_search** tool to generate the final response.\\n\\n### **Streaming agent responses**\\n\\nYou can also stream the individual responses from all nodes and edges in your LangGraph agent. Streaming messages allows users to receive responses in real-time. To do so, you can call the **stream()** function instead of the **invoke()** method.\\n\\nLet\\'s define a function that receives streaming agent response and displays it on the console.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    [object Object] s [object Object] stream:\\n        message = s[[object Object]][-[object Object]]\\n        [object Object] [object Object](message, [object Object]):\\n            [object Object](message)\\n        [object Object]:\\n            message.pretty_print()\\n\\n```\\n\\nNext, call **graph().stream()** and pass it the input messages. Also set the attribute **stream\\\\_mode** to **values**, which displays the values of the streaming agent responses.\\n\\n```\\nmessages = [HumanMessage(content=[object Object])]\\nprint_stream(graph.stream({[object Object]: messages}, stream_mode= [object Object]))\\n\\n```\\n\\nYou will see real-time responses from each graph node printed on the console. For example, in the output above, you can see the human message followed by the AI response, which contains tool calls to the **wikipedia\\\\_search** tool. The tool returns the response to the user query; this is again passed to the AI node, which generates the final response.\\n\\n### **Using built-in agents**\\n\\nIn previous sections, we created an agent that checks whether it needs a tool\\'s help to generate a final response. If it does, it calls the tool, fetches the tool response, and returns the final response; if it doesn\\'t, it simply returns the default LLM response. We can use LangGraph\\'s built-in [ReAct agent](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/#code) to achieve the same functionality.\\n\\nYou can use the **react\\\\_search\\\\_agent()** from the **langgraph.prebuilt** module to create a ReAct agent. To define the ReAct agent\\'s functionality, pass the **system\\\\_prompt** to the **state\\\\_modifier** attribute.\\n\\nThe following script creates a ReAct agent that uses the tool we created in previous sections:\\n\\n```\\nmodel = ChatOpenAI(model=[object Object])\\n\\nprompt = [object Object]\\n\\nreact_search_agent = create_react_agent(model, tools, state_modifier= prompt)\\n\\ndisplay(Image(react_search_agent.get_graph().draw_mermaid_png()))\\n\\n```\\n\\nYou can see that the ReAct agent above is very similar to what we created earlier from scratch.\\n\\nLet\\'s test the agent by asking a simple question that doesn\\'t require any tool\\'s help.\\n\\n```\\nmessages = [HumanMessage(content=[object Object])]\\nprint_stream(react_search_agent.stream({[object Object]: messages}, stream_mode= [object Object]))\\n\\n```\\n\\nYou can see that the ReAct agent generated a response without any tool\\'s assistance.\\n\\nLet\\'s send another request.\\n\\n```\\nmessages = [HumanMessage(content=[object Object])]\\nprint_stream(react_search_agent.stream({[object Object]: messages}, stream_mode= [object Object]))\\n\\n```\\n\\nThis time, the agent called the **wikipedia\\\\_search** tool before generating the final response.\\n\\n## **Memory management in LangGraph**\\n\\nBy default, interaction with LangGraph agents is stateless, which means that the agent does not remember the previous conversation and cannot generate responses to follow-up queries. In this section, you will see why you need agents with memory and how to create LangGraph agents that remember previous conversations.\\n\\n### **Why do you need agents with memory?**\\n\\nThe answer is simple: Humans have memory and can answer follow-up questions. You want your agents to remember what was previously discussed so that they can have a meaningful conversation.\\n\\nLet\\'s see an example where a user interacts with an agent without conversational memory. We ask the agent: \"Who is Christiano Ronaldo?\"\\n\\n```\\nmessages = [HumanMessage(content=[object Object])]\\nresult = react_search_agent.invoke({[object Object]: messages})\\n[object Object](result[[object Object]][-[object Object]].content)\\n\\n```\\n\\nHere, the agent probably called the **wikipedia\\\\_search** tool to generate the response. Let\\'s ask a follow-up question about Christiano Ronaldo.\\n\\n```\\nmessages = [HumanMessage(content=[object Object])]\\nresult = react_search_agent.invoke({[object Object]: messages})\\n[object Object](result[[object Object]][-[object Object]].content)\\n\\n```\\n\\nYou can see that the model doesn\\'t remember what we asked it previously. Though we could append previous conversations before the current message to provide context to the LLM, an LLM\\'s context window is limited and will eventually be filled, leading to slower agent responses and, in some cases, truncation of conversation context.\\n\\nModels with very large context windows can store an entire chat history, leading to recall issues where the model may overlook older conversations. Additionally, a large context window might introduce contradictory information if there are conflicting details from earlier parts of the conversation, potentially confusing the model. Lastly, using larger prompts can significantly increase the cost of processing.\\n\\nThe ability of an AI agent to remember previous conversations is crucial in almost all agent types, ranging from medical agents, where an agent must remember a patient\\'s previous information, to e-commerce agents, where it is important for an agent to remember user preferences to provide a customized response.\\n\\nThe diagram below shows an LLM-powered agent\\'s components; tools were used to retrieve additional information in the examples above. In the examples below, the role of memory will be explained.\\n\\nGeneral components of an AI agent ([source](https://lilianweng.github.io/posts/2023-06-23-agent/))\\n\\n### **Creating LangGraph agents with memory**\\n\\nLangGraph agents can be created with short-term or long-term memory.\\n\\n#### **Agents with short-term memory**\\n\\nThe easiest way to add persistence to your interactions with LangGraph agents is via checkpointers. To do so, you must pass a memory object (in memory or third-party) to the **checkpointer** attribute while compiling a LangGraph agent. For example:\\n\\n**graph.compile(checkpointer=memory)**\\n\\nFor a ReAct agent, you can pass the memory object to the **checkpointer** attribute of the **create\\\\_react\\\\_agent()** function.\\n\\nNext, while invoking the graph, you must pass the **configurable** dictionary containing the value for the **thread\\\\_id** key. The memory is associated with this **thread\\\\_id**.\\n\\nHere is an example.\\n\\n```\\nmemory = MemorySaver()\\nreact_search_agent = create_react_agent(model, tools, state_modifier= prompt,  checkpointer=memory)\\n\\nconfig = {[object Object]: {[object Object]: [object Object]}}\\nmessages = [HumanMessage(content=[object Object])]\\nresult = react_search_agent.invoke({[object Object]: messages}, config = config)\\n[object Object](result[[object Object]][-[object Object]].content)\\n\\n```\\n\\n```\\nmessages = [HumanMessage(content=[object Object])]\\nresult = react_search_agent.invoke({[object Object]: messages}, config = config)\\n[object Object](result[[object Object]][-[object Object]].content)\\n\\n```\\n\\nYou can see that the agent remembers that we are asking a question about Christiano Ronaldo. However, one drawback of short-term memory is that it is not shared between multiple sessions or threads. For example, if you change the **thread\\\\_id** and ask the same question, the agent will not understand the follow-up query.\\n\\n```\\nconfig = {[object Object]: {[object Object]: [object Object]}}\\nmessages = [HumanMessage(content=[object Object])]\\nresult = react_search_agent.invoke({[object Object]: messages}, config = config)\\n[object Object](result[[object Object]][-[object Object]].content)\\n\\n```\\n\\nThe other drawback of short-term memory is that the entire chat history might not fit the model context window. Longer chat histories can be complex and often introduce hallucinations in agent responses.\\n\\n#### **Agents with long-term memory**\\n\\nRecently, LangGraph introduced long-term memory, which you can share across multiple threads. You can also extract facts from user conversations and add them to long-term memory, leading to a shorter and more robust chat context.\\n\\nYou can use LangGraph\\'s **InMemoryStore** class to manage and store long-term memories. This class stores memories in namespaces, each of which may include multiple memories. Each memory has a memory ID, while context and content are key-value pairs.\\n\\nThe following script shows an example of storing a long-term memory in an **InMemoryStore** object using the **put()** method.\\n\\n```\\n[object Object] langgraph.store.memory [object Object] InMemoryStore\\nmemory_store = InMemoryStore()\\n\\nuser_id = [object Object]\\nnamespace = (user_id, [object Object])\\n\\nmemory_id = [object Object]\\nmemory = {[object Object] : [object Object]}\\nmemory_store.put(namespace,\\n                 memory_id,\\n                 memory)\\n\\n```\\n\\nYou can see memories in a namespace using the following script:\\n\\n```\\nmemories = memory_store.search(namespace)\\nmemories[-[object Object]].[object Object]()\\n\\n```\\n\\nNow we will create another memory for the same user:\\n\\n```\\nmemory_id = [object Object]\\nmemory = {[object Object] : [object Object]}\\nmemory_store.put(namespace, memory_id, memory)\\n\\nmemories = memory_store.search(namespace)\\n\\n[object Object] memory [object Object] memories:\\n    [object Object]([object Object])\\n\\n```\\n\\nYou can see two memories in the memory store now. Let\\'s see how you can create a LangGraph agent that uses LangGraph\\'s long-term memory.\\n\\nWe will create a tool that accepts the memory ID, content, and context and inserts them in a memory store. The tool also accepts the configuration dictionary containing the user ID and the memory store object.\\n\\n```\\n[object Object]\\n[object Object] [object Object]([object Object]):\\n    [object Object]\\n\\n    mem_id = memory_id [object Object] uuid.uuid4()\\n    user_id = config[[object Object]][[object Object]]\\n    namespace = ([object Object], user_id)\\n    store.put(\\n        namespace,\\n        key=[object Object](mem_id),\\n        value={[object Object]: content, [object Object]: context},\\n    )\\n    [object Object] [object Object]\\n\\n```\\n\\nIf the memory ID is not passed, it creates a new memory ID; otherwise, it updates the content of the passed memory ID.\\n\\nWe will define the **update\\\\_memory** function to add to our LangGraph agent node. It will receive the graph\\'s state, the configuration dictionary, and the **InMemoryStore** object. The function extracts the memory content and context from the graph\\'s state and the user ID from the configuration dictionary.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n\\n    [object Object]\\n    recent_tool_calls = state[[object Object]][-[object Object]].tool_calls\\n    memory_entries = []\\n\\n    [object Object]\\n    [object Object] call [object Object] recent_tool_calls:\\n        memory_content = call[[object Object]][[object Object]]\\n        memory_context = call[[object Object]][[object Object]]\\n        memory_entries.append([\\n            upsert_memory.invoke({[object Object]: memory_content, [object Object]: memory_context, [object Object]: config, [object Object]: store})\\n        ])\\n    [object Object]([object Object], memory_entries)\\n\\n    [object Object]\\n    response_data = [\\n        {\\n            [object Object]: [object Object],\\n            [object Object]: memory_entry[[object Object]],\\n            [object Object]: call[[object Object]],\\n        }\\n        [object Object] call, memory_entry [object Object] [object Object](recent_tool_calls, memory_entries)\\n    ]\\n\\n    [object Object]\\n    [object Object] {[object Object]: response_data[[object Object]]}\\n\\n```\\n\\nThe function passes these values to the **upsert\\\\_memory** tool. The **update\\\\_memory** function adds the tool\\'s response to the state. Next, we define the **run\\\\_llm()** function, which extracts memories from the **InMemoryStore** object using the user ID and invokes the LLM model using the memories and the user\\'s new query.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    user_id = config[[object Object]][[object Object]]\\n    namespace = ([object Object], user_id)\\n    memories = store.search(namespace)\\n\\n    user_info = [object Object].join([object Object] [object Object] mem [object Object] memories)\\n    [object Object] user_info:\\n        user_info = [object Object]\\n\\n    system_msg = [object Object]\\n\\n    response = model.bind_tools([upsert_memory]).invoke(\\n        [{[object Object]: [object Object], [object Object]: system_msg}] + state[[object Object]]\\n    )\\n    [object Object] {[object Object]: response}\\n\\n```\\n\\nThe last step is to define the **tool\\\\_exists** function, which decides whether we need to store user facts in memory.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    [object Object]\\n    msg = state[[object Object]][-[object Object]]\\n    [object Object] msg.tool_calls:\\n        [object Object]\\n        [object Object] [object Object]\\n    [object Object]\\n    [object Object] END\\n\\n```\\n\\nFinally, we will create our LangGraph agent that uses long-term memory to respond to user queries:\\n\\n```\\nmodel = ChatOpenAI(model=[object Object])\\nmemory_store = InMemoryStore()\\n\\ngraph_builder = StateGraph(MessagesState)\\n\\ngraph_builder.add_node([object Object], run_llm)\\ngraph_builder.add_node(update_memory)\\ngraph_builder.add_conditional_edges([object Object], tool_exists, [[object Object], END])\\ngraph_builder.add_edge([object Object], [object Object])\\n\\ngraph_builder.set_entry_point([object Object])\\ngraph = graph_builder.[object Object](store=memory_store)\\n\\ndisplay(Image(graph.get_graph().draw_mermaid_png()))\\n\\n```\\n\\nThe agent is similar to the ReAct agent we created earlier but maintains a long-term user memory. Let\\'s test the agent.\\n\\n```\\nconfig = {[object Object]: {[object Object]: [object Object]}}\\nmessages = [HumanMessage(content=[object Object])]\\n[object Object] chunk [object Object] graph.stream({[object Object]: messages}, config, stream_mode=[object Object]):\\n  chunk[[object Object]][-[object Object]].pretty_print()\\n\\n```\\n\\nYou can see that the agent called the **upsert\\\\_memory** tool and inserted some user information into long-term memory.\\n\\n```\\nconfig = {[object Object]: {[object Object]: [object Object]}}\\nmessages = [HumanMessage(content=[object Object])]\\n[object Object] chunk [object Object] graph.stream({[object Object]: messages}, config, stream_mode=[object Object]):\\n  chunk[[object Object]][-[object Object]].pretty_print()\\n\\n```\\n\\nThis shows that the agent remembers the user information. Since there was nothing to add to memory this time, the agent did not call any tool and directly responded to the user.\\n\\n### **Problems with LangGraph\\'s default memory options**\\n\\nThough LangGraph provides several default options to store memories, it has certain drawbacks:\\n\\n* Short-term memories are not shared between multiple sessions and threads.\\n* The memory context can exceed the LLM model context; in such cases, you must trim or summarize memories to fit the model context.\\n* Extremely long memory contexts may induce hallucinations in LLM models.\\n* LangGraph\\'s default long-term memory solves most problems associated with short-term memory. However, even with LangGraph\\'s default long-term memory, generating and updating facts from the conversation history and invalidating existing facts to have the most updated user information is challenging.\\n\\nThis is where Zep\\'s long-term memory comes into play.\\n\\n## **Zep Long-Term Memory for Agents**\\n\\n[Zep](https://www.getzep.com/) is a memory layer designed for AI agents that addresses several of the limitations of the default LangGraph short-term and long-term memory described above while offering additional functionality.\\n\\nZep\\'s memory layer updates as facts change by continually updating a [knowledge graph](https://help.getzep.com/graphiti/graphiti/overview) based on user interactions and business data. During conversations with users, new information is collected, and superseded facts are marked as invalid. Developers can retrieve up-to-date facts from the knowledge graph via a single API call, improving response quality by grounding the LLM in relevant historical data. This eliminates the need to store the entire user conversation and extract facts via prompt engineering techniques.\\n\\nYou can install the Zep cloud library via the following pip command:\\n\\n```\\n%pip install zep-cloud\\n\\n```\\n\\nTo use Zep cloud, import the **Zep** class from the **zep\\\\_cloud.client** module and instantiate it by passing the Zep API key. You can create or retrieve an existing API key from the [Projects](https://app.getzep.com/projects/) section of your Zep cloud.\\n\\n```\\n[object Object] zep_cloud.client [object Object] Zep\\n[object Object] zep_cloud [object Object] Message\\n[object Object] rich\\n\\nZEP_API_KEY = userdata.get([object Object])\\nclient = Zep(\\n    api_key=ZEP_API_KEY,\\n)\\n\\n```\\n\\nTo add memories for a user\\'s session, you need first to add the user and then the session. Users have a one-to-many relationship with sessions. The Zep client\\'s **user.add()** method adds a user to the Zep cloud, and the **memory.add\\\\_session()** method adds a new session. The script below defines a dummy user and the session to add to the Zep cloud.\\n\\n```\\nbot_name = [object Object]\\n\\nuser_name = [object Object]\\nuser_id = user_name + [object Object](uuid.uuid4())[:[object Object]]\\nsession_id = [object Object](uuid.uuid4())\\n\\nclient.user.add(\\n    user_id=user_id,\\n    email=[object Object],\\n    first_name=user_name,\\n    last_name=[object Object],\\n)\\n\\nclient.memory.add_session(\\n    user_id=user_id,\\n    session_id=session_id,\\n)\\n\\n```\\n\\nLet\\'s define a dummy chat history between the user and an agent.\\n\\n```\\nchat_history = [\\n    {\\n        [object Object]: [object Object],\\n        [object Object]: bot_name,\\n        [object Object]: [object Object],\\n        [object Object]: [object Object],\\n    },\\n    {\\n        [object Object]: [object Object],\\n        [object Object]: user_name,\\n        [object Object]: [object Object],\\n        [object Object]: [object Object],\\n    },\\n    {\\n        [object Object]: [object Object],\\n        [object Object]: bot_name,\\n        [object Object]: [object Object],\\n        [object Object]: [object Object],\\n    },\\n    {\\n        [object Object]: [object Object],\\n        [object Object]: user_name,\\n        [object Object]: [object Object],\\n        [object Object]: [object Object],\\n    },\\n    {\\n        [object Object]: [object Object],\\n        [object Object]: bot_name,\\n        [object Object]: [object Object],\\n        [object Object]: [object Object],\\n    },\\n    {\\n        [object Object]: [object Object],\\n        [object Object]: user_name,\\n        [object Object]: [object Object],\\n        [object Object]: [object Object],\\n    },\\n    {\\n        [object Object]: [object Object],\\n        [object Object]: bot_name,\\n        [object Object]: [object Object],\\n        [object Object]: [object Object],\\n    },\\n]\\n\\n```\\n\\nTo populate a Zep session, you must pass a list of **zep\\\\_cloud.Message** type objects. The following script accepts a list of chat history messages and converts them to a list of **zep\\\\_cloud.Message** type objects. You must pass values for the **role\\\\_type**, **role**, and **content** attributes for each **Message** object. Finally, you can add messages to a session using the **memory.add()** method.\\n\\n```\\n[object Object] [object Object]([object Object]) -> [object Object][Message]:\\n\\n    [object Object] [\\n        Message(\\n            role_type=msg[[object Object]],\\n            role=msg.get([object Object], [object Object]),\\n            content=msg[[object Object]],\\n        )\\n        [object Object] msg [object Object] chat_history\\n    ]\\n\\nformatted_chat_messages = convert_to_zep_messages(chat_history)\\n\\nclient.memory.add(\\n    session_id=session_id, messages= formatted_chat_messages\\n)\\n\\n```\\n\\nOnce you have messages in session, you can retrieve all facts about a user from all the sessions using the **user.get\\\\_facts()** method, as shown below.\\n\\n```\\nfact_response = client.user.get_facts(user_id=user_id)\\n[object Object] fact [object Object] fact_response.facts:\\n    rich.[object Object](fact)\\n\\n```\\n\\nIf you are only interested in retrieving facts from a relevant session, you can call the **memory.get()** method, providing it the session ID. Subsequently, you can retrieve session facts using the **relevant\\\\_facts** attribute.\\n\\n```\\nsession_facts = client.memory.get(session_id=session_id)\\nrich.[object Object]([r.fact [object Object] r [object Object] session_facts.relevant_facts])\\n\\n```\\n\\nThe output above shows all relevant facts for a specific user session.\\n\\n### **Putting it all together: a LangGraph agent with Zep**\\n\\nNow that you know how Zep\\'s long-term memory works, let\\'s look at how to develop an agent using LangGraph agents that employ Zep\\'s long-term memory to store user facts. The agent responses will be based on the user facts from Zep\\'s memory.\\n\\nWe will define a graph state that stores messages originating from different nodes, user names, and session IDs. Next, we will create the **search\\\\_facts** tool, which uses the Zep client\\'s **memory.search\\\\_sessions()** method to find user facts relevant to the query.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    messages: Annotated[[object Object], add_messages]\\n    user_name: [object Object]\\n    session_id: [object Object]\\n\\n\\n[object Object]\\n[object Object] [object Object] [object Object]([object Object]):\\n    [object Object]\\n    [object Object] [object Object] client.memory.search_sessions(user_id=state[[object Object]], text=query, limit=limit, search_scope=[object Object])\\n\\n\\ntools = [search_facts]\\ntool_node = ToolNode(tools)\\nmodel = ChatOpenAI(model=[object Object], temperature=[object Object]).bind_tools(tools)\\n\\n```\\n\\nThe **search\\\\_facts** tool is added to the LLM. We also create an object of the **ToolNode** class, which serves as the method for calling tools.\\n\\nSubsequently, we define the **chatbot()** method, which serves as the starting node of the graph. This method fetches relevant user facts for the current session and passes them in the system prompt to the LLM. Note that the system prompt tells the LLM to act as a financial advisor and use the user facts to provide a customized response.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n\\n    memory = client.memory.get(state[[object Object]])\\n    facts_string = [object Object]\\n    [object Object] memory.relevant_facts:\\n        facts_string = [object Object].join([f.fact [object Object] f [object Object] memory.relevant_facts])\\n\\n    system_message = SystemMessage(\\n        content=[object Object]\\n    )\\n\\n    messages = [system_message] + state[[object Object]]\\n\\n    response = model.invoke(messages)\\n\\n    [object Object]\\n    messages_to_save = [\\n        Message(\\n            role_type=[object Object],\\n            role=state[[object Object]],\\n            content=state[[object Object]][-[object Object]].content,\\n        ),\\n        Message(role_type=[object Object], content=response.content),\\n    ]\\n\\n    client.memory.add(\\n        session_id=state[[object Object]],\\n        messages=messages_to_save,\\n    )\\n\\n    [object Object]\\n    [object Object]\\n    [object Object]\\n    state[[object Object]] = trim_messages(\\n        state[[object Object]],\\n        strategy=[object Object],\\n        token_counter=[object Object],\\n        max_tokens=[object Object],\\n        start_on=[object Object],\\n        end_on=([object Object], [object Object]),\\n        include_system=[object Object],\\n    )\\n\\n    [object Object] {[object Object]: [response]}\\n\\n```\\n\\nThe LLM response is added to the Zep memory for the current session using the **memory.add()** method. Zep will automatically fetch facts from these messages. Notice that, unlike the LangChain long-term memory, you don\\'t have to do any prompt engineering to extract and save facts while using the Zep memory-everything is done behind the scenes for you.\\n\\nFinally, we trim the messages in the message state to the last three since we don\\'t need the complete message history. We use Zep user facts to maintain context in the conversation.\\n\\nWe will define a method called **should\\\\_continue** that we will add to the conditional edge to decide whether the LLM should call the **search\\\\_facts** tool or directly send a response to the user.\\n\\nFinally, we define our LangGraph and print the graph\\'s figure.\\n\\n```\\ngraph_builder = StateGraph(State)\\n\\nmemory = MemorySaver()\\n\\n[object Object] [object Object]([object Object]):\\n    messages = state[[object Object]]\\n    last_message = messages[-[object Object]]\\n    [object Object]\\n    [object Object] [object Object] last_message.tool_calls:\\n        [object Object] [object Object]\\n    [object Object]\\n    [object Object]:\\n        [object Object] [object Object]\\n\\ngraph_builder.add_node([object Object], chatbot)\\ngraph_builder.add_node([object Object], tool_node)\\n\\ngraph_builder.add_edge(START, [object Object])\\n\\ngraph_builder.add_conditional_edges([object Object], should_continue, {[object Object]: [object Object], [object Object]: END})\\ngraph_builder.add_edge([object Object], [object Object])\\n\\n\\ngraph = graph_builder.[object Object](checkpointer=memory)\\ndisplay(Image(graph.get_graph().draw_mermaid_png()))\\n\\n```\\n\\nThe graph above is similar to the ReAct agent, where the tools node now calls the **search\\\\_facts** tool. Next, we will define the **extract\\\\_messages()** function that extracts messages from the response returned by the **graph.invoke()** method.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    output = [object Object]\\n    [object Object] message [object Object] result[[object Object]]:\\n        [object Object] [object Object](message, AIMessage):\\n            role = [object Object]\\n        [object Object]:\\n            role = result[[object Object]]\\n        output += [object Object]\\n    [object Object] output.strip()\\n\\n```\\n\\nFinally, we define the **graph\\\\_invoke()** function, which accepts user query, user name, and session name (**thread\\\\_id** in the following script) and returns the LangGraph agent\\'s response.\\n\\n```\\n[object Object] [object Object]([object Object]):\\n    r = graph.invoke(\\n        {\\n            [object Object]: [\\n                {\\n                    [object Object]: [object Object],\\n                    [object Object]: message,\\n                }\\n            ],\\n            [object Object]: user_name,\\n            [object Object]: thread_id,\\n        },\\n        config={[object Object]: {[object Object]: thread_id}},\\n    )\\n\\n    [object Object] ai_response_only:\\n        [object Object] r[[object Object]][-[object Object]].content\\n    [object Object]:\\n        [object Object] extract_messages(r)\\n\\n```\\n\\nTo test the agent, we will create a new session for a dummy user and add the user and the session to the Zep cloud memory.\\n\\n```\\nuser_name = [object Object] + uuid.uuid4().[object Object][:[object Object]]\\nsession_id = uuid.uuid4().[object Object]\\n\\nclient.user.add(user_id=user_name)\\nclient.memory.add_session(session_id=session_id,\\n                          user_id=user_name)\\n\\n```\\n\\nNext, we will execute a **while** loop that accepts user inputs; calls the **graph\\\\_invoke()** method using the user name, session ID, and user input; and prints the agent\\'s response on the console.\\n\\n```\\n[object Object] [object Object]:\\n\\n    user_input = [object Object]([object Object])\\n\\n    [object Object] user_input.lower() == [object Object]:\\n        [object Object]([object Object])\\n        [object Object]\\n\\n    [object Object]\\n    r = graph_invoke(\\n        user_input,   [object Object]\\n        user_name,    [object Object]\\n        session_id,   [object Object]\\n    )\\n\\n    [object Object]\\n    [object Object]([object Object], r)\\n\\n```\\n\\nLet\\'s test the agent by providing it with some information.\\n\\nYou can check the session to see the facts the agent has stored about the user.\\n\\n```\\nsession_facts = client.memory.get(session_id=session_id)\\nrich.[object Object]([r.fact [object Object] r [object Object] session_facts.relevant_facts])\\n\\n```\\n\\nLet\\'s ask a question to verify that the agent can access the user facts.\\n\\nYou can see that the agent has all the information about the user. Zep memory stores important facts about the user, which you can use to avoid hallucinations and improve the personalized customer experience.\\n\\n## **Guidelines for building LangGraph agents**\\n\\nHere are some of the guidelines you should follow while working with LangChain agents:\\n\\n* Remember that LangGraph was built by the creators of LangChain but can be used without LangChain. It is a more powerful framework for building AI Agents because LangGraph allows you to define flows that involve cycles, which is essential for most agentic architectures.\\n* Tools are integral to LangGraph agents, but they should not be overused. Only implement tools to fetch information that an LLM agent does not possess by default.\\n* The tool description should include as much detail as possible. This will help the agent select the correct tool for the task.\\n* An agent is only as good as its context. Depending on your requirements, store all the relevant information from past conversations in short- or long-term memory.\\n* Third-party SDKs (like [Zep](https://help.getzep.com/sdks)) can make your life easier by automatically managing memory and storing conversation facts, permitting a personalized user experience.\\n\\n## **Last thoughts**\\n\\nLangGraph agents provide a flexible way to develop complex LLM applications. This article explains LangGraph agents and how to implement them with detailed examples. Adding external tools enables the agents to retrieve external information, and persisting memory across conversations enables the LangGraph agent to provide contextualized responses.\\n\\nZep\\'s long-term memory stores conversation context and user facts. Zep is fast and highly effective in extracting relevant user facts, resulting in better and more personalized user responses. Incorporating Zep\\'s long-term memory helped the agent remember user facts, allowing it to provide personalized responses.\\n\\n[### A Developer\\'s Guide to the MCP](/ai-agents/developer-guide-to-mcp/)[### LLM Evaluation Framework: Evaluating LLM-based Applications](/ai-agents/llm-evaluation-framework/)\\n\\n[Back to All Guides](/ai-agents/)'}, {'url': 'https://www.reddit.com/r/LangChain/comments/1frgiah/tutorial_for_langgraph_any_source_will_help/', 'title': 'Tutorial for Langgraph , any source will help . : r/LangChain', 'content': 'Tutorial for Langgraph , any source will help . : r/LangChain : r/LangChain Open menu Open navigationGo to Reddit Home Image 1: r/LangChain icon Go to LangChain r/LangChain Image 2: r/LangChain iconr/LangChain LangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. Tutorial for Langgraph , any source will help . TL;DR : Need some good resource/Tutorial to understand langgraph apart form documentation . Tutorials and resources for Langgraph Langgraph tutorial for beginners Langchain and Langgraph tutorial comparison New to Reddit? *   Reddit reReddit: Top posts of September 28, 2024 * * * *   Reddit reReddit: Top posts of September 2024 * * * *   Reddit reReddit: Top posts of 2024 * * *', 'score': 0.7574541, 'raw_content': \"Tutorial for Langgraph , any source will help . : r/LangChain\\n\\n===============\\n[Skip to main content](https://www.reddit.com/r/LangChain/comments/1frgiah/tutorial_for_langgraph_any_source_will_help/#main-content)Tutorial for Langgraph , any source will help . : r/LangChain\\n\\nOpen menu Open navigation[](https://www.reddit.com/)Go to Reddit Home\\n\\nr/LangChain A chip A close button\\n\\n[Log In](https://www.reddit.com/login/)Log in to Reddit\\n\\nExpand user menu Open settings menu\\n\\n[![Image 1: r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96:96,smart&s=c38d2f77c32c99847a3971d478fe17697ec497e0) Go to LangChain](https://www.reddit.com/r/LangChain/)\\n\\n[r/LangChain](https://www.reddit.com/r/LangChain/)\\n\\n![Image 2: r/LangChain icon](https://styles.redditmedia.com/t5_7tpn6r/styles/communityIcon_vw08a423ptxa1.png?width=96&height=96&frame=1&auto=webp&crop=96:96,smart&s=c38d2f77c32c99847a3971d478fe17697ec497e0)[r/LangChain](https://www.reddit.com/r/LangChain/)\\n\\nLangChain is an open-source framework and developer toolkit that helps developers get LLM applications from prototype to production. It is available for Python and Javascript at https://www.langchain.com/.\\n\\n* * *\\n\\n73K Members Online\\n\\n•1 yr. ago\\n\\n[deleted]\\n\\nTutorial for Langgraph , any source will help .\\n===============================================\\n\\n[Tutorial](https://www.reddit.com/r/LangChain/?f=flair_name%3A%22Tutorial%22)\\n\\nI've been trying to make a project using **Langgraph** by connecting agents via concepts of graphs . But the thing is that the documentation is not very friendly to understand , nor the tutorials that i found were focusing on the functionality of the classes and modules . Can you gyus suggest some resources to refer so as to get an idea of how things work in langgraph .\\n\\nTL;DR : Need some good resource/Tutorial to understand langgraph apart form documentation .\\n\\n Read more \\n\\n Share \\n\\nRelated Answers Section\\n=======================\\n\\nRelated Answers\\n\\n[Tutorials and resources for Langgraph](https://www.reddit.com/answers/38d8e04b-93b3-4475-abd3-c6f25ac6e76c/?q=Tutorials%20and%20resources%20for%20Langgraph&source=PDP)\\n\\n[Langgraph tutorial for beginners](https://www.reddit.com/answers/ea336a55-4114-4e68-ae59-94d724e9f1f5/?q=Langgraph%20tutorial%20for%20beginners&source=PDP)\\n\\n[Getting started with Langgraph](https://www.reddit.com/answers/9e0e57c8-e7a2-4555-81b4-1cf8517c322c/?q=Getting%20started%20with%20Langgraph&source=PDP)\\n\\n[Langchain and Langgraph tutorial comparison](https://www.reddit.com/answers/b8843c1d-d2bc-450e-9360-18999ffe172d/?q=Langchain%20and%20Langgraph%20tutorial%20comparison&source=PDP)\\n\\n[Langgraph agent framework overview](https://www.reddit.com/answers/0fc452a5-3f50-452e-babd-dad8f3cb2117/?q=Langgraph%20agent%20framework%20overview&source=PDP)\\n\\nNew to Reddit? \\nCreate your account and connect with a world of communities.\\n\\nContinue with Google Continue with Google. Opens in new tab\\n\\n Continue with Email \\n\\n Continue With Phone Number \\n\\nBy continuing, you agree to our[User Agreement](https://www.redditinc.com/policies/user-agreement)and acknowledge that you understand the[Privacy Policy](https://www.redditinc.com/policies/privacy-policy). \\n\\n Public \\n\\nAnyone can view, post, and comment to this community\\n\\nTop Posts\\n---------\\n\\n* * *\\n\\n*   [Reddit reReddit: Top posts of September 28, 2024 * * *](https://www.reddit.com/posts/2024/september-28-1/global/)\\n*   [Reddit reReddit: Top posts of September 2024 * * *](https://www.reddit.com/posts/2024/september/global/)\\n*   [Reddit reReddit: Top posts of 2024 * * *](https://www.reddit.com/posts/2024/global/)\\n\\n[Reddit Rules](https://www.redditinc.com/policies/content-policy)[Privacy Policy](https://www.reddit.com/policies/privacy-policy)[User Agreement](https://www.redditinc.com/policies/user-agreement)[Accessibility](https://support.reddithelp.com/hc/sections/38303584022676-Accessibility)[Reddit, Inc. © 2025. All rights reserved.](https://redditinc.com/)\\n\\nExpand Navigation Collapse Navigation\\n\\n![Image 3](https://id.rlcdn.com/472486.gif)\\n\"}]\n"
     ]
    }
   ],
   "source": [
    "# 도구 실행\n",
    "print(tool.invoke(\"LangGraph Tutorial\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM + Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State 정의 \n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 정의 \n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM + Tools \n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    answer = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [answer]} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 초기화 \n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12add6d10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노드 연결\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Node \n",
    "\n",
    "- 도구가 호출될 경우 실제로 실행할 수 있는 함수 \n",
    "- 가장 최근의 메시지를 확인하고 메시지에 `tool_calls`가 포함되어 있으면 도구를 호출하는 `BasicToolNode` 구현 \n",
    "- 아래 코드 블럭은 이해를 돕기 위해 직접 구현. 이후에는 LangGraph의 ToolNode로 대체함 \n",
    "- [Reference]https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12add6d10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"Run tools requested in the last AIMessage node\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        # 도구 리스트\n",
    "        # 주어진 도구 리스트를 이름(name)을 기준으로 딕셔너리 형태로 변환\n",
    "        self.tools_list = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        # 메시지가 존재할 경우 가장 최근 메시지 1개 추출\n",
    "        # inputs 딕셔너리에서 \"messages\" 키의 값을 가져옴 (없으면 빈 리스트 반환)\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "\n",
    "        # 도구 실행 결과를 저장할 리스트\n",
    "        outputs = []\n",
    "\n",
    "        # message 객체 안의 tool_calls 속성에는 LLM이 호출 요청한 도구 정보가 리스트로 저장되어 있음\n",
    "        for tool_call in message.tool_calls:\n",
    "            # 도구 이름으로 실제 도구 인스턴스를 가져와서, 전달된 인자(args)를 사용해 실행\n",
    "            tool_result = self.tools_list[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "\n",
    "            # 도구 호출 후 결과 저장\n",
    "            # 도구 실행 결과를 문자열(JSON 형식)로 변환하여 ToolMessage 객체로 저장\n",
    "            outputs.append(\n",
    "                # 도구 호출 결과를 메시지로 저장\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(\n",
    "                        tool_result, ensure_ascii=False\n",
    "                    ),  # 도구 호출 결과를 문자열로 변환\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "# 도구 노드 생성\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "\n",
    "# 그래프에 도구 노드 추가\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Edge\n",
    "\n",
    "- 일반적으로 \"if\" 문을 포함하여 현재 그래프 상태에 따라 다른 노드로 라우팅 \n",
    "- 이러한 함수는 현재 그래프 `state`를 받아 다음에 호출할 Node 를 나타내는 **문자열 또는 문자열 목록** 을 반환\n",
    "\n",
    "- 아래에서는 `route_tools`라는 라우터 함수를 정의하여 챗봇의 출력에서 `tool_calls`를 확인\n",
    "- 이 함수를 `add_conditional_edges`를 호출하여 그래프에 제공하면, `chatbot` 노드가 완료될 때마다 이 함수를 확인하여 다음으로 어디로 갈지 결정\n",
    "- 조건은 도구 호출이 있으면 `tools`로, 없으면 `END`로 라우팅\n",
    "\n",
    "- [Reference] tools_condition\n",
    "https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(\n",
    "    state: State,\n",
    "):  \n",
    "    # state에서 \"messages\" 키를 통해 메시지 리스트를 가져옴\n",
    "    # messages는 지금까지 주고받은 대화 기록 (주로 AIMessage, HumanMessage 등)\n",
    "    if messages := state.get(\"messages\", []):\n",
    "        ai_message = messages[-1] # 가장 최근 AI 메시지 추출\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "\n",
    "    # 가장 최근 메시지에 tool_calls 속성이 있고, 실제 호출 요청이 하나 이상 존재하면\n",
    "    # 도구 호출이 있는 경우 \"tools\" 반환\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12add6d10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_conditional_edges(\n",
    "    source=\"chatbot\",\n",
    "    path=route_tools,\n",
    "    path_map={\n",
    "        \"tools\":\"tools\",\n",
    "        END:END,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x12add6d10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "              *               \n",
      "              *               \n",
      "              *               \n",
      "        +---------+           \n",
      "        | chatbot |           \n",
      "        +---------+           \n",
      "         *         .          \n",
      "       **           ..        \n",
      "      *               .       \n",
      "+-------+         +---------+ \n",
      "| tools |         | __end__ | \n",
      "+-------+         +---------+ \n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='SK AX에서 진행하는 SKALA에 대해서 검색해 주세요' id='d4064aa4-f82f-4142-9b52-05ac5f605ea1'\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_OVeaUgNoTCO5TE0PRTHrABgu', 'function': {'arguments': '{\"query\":\"SK AX SKALA\"}', 'name': 'tavily_web_search'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 103, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-f5a527a8-a155-478f-b6ea-abc498171e5e-0' tool_calls=[{'name': 'tavily_web_search', 'args': {'query': 'SK AX SKALA'}, 'id': 'call_OVeaUgNoTCO5TE0PRTHrABgu', 'type': 'tool_call'}] usage_metadata={'input_tokens': 103, 'output_tokens': 20, 'total_tokens': 123}\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='[{\"url\": \"http://skala.co.kr/\", \"title\": \"SKALA, SK AX AI Leader Academy\", \"content\": \"SKALA(SK AI Leader Academy)는 SK AX의 채용연계형 AI\\xa0서비스 개발 과정으로, 약 5개월간 압축적인 SW, Data·AI 교육 및 팀 프로젝트를\\xa0통해\\xa0AI 서비스\\xa0개발에 필요한 지식과 경험을 교육한 후 SK AX 및\\xa0자회사의 신입구성원으로 채용하기\\xa0위한 교육입니다. SKALA는 SK AX 및 자회사의 신입사원을 채용하기\\xa0위한 채용연계형 교육으로, **과정 종료 후 SKALA****이수자 대상 서류전형 면제 및 채용을 우대하는****특별****전형이****진행****됩니다.** | ※ 미취업 청년 및 대학생\\xa0대상 지원되는 정부 재정\\xa0지원 프로그램에 참여 중인 경우 중복수급이 불가할 수\\xa0있습니다. ※ 단, 최종 합격의 의미는 교육 입과 합격을 의미하며, SK AX 또는 자회사에 대한 채용 합격을 의미하지 않습니다. 교육 수강 및 중도 퇴소 이력이 있는 경우 아래를 참고해 교육비 지원 가능 여부 및 금액을 사전에 확인 후 지원 부탁드립니다.\", \"score\": 0.91901255, \"raw_content\": \"[게시물 알림](javascript:;)\\\\n[내 글 반응\\\\n\\\\n내가 작성한 게시물이나 댓글에 다른 사람이 댓글이나 답글을 작성하면 알려줍니다.](javascript:;)\\\\n[공지사항\\\\n\\\\n사이트에서 보내는 중요한 공지를 실시간으로 알려줍니다.](javascript:;)\\\\n\\\\n* [Alarm](javascript:;)\\\\n* [마이페이지](/login?back_url=L3Nob3BfbXlwYWdl&type=mypage)\\\\n  [로그아웃](/logout.cm?back_url=Lw%3D%3D)\\\\n\\\\nSKALA(SK AI Leader Academy)는 SK AX의 채용연계형 AI\\xa0서비스 개발 과정으로, 약 5개월간 압축적인 SW, Data·AI 교육 및 팀 프로젝트를\\xa0통해\\xa0AI 서비스\\xa0개발에 필요한 지식과 경험을 교육한 후 SK AX 및\\xa0자회사의 신입구성원으로 채용하기\\xa0위한 교육입니다.\\\\n\\\\n**우리와 함께 하게 될 구성원을 육성하는 마음으로****전 과정을 직접 만들고, 강의하며, 채용합니다.**\\\\n\\\\n**K-digital Training | 100% 국비지원**\\\\n\\\\n고용노동부, 대한상공회의소와 함께 합니다.\\\\n\\\\nSKALA는 SK AX 및 자회사의 신입사원을 채용하기\\xa0위한 채용연계형 교육으로, **과정 종료 후 SKALA****이수자 대상 서류전형 면제 및 채용을 우대하는****특별****전형이****진행****됩니다.**\\\\n\\\\nAI 서비스를 구현하기 위해서는 SW, Data, AI만이\\xa0아니라, **각각의 지식들에 대한 이해를 기반으로 여러****기술을 연결해서 다룰 수 있어야 합니다.**\\\\n\\\\n본 과정은 AI 서비스 개발을 위해, MLMachine Learning\\xa0/ DLDeep Learning과 LLMLarge Language Model을 융합하여 백엔드\\xa0모델로 서빙하고, 이를 최종적으로 프론트엔드를 통해 사용자에게\\xa0반응형으로 제공하는 All-in-One\\xa0학습 경험을 제공합니다.\\\\n\\\\n대기업의 이름으로 홍보되는 과정은 많지만 실제 교육은 별도의 업체에서 강의, 운영하는 경우가 많습니다.\\\\n\\\\nSKALA는 기술교과부터 특강까지 모든 교육 내용을 **SK AX 현직 기술·교육 전문가가 직접 개발하고 강의**해,\\xa0SK AX와 자회사의 신입사원에게 요구되는 기술과\\xa0역량을 갖출 수 있도록 가이드하며,\\xa0실제 시장이\\xa0필요로\\xa0하는 기술과 노하우를 보다 생생하게 전수합니다.\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| |  | | --- | | SKALA는 SK AX 및 자회사의 신입사원을 채용하기 위한 채용연계형 교육으로, 과정 종료 후 SKALA 이수자 대상 서류 전형 면제 및 채용을 우대하는 특별 전형이 진행됩니다. | |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| |  | | --- | | AI 서비스를 구현하기 위해서는 SW, Data, AI만이 아니라,\\xa0각각의 지식들에 대한 이해를 기반으로 여러 기술을 연결해서 다룰 수 있어야 합니다.   본 과정은 AI 서비스 개발을 위해 MLMachine Learning\\xa0/ DLDeep Learning\\xa0과 LLMLarge Language Model\\xa0을 융합해\\xa0백엔드 모델로 서빙하고, 이를 프론트엔드를 통해 사용자에게 반응형으로 제공하는\\xa0All-in-One 학습 경험을 제공합니다. | |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| |  | | --- | | 대기업의 이름으로 홍보되는 과정은 많지만 실제 교육은 별도의 업체에서 강의, 운영하는 경우가 많습니다.  SKALA는 기술교과부터 특강까지 모든 교육 내용을 SK AX에 재직하는 현직 기술·교육 전문가가 직접 개발 하고 강의해, SK AX와 자회사의 신입사원에게 요구되는 기술과 역량을 갖출 수 있도록 가이드하며,\\xa0 실제 시장에서 필요로 하는 기술과 노하우를 보다 생생하게 전수합니다. | |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **01.** 교육비 걱정은 넣어두세요 **교육**+**교재**+**실습비 전액****무료!**  ~~10,531,987원~~ → 0원 |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **02.** 출석만 해도 최대 316,000원 **매월 훈련장려금 지원**  ※ 단,\\xa0정부 재정지원 프로그램에\\xa0참여 중인 경우 중복수급이 불가할 수\\xa0있습니다. |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **03.** 식사는 든든히 챙겨먹을 수 있게\\xa0 **점심식사 및 저녁식사 제공**  ※ 저녁식사는 팀 프로젝트가\\xa0진행되는 저녁 연장 교육기간에 한해 제공됩니다. |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **04.** 교육 종료시까지 무상 대여\\xa0 **교육용 노트북 제공** |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **05.** SKALA의 불은 꺼지지 않으니까\\xa0 **강의장 야간 개방 (~22시)** |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **06.** 실전 경험과 기술로 무장된 **SK AX 현직자** **프로젝트 멘토링 제공** |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **07.** 완주를 축하합니다!\\xa0 **인당 100만원** **수료 축하금 지급** |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **08.** 총 상금 750만원 **프로젝트 우수팀 상금 지급** |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **09.** 취업을 위한 Tip 대방출\\xa0 **SK AX 채용 전문가의** **취업 지원** |  |\\\\n\\\\n**01.**\\\\n\\\\n교육비 걱정은 넣어두세요  \\\\n**교육 + 교재 + 실습비****전액 무료!**\\\\n\\\\n~~**10,531,987원**~~**→ 0원**\\\\n\\\\n**02.**\\\\n\\\\n출석만 해도 지원되는 현금 혜택 💸  \\\\n**월 최대 316,000원 훈련장려금 지급**\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| ※ 미취업 청년 및 대학생\\xa0대상 지원되는 정부 재정\\xa0지원 프로그램에 참여 중인 경우 중복수급이 불가할 수\\xa0있습니다. |  |\\\\n\\\\n**03.**\\\\n\\\\n식사는 든든히 챙겨먹을 수 있게  \\\\n**점심식사 및 저녁식사 제공**\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| ※ 저녁식사는 팀 프로젝트가 진행되는 저녁 연장\\xa0교육기간에 한해 제공됩니다. |  |\\\\n\\\\n**04.**\\\\n\\\\n교육 종료시까지 무상 대여\\\\n\\\\n**교육용 노트북 제공**\\\\n\\\\n**05.**  \\\\nSKALA의 불은 꺼지지 않으니까 \\xa0\\\\n\\\\n**강의장 야간 개방 (~22시)**\\\\n\\\\n**06.**\\\\n\\\\n실전 경험과 기술로 무장된  \\\\n**SK AX 현직자 프로젝트 멘토링 제공**\\\\n\\\\n**07.**\\\\n\\\\n완주를 축하합니다!\\\\n\\\\n**인당 100만원 수료 축하금 지급**\\\\n\\\\n**08.**\\\\n\\\\n총 상금 750만원\\\\n\\\\n**프로젝트 우수팀 상금 지급**\\\\n\\\\n**09.**\\\\n\\\\n취업을 위한 Tip 대방출\\\\n\\\\n**SK AX 채용 전문가의 취업 지원**\\\\n\\\\n---\\\\n\\\\n---\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **Course 1.****SW Fundamental** | . Front-end (HTML, CSS, JavaScript, Vue.js, Node.js) . Back-end (Java, SpringBoot, Rest API) . 데이터베이스 (데이터베이스 모델링, SQL) . Cloud, K8S, DevOps  . Mini Project |\\\\n| **Course 2.****Data · AI** | . Python Programming . 데이터 분석, Machine Learning, Deep Learning . 생성형 AI 및 LLM의 이해 . 생성형 AI 서비스 개발의 이해 (LangChain, RAG, Vector DB) . AI Agent 설계 . Mini Project |\\\\n| **Course 3.****AI Team Project** | . 프로젝트 관리방법론 (요구사항 분석/정의, 일정/범위/품질/리스크/이슈관리) . AI 서비스 개발 주제의 Team Project 수행 . 프로젝트 멘토링 |\\\\n| **Special Course.****특강** | . 산업별 IT 프로젝트 수행사례  . IT 업계/마켓 트렌드 . Biz. Skill . 취업 기본 소양 |\\\\n\\\\n---\\\\n\\\\n---\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **Course 1. SW Fundamental** | |\\\\n| . Front-end\\xa0(HTML, CSS, JavaScript, Vue.js, Node.js) . Back-end (Java, Spring Boot, Rest API)  . 데이터베이스 (데이터베이스 모델링, SQL)  . Cloud, K8S, DevOps . Mini-Project | |\\\\n|  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **Course 2. Data·AI** | |\\\\n| . Python Programming . 데이터 분석, MLMachine Learning, DLDeep Learning . 생성형 AI 및 LLM의 이해 . 생성형 AI 서비스 개발의 이해\\xa0(LangChain, RAG, Vector DB) . AI Agent 설계  . Mini-Project | |\\\\n|  |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **Course 3. AI Team Project** | |\\\\n| . 프로젝트 관리방법론 . AI 서비스 개발 주제의 팀 프로젝트 수행\\xa0 . 프로젝트 멘토링 | |\\\\n|  |  |\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| **Special Course. 특강** | |\\\\n| . 산업별 IT 프로젝트 수행사례 . IT 업계 및 마켓 트렌드  . Biz. Skill . 취업 기본 소양 | |\\\\n|  |  |\\\\n\\\\n교육기간\\\\n\\\\n**약 5개월**※ 2기 진행 일정: 7.21(월) ~ 12.24(수)\\\\n\\\\n교육시간\\\\n\\\\n**주중 전일 9:00~18:00 (8시간)**※ AI Team Project 기간에는 2시간 저녁 연장 진행\\\\n\\\\n진행방식\\\\n\\\\n**교육과정 전 기간****오프라인 진행**\\\\n\\\\n진행방식\\\\n\\\\n**SK AX 본사 교육장**※ 본사 소재지: 분당 정자동\\xa0\\\\n\\\\n(성남대로 343번길 9 SK u-타워)\\\\n\\\\n교육기간\\\\n\\\\n교육시간\\\\n\\\\n진행방식\\\\n\\\\n교육장소\\\\n\\\\n**약 5개월**  \\\\n  \\\\n  \\\\n※ 2기 진행 일정:   \\\\n7.21(월) ~ 12.24(수)\\\\n\\\\n**주중 전일**\\\\n\\\\n**9:00~18:00 (8시간)**\\\\n\\\\n※ AI Team Project 진행 기간에는\\xa02시간 저녁 연장 진행\\\\n\\\\n교육과정 전 기간  \\\\n**100%****오프라인**\\\\n\\\\n**SK AX 본사 교육장**\\\\n\\\\n※ 본사 소재지: 분당 정자동\\xa0\\\\n\\\\n(성남대로 343번길 9\\xa0SK u-타워)\\\\n\\\\n* 전체\\\\n* 지원\\\\n* 교육\\\\n* 채용연계\\\\n\\\\n#### 채용연계 채용연계의 의미가 무엇인가요?\\\\n\\\\n과정 종료 후 진행되는 신입사원 공채에서 서류 및 AICT 전형을 면제받는 것을 의미하며, \\xa0공채 지원 시 최종 입사 여부는 서류전형 면제 이후 별도의 채용 절차를 통해 결정됩니다.\\xa0\\\\n\\\\n이와 더불어 과정 이수 후 1년간 추가적으로 SK AX 및 자회사의 공채에서 서류전형을 면제받을 수 있습니다.\\\\n\\\\n#### 지원 2기 선발 프로세스가 진행되는 일정이 어떻게 되나요? 최종 합격은 언제쯤 결정될까요?\\\\n\\\\n2기 선발 프로세스 및 일정은 아래와 같이 진행되며, 상세 일정은 전형별 합격자 대상 안내 예정입니다.\\xa0\\\\n\\\\n|  |  |  |  |  |\\\\n| --- | --- | --- | --- | --- |\\\\n| **지원접수 \\xa0 →** 6.2(월) ~ 6.15(일) | **서류 검토 \\xa0 →** 6월 중순 | **S****KCT(인성) 응시 \\xa0 \\xa0→**  6월 말 ※ 기간 내 온라인 자율 응시 | **면접****→**  6월 말 ~ 7월 초 ※ 비대면 진행 | **최종 합격** 7월 초 |\\\\n\\\\n※ 단, 최종 합격의 의미는 교육 입과 합격을 의미하며, SK AX 또는 자회사에 대한 채용 합격을 의미하지 않습니다.\\\\n\\\\n#### 지원 전공에 상관없이 지원이 가능한가요?\\\\n\\\\nSKALA는 AI 서비스 개발자로 성장하고자 하는 열정과 의지를 최우선으로 고려하므로 프로그래밍에 대한 지식이 없는 비전공자도 지원 가능합니다.\\\\n\\\\n#### 지원 지원하는 데 학력 제한이 있나요?\\\\n\\\\n학력 및 전공에 별도 제한을 두지 않으며, AI 서비스 개발자로 성장하고자 하는 열정과 의지를 최우선으로 고려합니다.\\\\n\\\\n#### 채용연계 과정 이수 후 채용으로 연계되는 회사가 어디인가요?\\\\n\\\\nSK주식회사 \\xa0AX와 그 자회사 ATS(애커튼테크놀로지서비스) 입니다.   \\\\n각 회사에 대한 상세한 정보는 아래 홈페이지를 참고해주세요.\\xa0\\\\n\\\\n🔗 [**SK주식회사 AX 홈페이지 바로가기**](https://www.skax.co.kr)**[↗](https://www.skcc.com)  \\\\n🔗**[**ATS(애커튼테크놀로지서비스) 홈페이지 바로가기****↗**](https://www.ackertonts.com/)\\\\n\\\\n※ 단, 과정 이수가 채용을 보장하는 것은 아니며, 과정 이수 후 별도의 절차를 거쳐 채용 여부가 결정됩니다.\\\\n\\\\n#### 지원 내일배움카드 발급 자격이 어떻게 되나요?\\\\n\\\\n국민내일배움카드는 아래 사항에 해당되는 분들을 제외한 국민 누구나 신청 가능합니다.  \\\\n\\xa0  \\\\n**※ 국민내일배움카드 지원 제외 대상:**  \\\\n- \\xa0공무원, 사립학교 교직원  \\\\n- \\xa075세 이상인 사람  \\\\n- \\xa0대규모 기업 근로자로서, 월 임금 300만원 이상이고, 만 45세 미만인 사람  \\\\n- \\xa0월 소득 500만원 이상의 특수형태근로종사자\\xa0  \\\\n\\xa0 \\xa0 \\\\\\\\* 특수형태 근로종사자: 사업주와 도급(위탁) 계약을 하고 근로자와 유사하게 서비스를 제공하는 사람으로 보험모집인, 건설기계 소유 기사, 학습지 교사,\\xa0  \\\\n\\xa0 \\xa0 \\xa0 \\xa0골프장 캐디, 택배 기사, 퀵서비스 기사, 대리운전 기사, 대출 모집인, 신용카드 회원 모집인, 방문 판매원, 강사, 기타 프리랜서 등을 말합니다.  \\\\n- \\xa0사업 기간이 1년 미만 이거나 월 소득이 300만원 이상인 법인대표  \\\\n- \\xa0사업 기간이 1년 미만이거나 연 매출 4억 이상의 자영업자  \\\\n- \\xa0월 소득이 300만원 이상인 비영리단체 대표  \\\\n- \\xa0졸업까지 남은 수업연한이 2년 이상인 대학/대학원 재학생, 고등학교 1~2학년생  \\\\n- \\xa0생계급여를 받고 있는 사람(조건부 수급자 또는 조건부과 유예자는 지원 가능)  \\\\n- \\xa0다른 부처 또는 지방자치단체로부터 교육/훈련비를 지원받고 있는 사람  \\\\n- \\xa0지원·융자·수강제한 기간인 부정수급자  \\\\n- 부정행위에 따른 지원금을 반환하지 않은 사람  \\\\n- \\xa0기타 지원 필요성이 인정되지 않는 사람\\\\n\\\\n🔗 [**국민내일배움카드 제도 안내 홈페이지 바로가기 ↗**](https://www.work24.go.kr/cm/c/f/1100/selecSystInfo.do?currentPageNo=1&recordCountPerPage=12&systClId=SC00000004&systId=SI00000351)\\\\n\\\\n#### 지원 여러 개의 K-digital Training 과정에 중복 지원이 가능한가요?\\\\n\\\\n여러 개의 K-digital Training 과정에 중복으로 지원은 가능하나, 중복 수강은 불가합니다.  \\\\nK-digital Training 과정은 내일배움카드제도로 국비지원을 통해 인당 1회에 한하여 지원됩니다.\\\\n\\\\n#### 지원 국민취업지원제도와 병행할 수 있나요?\\\\n\\\\n네, 병행할 수 있습니다.  \\\\n단, 수강을 위해 국민취업지원제도 담당자를 통해 HRD-Net에서 수강신청 하셔야 하니 \\\\\"**지원 전\\\\\"**담당자와 반드시 상의하세요.  \\\\n  \\\\n**🔗 [국민취업지원제도 안내 사이트 바로가기 ↗](https://www.work24.go.kr/ua/z/z/1300/selectEmssRqutIntro.do)**\\\\n\\\\n#### 지원 국비지원과정을 수강했거나 중도 퇴소한 이력이 있는 경우 지원이 가능한가요?\\\\n\\\\n**K-디지털 트레이닝** 또는 **4차산업인력양성**으로 구분되는 국비지원과정을 수강했거나 중도 퇴소한 이력이 있는 경우,\\xa0  \\\\n이외의 국비지원과정으로 분류되는 교육을 수강한 경우라도 국민내일배움카드 잔액이 0원인 경우 수강이 불가할 수 있습니다.  \\\\n  \\\\n교육 수강 및 중도 퇴소 이력이 있는 경우 아래를 참고해 교육비 지원 가능 여부 및 금액을 사전에 확인 후 지원 부탁드립니다.\\\\n\\\\n**※ 국민내일배움카드를 활용한 수강 이력 확인 방법**  \\\\n① **고용24**[**↗**](https://www.work24.go.kr/cm/main.do)\\xa0접속 후 \\\\\"나의수강이력\\\\\"에서 수강했던 과정명 확인  \\\\n② 해당 과정명을 검색해 검색결과로 뜨는 과정명에 태그되어 있는 사업명 확인  \\\\n③ **K-디지털 트레이닝**\\xa0 또는 \\xa0**4차산업인력양성**이 태그되어 있을 경우 수강 또는 중도 퇴소 이력이 있는 것  \\\\n  \\\\n**※ 국민내일배움카드 잔액 확인**\\xa0  \\\\n① \\xa0[**고용24↗**](https://www.work24.go.kr/cm/main.do) 접속 후 마이페이지 → 훈련관리 → 국민내일배움카드 클릭\\xa0  \\\\n② 카드발급/사용내역 → 카드사용내역 → 지원잔액 확인\\xa0  \\\\n  \\\\n**※ 교육비 지원 관련 문의처**  \\\\n① 고용노동부 콜센터(국번없이 1350)  \\\\n② 관할 고용센터 또는 고용복지플러스센터   \\\\n③ 대한상공회의소 담당자 02-6050-3929\\\\n\\\\n#### 교육 교육과정은 평일에만 진행되나요?\\\\n\\\\n네, 교육과정은 주중 평일에만 진행되며, 주말과 공휴일에는 진행되지 않습니다.\\xa0\\\\n\\\\n단, 자연재해 및 재난, 감염병과 같은 비상상황이 발생할 경우 부득이하게 교육 일정이 변경될 수 있으며  \\\\n필요시 주말 및 공휴일에 교육이 진행될 수 있습니다.\\\\n\\\\nSKALA는 고용노동부에서 실시하는 K-디지털 트레이닝 사업의 일환으로 실시되는 교육 과정으로,  \\\\n국비 지원을 통해 교육비, 교재비, 실습비 등 교육에 필요한 비용은 전액 무료입니다.\\\\n\\\\n단, 국비 지원을 받기 위해서는 **국민내일배움카드**를 발급받을 수 있어야 하며,   \\\\nK-디지털 트레이닝 또는 4차산업인력양성 과정을 수강한 이력이 없고, 보유하고 있는 내일배움카드에 잔액이 남아있어야 합니다.\\xa0\\\\n\\\\n국비 지원이 아닌, 자비부담금 납부를 통해서는 수강이 불가합니다.\\xa0\\\\n\\\\n**🔗 [국민내일배움카드 제도 안내 홈페이지 바로가기](https://www.work24.go.kr/cm/c/f/1100/selecSystInfo.do?currentPageNo=1&recordCountPerPage=12&systClId=SC00000004&systId=SI00000351)\\xa0↗  \\\\n🔗\\xa0[국민내일배움카드를 활용한 K-디지털 트레이닝 참여 안내 홈페이지 바로가기](https://www.work24.go.kr/cm/c/f/1100/selecSystInfo.do?currentPageNo=1&recordCountPerPage=10&upprSystClId=&systClId=SC00000197&systId=SI00000423&systCnntId=CI00001188)****↗**\\\\n\\\\nFAQ 외 문의는\\xa0아래\\xa0문의처로 문의해주세요.\\\\n\\\\nE-Mail\\u3000skala@sk.com\\\\n\\\\n[카카오톡 채널\\u3000@skala](http://pf.kakao.com/_ReLln/chat)\\\\n\\\\n**FAQ 외 문의는 아래 문의처로 문의해 주세요.**\\\\n\\\\n✉\\xa0E-Mail \\xa0[skala@sk.com](mailto:skala@sk.com)\\xa0 \\xa0 💬 카카오톡 채널 \\xa0[@skala](http://pf.kakao.com/_ReLln/chat)\\\\n\\\\n[SK AX 홈페이지 ↗](https://www.skcc.co.kr/)[SK AX 유튜브 ↗](https://www.youtube.com/channel/UCkn19q_NInHVEevXk98SBig)\\\\n\\\\n[SK AX 블로그 ↗](https://blog.naver.com/skcc_official)\\\\n\\\\n* [About](/#doz_body)\\\\n* [Curriculum](/#doz_menu_curriculum)\\\\n* [FAQ](/#doz_menu_faq)\\\\n* [Apply](/apply)\\\\n\\\\n대표이사 \\xa0 최태원, 장용호\\xa0\\\\n\\\\n사업자등록번호 \\xa0 783-85-00169  \\\\n주소 경기도 성남시 분당구 성남대로 343번길 9\\\\n\\\\n@2024 SKALA, SK AI Leader Academy All rights reserved.\"}, {\"url\": \"https://his.pusan.ac.kr/bbs/pnuenv/2718/1729241/artclView.do\", \"title\": \"[SK AX] 채용연계형 AI 서비스 개발 과정 2기 (~6/15)\", \"content\": \"SK AX가 직접 만들고, 강의하고, 채용합니다 ?SKALA(SKAI Leader Academy)는SK AX의 채용연계형 AI 서비스 개발 과정으로,. 약 5개월간 압축적인 SW, Data, AI 교육\", \"score\": 0.81630427, \"raw_content\": null}, {\"url\": \"https://www.skcareersjournal.com/3479\", \"title\": \"실전 경험과 채용 기회를 동시에! SK(주) AX의 AI 인재 양성 ...\", \"content\": \"Jun 10, 2025—안녕하세요, SK㈜ AX (구 SK(주) C&C) 취재기자 김태현입니다. ·SKALA 과정의 주안점은 \\'AI 서비스 개발\\'에있습니다.\", \"score\": 0.7060491, \"raw_content\": \"![](https://www.facebook.com/tr?id=1567572630195200&ev=PageView&noscript=1)\\\\n\\\\n# [SK채용 공식 블로그](https://www.skcareersjournal.com/)\\\\n\\\\n![SK채용 공식 블로그](https://tistory1.daumcdn.net/tistory/1886109/skinSetting/e9e3268ae210462793a30e9092bd4645)\\\\n![N](https://tistory1.daumcdn.net/tistory_admin/blogs/image/category/new_ico_5.gif)\\\\n![N](https://tistory1.daumcdn.net/tistory_admin/blogs/image/category/new_ico_5.gif)\\\\n![N](https://tistory1.daumcdn.net/tistory_admin/blogs/image/category/new_ico_5.gif)\\\\n![N](https://tistory1.daumcdn.net/tistory_admin/blogs/image/category/new_ico_5.gif)\\\\n![N](https://tistory1.daumcdn.net/tistory_admin/blogs/image/category/new_ico_5.gif)\\\\n\\\\n# 실전 경험과 채용 기회를 동시에! SK(주) AX의 AI 인재 양성 프로그램 \\'SKALA\\'\\\\n\\\\n## ******실전 경험과 채용 기회를 동시에! SK(주) AX의 AI 인재 양성 프로그램 \\'SKALA\\' 담당자 편******\\\\n\\\\n![](https://blog.kakaocdn.net/dna/baoRWh/btsMYLHBunr/AAAAAAAAAAAAAAAAAAAAAMRqUCYlw-IJTMD4vLKqH3pdUpUzbBBVN0eD2MFbAuQh/tfile.dat?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=MBoPnthKOnuZ15gTJBEKWGCYRu4%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/cOmWZX/btsOtLAwVjT/AAAAAAAAAAAAAAAAAAAAAILpXsYM1FzarEchTuf2QuhmIvyXdDmwBiQ6a_6qEmWG/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=28T2%2Fc95j2NE%2FqOLBrBhO%2BfnCUk%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/cOmWZX/btsOtLAwVjT/AAAAAAAAAAAAAAAAAAAAAILpXsYM1FzarEchTuf2QuhmIvyXdDmwBiQ6a_6qEmWG/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=28T2%2Fc95j2NE%2FqOLBrBhO%2BfnCUk%3D)\\\\n\\\\n#### 안녕하세요, SK㈜ AX (구 SK(주) C&C) 취재기자 김태현입니다. 인공지능의 급격한 발전과 글로벌 AI 패러다임으로 인해, 국내외 유수 기업들은 AI 인재 육성에 힘쓰고 있습니다. 체계적인 교육 프로그램을 통해 실무에 즉시 적용할 수 있는 전문가를 양성하는 것이 필수적인 과제로 떠오르고 있는데요, SK(주) AX는 이러한 트렌드를 이끌며 AI 전문가 양성 프로그램인 \\\\\\\\*\\\\\\\\*SKALA(SK AI Learning Academy)\\\\\\\\*\\\\\\\\*를 운영하며 기업 맞춤형 AI 인재를 체계적으로 육성하고 있습니다. 본 기사에서는 SKALA 프로그램의 주요 특징과 운영 방식을 담당자의 인터뷰를 통해 자세히 살펴보려 합니다. 후속 기사에서는 SKALA에 참여하고 있는 교육생들의 인터뷰를 보다 생생하게 다뤄보려 하는데요, 우선, 담당자의 깊이 있는 이야기를 담은 SKALA 인터뷰를 함께 살펴보시죠!\\\\n\\\\n### **SK Careers Editor 20기 김태현**\\\\n\\\\n![](https://blog.kakaocdn.net/dna/bhsqJG/btsOtvLrcyB/AAAAAAAAAAAAAAAAAAAAAB0cU-dSvdmBzDI_zXD0IdUVf--KtiqF7U67GD2qQ1gB/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=wuyGorTeAIE8xXiLnicJeqeb%2F80%3D)\\\\n![](https://blog.kakaocdn.net/dna/RGYB9/btsOttNEvYx/AAAAAAAAAAAAAAAAAAAAAGyab-t0ncLNCQ1BXn-dQWaLf3_rMYW9C-OSGnkiN-VR/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=ZbdhqPmxUf6Q%2FT2G%2Bf68wE8le0Q%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/bhsqJG/btsOtvLrcyB/AAAAAAAAAAAAAAAAAAAAAB0cU-dSvdmBzDI_zXD0IdUVf--KtiqF7U67GD2qQ1gB/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=wuyGorTeAIE8xXiLnicJeqeb%2F80%3D)\\\\n![](https://blog.kakaocdn.net/dna/RGYB9/btsOttNEvYx/AAAAAAAAAAAAAAAAAAAAAGyab-t0ncLNCQ1BXn-dQWaLf3_rMYW9C-OSGnkiN-VR/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=ZbdhqPmxUf6Q%2FT2G%2Bf68wE8le0Q%3D)\\\\n\\\\n#### 안녕하세요, SK㈜ AX College사업팀 이예슬 매니저입니다. HRD 직무로 일하고 있고, 주로 하는 일은 외부 교육 사업을 수행하기 위해 필요한 교육 프로그램 기획 및 운영을 담당하고 있습니다. 교육을 하는 목적에 따라 그 목적을 달성하기 위한 프로그램을 고안하고, 세부 운영 방안을 수립하는 기획력이 중요합니다.\\\\n\\\\n![](https://blog.kakaocdn.net/dna/BlGOx/btsOu5Lgd6T/AAAAAAAAAAAAAAAAAAAAANJ5C60kzs4_D7LN5OMujuzINGwbYSjElPn2sESmcono/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=ounvj8IgOU2S8Vcrl%2FfYdauVpHo%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/BlGOx/btsOu5Lgd6T/AAAAAAAAAAAAAAAAAAAAANJ5C60kzs4_D7LN5OMujuzINGwbYSjElPn2sESmcono/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=ounvj8IgOU2S8Vcrl%2FfYdauVpHo%3D)\\\\n\\\\n#### SKALA는\\xa0SK㈜\\xa0AX의 채용연계형\\xa0AI\\xa0서비스 개발 과정으로,\\xa0약\\xa05개월간\\xa0SW, Data/AI\\xa0교육 및 팀 프로젝트를 통해\\xa0AI\\xa0서비스 개발에 필요한 지식과 경험을 압축적으로 교육한 후\\xa0SK㈜\\xa0AX 및 자회사의 신입구성원으로 채용하려는 목적으로 기획 되었습니다. 서면과 짧은 대면 면접으로 이루어지는 일반적인 신입 공채 과정으로는 회사에서 채용하고자 하는 인재를 가려내기가 쉽지 않기에,\\xa0이런 점을 보완할 수 있도록 일정기간 밀착해서 교육하며 회사가 원하는 인재를 채용하기 위해 운영 되고 있습니다.\\\\n\\\\n![](https://blog.kakaocdn.net/dna/bJ8eYb/btsOuP9Jgjl/AAAAAAAAAAAAAAAAAAAAAI4alDH1iHDDlYnq0t5dDOK83JBdLJScSjI-_KYZZsbN/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=IAz4i%2FJqpoOSUQQ3FGRaDK%2FrsJE%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/bJ8eYb/btsOuP9Jgjl/AAAAAAAAAAAAAAAAAAAAAI4alDH1iHDDlYnq0t5dDOK83JBdLJScSjI-_KYZZsbN/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=IAz4i%2FJqpoOSUQQ3FGRaDK%2FrsJE%3D)\\\\n\\\\n#### SKALA\\xa0과정의 주안점은 ’AI\\xa0서비스 개발’에 있습니다. 프로그래밍 기초부터 클라우드,\\xa0데이터분석,\\xa0생성형\\xa0AI까지 굉장히 광범위한 내용을 다루고 있지만 이 모든 것은 결국\\xa0AI를 서비스로 녹여낼 수 있는 역량을 기르기 위함입니다. 한 분야만 알아서는\\xa0AI를 서비스화하는 데에 한계가 있기에,\\xa0커리큘럼의 모든 내용을 세세히,\\xa0깊이 아는 것보다는 각각의 부분이\\xa0AI\\xa0서비스 개발로 어떻게 연결되는지를 거시적으로 이해하는 것이 핵심입니다.\\\\n\\\\n![](https://blog.kakaocdn.net/dna/comuTX/btsOtNkOZcF/AAAAAAAAAAAAAAAAAAAAADJu-f1ppv5vUJppouNoaoHn8Gfe4p3kEEy_2Pw1K8fX/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=W8v58AE%2F%2F90iuVSExbWMBYKCg4k%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/comuTX/btsOtNkOZcF/AAAAAAAAAAAAAAAAAAAAADJu-f1ppv5vUJppouNoaoHn8Gfe4p3kEEy_2Pw1K8fX/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=W8v58AE%2F%2F90iuVSExbWMBYKCg4k%3D)\\\\n\\\\n#### 요즘에는 대학교에서 전공을 불문하고 기본적인 프로그래밍 언어는 접하고 오는 경우가 많고,\\xa0전공생이 아니라고 하더라도 다양한 교육 기회를 통해 개발을 공부할 수 있기 때문에 전공에 제한을 두고 있지는 않습니다. 프로그래밍도 결국 도구이기 때문에,\\xa0내가 무엇을 개발하고 싶은지에 대한 목표의식이 명확하면 개발 역량은 개인 노력의 여하에 따라 길러질 수 있다고 봤습니다. 물론 비전공자이면 열정과 노력이 더 많이 필요할 것이고,\\xa0이러한 점 때문에 선발 과정에서도 교육 참여 의지를 가장 중요하게 봤습니다.\\\\n\\\\n![](https://blog.kakaocdn.net/dna/Zp4nx/btsOuPPrYOs/AAAAAAAAAAAAAAAAAAAAAMq5hlIs8xy-Rl7Mq_MvT_--NDhuF80-BEuiSF0UAY1x/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=5nehOkVineKnwEQwnS%2FD06WdrGo%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/Zp4nx/btsOuPPrYOs/AAAAAAAAAAAAAAAAAAAAAMq5hlIs8xy-Rl7Mq_MvT_--NDhuF80-BEuiSF0UAY1x/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=5nehOkVineKnwEQwnS%2FD06WdrGo%3D)\\\\n\\\\n#### 과정 말미 한 달 반의 기간동안 진행되는 팀 프로젝트가 실제\\xa0SK(주) AX의 개발방법론과 프로젝트 관리 방법을 따르도록 설계되어 있고,\\xa0그에 맞게 결과물이 나올 수 있도록 가이드합니다. 서비스 기획서,\\xa0프로젝트 수행 계획서,\\xa0서비스 분석/설계서,\\xa0개발 소스코드,\\xa0테스트 계획서 및 프로젝트 종료 보고서 등 단계별로 도출되어야 하는 산출물을 작성해 봄으로써 보다 체계적인 프로젝트 수행 경험을 쌓을 수 있는 기회를 제공하고 있습니다.\\\\n\\\\n![](https://blog.kakaocdn.net/dna/N3AXN/btsOu5dqzU1/AAAAAAAAAAAAAAAAAAAAACSXtWw1JsUkQ0ohD8l12Yfwo_froLYdgXKsjTiR_lCB/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=tPn94e5H9KqrIyHPyPMANjeXcVQ%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/N3AXN/btsOu5dqzU1/AAAAAAAAAAAAAAAAAAAAACSXtWw1JsUkQ0ohD8l12Yfwo_froLYdgXKsjTiR_lCB/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=tPn94e5H9KqrIyHPyPMANjeXcVQ%3D)\\\\n\\\\n#### SKALA\\xa0수료생 전원에게\\xa0SKALA\\xa0특별 채용 전형에 참여할 수 있는 기회가 주어집니다. 채용으로 연계되는 회사는\\xa0SK㈜\\xa0AX와 자회사\\xa0ATS (애커튼테크놀로지서비스)로, SKALA\\xa0특별 채용 전형은 서류 전형을 면제해주고,\\xa0그 이후의 전형부터 진행됩니다.\\xa0일반적으로 굉장히 높은 서류전형의 경쟁률을 생각했을 때\\xa0SKALA를 수료한 사람들만 참여할 수 있다는 점이 수료생들에게 매우 유리하게 작용합니다. 만약 특별 채용 전형으로\\xa0SK㈜\\xa0AX와\\xa0ATS로 채용 되지 않더라도,\\xa0수료 후\\xa01년간 진행되는\\xa0SK㈜\\xa0AX와\\xa0ATS의 신입 채용 일반 공채에서 서류전형을 면제받을 수 있습니다.\\\\n\\\\n![](https://blog.kakaocdn.net/dna/cneqlz/btsOtFHdHMg/AAAAAAAAAAAAAAAAAAAAALkTbzRtWivK5XkLrCZcWThROmtNyra6oPm0My0Uy-mN/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=%2BxvBHf6yR%2FNxvzhlya053vQMRTs%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/cneqlz/btsOtFHdHMg/AAAAAAAAAAAAAAAAAAAAALkTbzRtWivK5XkLrCZcWThROmtNyra6oPm0My0Uy-mN/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=%2BxvBHf6yR%2FNxvzhlya053vQMRTs%3D)\\\\n\\\\n#### 예상되는 가장 큰 도전과제는 과정에 참여하는 모든 사람이 각자 나름의 성장을 이뤄내도록 하는 것인데요. 다양한 수준의 학습자가 동일한 커리큘럼으로 진행되는 과정이기 때문에 개인별로 과정에 대한 흡수율이 다를 수밖에 없습니다. 특히 SKALA는 전공에 제한을 두지 않고 모집을 했기 때문에 전공생과 비전공생의 격차가 있을 수밖에 없습니다. 5개월 이상 장기간 진행되는 교육과정에서 학습자 간 수준 차이가 두드러진다면, 결국 학습 분위기 형성에도 부정적일 수 있다고 판단했습니다. 이에 따라 학습자마다 각기 다른 영역의 강점을 가진 사람과 매치해 짝을 지어 자리를 배치했습니다. 내가 잘하는 영역에서는 내가 내 짝을 도와주고, 또 다른 영역에서 내가 어려움을 겪고 있을 때 내 짝이 나를 도와줄 수 있도록 했습니다. 현재까지 학습자들의 피드백을 들어보면 이 방법이 꽤 효과적으로 적용되고 있는 것 같습니다. 물론 짝의 도움으로 해소되지 않는 문제는 교수님들께서 적극적으로 질문에 답하고 도움을 주고 계십니다.\\\\n\\\\n![](https://blog.kakaocdn.net/dna/Xdd2L/btsOuiLzzJQ/AAAAAAAAAAAAAAAAAAAAAOZ-BjZO3K5JPX0v8x9XV6I0d9JD9HkAzw33cQIWoJZT/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=sfHt9M2dAY2FXzYKHC9ZmFD4X7k%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/Xdd2L/btsOuiLzzJQ/AAAAAAAAAAAAAAAAAAAAAOZ-BjZO3K5JPX0v8x9XV6I0d9JD9HkAzw33cQIWoJZT/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=sfHt9M2dAY2FXzYKHC9ZmFD4X7k%3D)\\\\n\\\\n#### SKALA의 가장 주된 홍보 문구는 “SK㈜\\xa0AX가 직접 만들고,\\xa0강의하고,\\xa0채용합니다” 입니다. 일반적으로 기업에서 운영하는 부트캠프나\\xa0IT\\xa0교육은 실질적인 운영을 외부업체에서 담당하는 경우가 대부분이지만\\xa0SKALA의 경우, SK㈜\\xa0AX\\xa0현직 기술전문가와 역량개발 전문가가 직접 설계하고,\\xa0강의합니다. 덕분에 그간\\xa0SK㈜ AX에서 사업을 통해 쌓아온 프로젝트 수행 및 개발 경험,\\xa0산업 도메인 관련 지식을 커리큘럼에 충실히 녹일 수 있었습니다.\\\\n\\\\n![](https://blog.kakaocdn.net/dna/zqimZ/btsOvKfNhLb/AAAAAAAAAAAAAAAAAAAAAEjQe0y9T33WJ2IWyQFY0NbMPz5l_70gYDYp10w_1DXb/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=n1iE90Ptq56ZKc0gZd%2FUP6abfpQ%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/zqimZ/btsOvKfNhLb/AAAAAAAAAAAAAAAAAAAAAEjQe0y9T33WJ2IWyQFY0NbMPz5l_70gYDYp10w_1DXb/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=n1iE90Ptq56ZKc0gZd%2FUP6abfpQ%3D)\\\\n\\\\n#### SKALA는 매 기수 학습자,\\xa0교수진,\\xa0운영진의 피드백을 받아 지속적으로 교육 과정을 개선해 나갈 계획이며,\\xa0현재 진행중인\\xa0AI\\xa0서비스 개발 과정 이외에도, SK㈜\\xa0AX\\xa0및 자회사가 필요로 하는 인재를 키우고,\\xa0채용하기 위한 교육 분야 확대를 적극적으로 검토하고 있습니다.\\\\n\\\\n![](https://blog.kakaocdn.net/dna/FikAz/btsOumf77Aj/AAAAAAAAAAAAAAAAAAAAACVXf1i8997_vwrQlqMaLzi5Qokh3gKPgDVs2hvSdofw/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=QYiYKx5MBAMwYztz8GV2AFu%2FBU4%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/FikAz/btsOumf77Aj/AAAAAAAAAAAAAAAAAAAAACVXf1i8997_vwrQlqMaLzi5Qokh3gKPgDVs2hvSdofw/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=QYiYKx5MBAMwYztz8GV2AFu%2FBU4%3D)\\\\n\\\\n#### SKALA는 무엇보다도 성장 가능성에 초점을 두고 있는 교육과정입니다. 본인이 이 과정에서 얻어가고 싶은 게 명확하다면 다른 요소는 부차적이니 주저말고 지원해주세요!\\\\n\\\\n#### 금번 기사에서는\\xa0SKALA\\xa0프로그램을 직접 운영하는 담당자의 인터뷰를 통해 교육 과정의 핵심 목표와 운영 방향성에 대해 알아보았는데요, SK(주) AX의\\xa0SKALA\\xa0프로그램은 맞춤형\\xa0AI\\xa0인재를 양성하기 위한 실무 중심의 교육 과정으로,\\xa0최신 기술 트렌드와 실습 중심의 커리큘럼을 통해 실질적인 역량 강화를 지원하고 있음을 확인할 수 있었습니다. 앞으로도\\xa0AI\\xa0기술을 선도할 인재 양성을 지속적으로 지원하며,\\xa0기업과 사회가 요구하는 전문성을 갖춘 인재들이 성장할 수 있도록 적극적인 노력을 기울일\\xa0SK(주) AX의 미래가 더욱 기대됩니다. **후속 기사에서는\\xa0SKALA\\xa0교육에 직접 참여하고 있는 교육생들의 이야기**를 들어보며,\\xa0프로그램이 실제로 어떤 영향을 미치는지에 대한,\\xa0보다 깊이 있는 이야기를 공개할 예정입니다. SKALA에 대해 더욱 생생하게 전달 드릴 수 있으리라 생각되는데요.\\xa0그럼,\\xa0후속 기사에서 뵙겠습니다.\\xa0감사합니다!\\\\n\\\\n![](https://blog.kakaocdn.net/dna/u2oMZ/btsOt2IYydI/AAAAAAAAAAAAAAAAAAAAADznCw6K3ixxN-mQVXlemQF1jGm7tOhHIlQlReomCCmo/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=gmKvVLW2kK7qyFNSsePJtcnIy2k%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/u2oMZ/btsOt2IYydI/AAAAAAAAAAAAAAAAAAAAADznCw6K3ixxN-mQVXlemQF1jGm7tOhHIlQlReomCCmo/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=gmKvVLW2kK7qyFNSsePJtcnIy2k%3D)\\\\n\\\\n#### \\'[News](/category/News) > [SK㈜ AX](/category/News/SK%E3%88%9C%20AX)\\' 카테고리의 다른 글\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| [SKCE 취재 기자에서 SK 신입사원으로 돌아왔습니다🫢SK 현직자의 꿀팁 대방출🔥](/3488)\\xa0\\xa0(0) | 2025.06.26 |\\\\n| [실전 경험과 채용 기회를 동시에! SK(주) AX의 AI 인재 양성 프로그램 \\'SKALA\\' 교육생 편](/3480)\\xa0\\xa0(6) | 2025.06.11 |\\\\n| [[신입사원 인터뷰] 우리 같이, AX 구성원이 되어볼래? 2025 신입사원이 들려주는 SK(주) AX 합격 꿀TIP](/3462)\\xa0\\xa0(0) | 2025.05.22 |\\\\n| [[현직자 인터뷰] IT 금융의 길은 C&C로 통한다! C&C가 만들어가는 더 똑똑한 초개인화 금융 세상](/3460)\\xa0\\xa0(0) | 2025.05.20 |\\\\n| [\\\\\"폭싹 바꿨수다!\\\\\" : 새로워진 SK㈜ AX의 신입 채용 전형🤗](/3465)\\xa0\\xa0(0) | 2025.05.20 |\\\\n\\\\n## 태그\\\\n\\\\nCopyright © SK. All Rights Reserved.\\\\n\\\\n## 티스토리툴바\"}, {\"url\": \"https://www.skax.co.kr/\", \"title\": \"SK AX\", \"content\": \"SK AX provides differentiated customer value based on our expertise in various industries such as manufacturing, communication and media, semiconductors, energy and chemicals, finance, and public sectors accumulated over the past 30 years, as well as digital technologies such as AI, Cloud, Digital Manufacturing, and Digital ESG. We realize customer-centered finance through financial solutions and service innovations based on digital technology, reduce costs through work efficiency, and support the realization of sustainable finance based on ESG management. With the spread of non-face-to-face consumption and the emergence of rational consumption patterns, we provide customized distribution services based on digital technology. We improve customer experience based on data and provide new service and business models using digital technology.\", \"score\": 0.5170594, \"raw_content\": \"Intelligent Factory Solution, iFacts\\\\n\\\\nIncrease the competitiveness of the manufacturing industry with tomorrow\\'s Digital technology.\\\\n\\\\n[Learn more](#)\\\\n\\\\nBe the Answer to Sustainability, CodeGreen\\\\n\\\\nThe answer to the path to sustainability, Digital ESG Solutions\\\\n\\\\n[Learn more](#)\\\\n\\\\nImagine, AX\\\\n\\\\nGlobal Top 10 AX Innovator with Cutting-Edge AI and Unmatched Growth Potential\\\\n\\\\n[Learn more](#)\\\\n\\\\nA Guide to Enterprise AI Innovation, Solur\\\\n\\\\nLike the sundial that helped Vikings navigate, it shines a light on the future of infinite AI possibilities.\\\\n\\\\n[Learn more](#)\\\\n\\\\nA to Z for enterprise cloud services, CloudZ\\\\n\\\\nMeets any customer\\'s needs quickly and completely at once.\\\\n\\\\n[Learn more](#)\\\\n\\\\nIntelligent Factory Solution, iFacts\\\\n\\\\nIncrease the competitiveness of the manufacturing industry with tomorrow\\'s Digital technology.\\\\n\\\\n[Learn more](#)\\\\n\\\\nBe the Answer to Sustainability, CodeGreen\\\\n\\\\nThe answer to the path to sustainability, Digital ESG Solutions\\\\n\\\\n[Learn more](#)\\\\n\\\\nImagine, AX\\\\n\\\\nGlobal Top 10 AX Innovator with Cutting-Edge AI and Unmatched Growth Potential\\\\n\\\\n[Learn more](#)\\\\n\\\\nA Guide to Enterprise AI Innovation, Solur\\\\n\\\\nLike the sundial that helped Vikings navigate, it shines a light on the future of infinite AI possibilities.\\\\n\\\\n[Learn more](#)\\\\n\\\\n[01SK AX](#)\\\\n\\\\n[02Generative AI](#)\\\\n\\\\n[03Cloud](#)\\\\n\\\\n[04Manufacturing](#)\\\\n\\\\n[05Digital ESG](#)\\\\n\\\\n## We lead the digital transformation of our customers and society\\\\n\\\\nSK AX provides differentiated customer value based on our expertise in various industries such as manufacturing, communication and media, semiconductors, energy and chemicals, finance, and public sectors accumulated over the past 30 years, as well as digital technologies such as AI, Cloud, Digital Manufacturing, and Digital ESG.\\\\n\\\\n[Generative AI](/generative-ai)\\\\n\\\\n[Cloud](/cloud)\\\\n\\\\n[Manufacturing](/manufacturing)\\\\n\\\\n[Digital ESG](/esg)\\\\n\\\\n## Main Business Areas\\\\n\\\\nGenerative AI\\\\n\\\\nBy lowering the entry barriers for companies to use AI, we expand the application area and support the achievement of efficiency to reduce costs and secure new revenues.\\\\n\\\\nManufacturing\\\\n\\\\nBased on digital technology, we improve the level of automation and intelligence of factories to achieve quality improvement and production efficiency, which are key performance indicators.\\\\n\\\\nFinance\\\\n\\\\nWe realize customer-centered finance through financial solutions and service innovations based on digital technology, reduce costs through work efficiency, and support the realization of sustainable finance based on ESG management.\\\\n\\\\nCommerce/Logistics\\\\n\\\\nWith the spread of non-face-to-face consumption and the emergence of rational consumption patterns, we provide customized distribution services based on digital technology.\\\\n\\\\nTelecommunications\\\\n\\\\nWe improve customer experience based on data and provide new service and business models using digital technology. In addition, through convergence with various industries such as finance, healthcare, and manufacturing, we achieve value improvement in our services.\\\\n\\\\nService\\\\n\\\\nWe innovate services and improve revenue streams through digital technology.\\\\nWe provide customized services by utilizing AI big data analysis technology to collect customer data.\\\\n\\\\nCloud\\\\n\\\\nAs a comprehensive cloud partner, a group of cloud experts with more than 1,500 CSP (Cloud Solution Provider) technical qualifications are here to help our customers.\\\\n\\\\nDigital ESG\\\\n\\\\nBased on ESG goals using digital technology, we establish sustainable development strategic goals, investment plans, and support impact assessment verification.\\\\n\\\\n## Video\\\\n\\\\nMake tomorrow with today\\'s technology,  \\\\ndream of the future with tomorrow\\'s technology\"}, {\"url\": \"https://sunq.tistory.com/10\", \"title\": \"[취업도전기] SKALA 및 SK AX 신입사원 채용 후기 - Sun\\' Day\", \"content\": \"Jul 13, 2025—지원 단계는 서류 제출, 인성 검사, 면접 총 3단계로 이루어졌는데 모두 비대면으로 이루어져서 전형 진행에는 어려움이 없었다. 자소서는 총 4문항으로\", \"score\": 0.498902, \"raw_content\": \"### [취업도전기] SKALA 및 SK AX 신입사원 채용 후기\\\\n\\\\n### 들어가기 앞서\\\\n\\\\n막 학기가 끝나고 취업할 때까지 텅 빈 시간이 아까워서 지원하게 된 SKALA였다. 학교가 아닌 기업 현직자분들의 수업을 들으며, AI Agent와 RAG 등 AI를 활용한 서비스 개발뿐만 아니라 프로젝트를 진행하며 제대로 된 AI 도구 활용 능력을 기를 수 있었다. 또한, 이전까지는 몰랐던 국내 SI 프로젝트들이 어떻게 돌아가고 어떻게 사업이 이루어지는지 엿볼 수 있었다. 비록, SKCT에서 떨어져 SK AX와 함께할 수 없게 되었지만, 학교 사람들과 지내기만 했던 우물 안 개구리에서 다양한 학교, 지역, 나이, 경험을 가진 사람들과 반년 동안 지내면서 넓은 시야를 가질 수 있게 된 것 같다. 좋은 경험과 추억을 쌓고 마무리를 짓게 되어 아쉬움은 없다.\\\\n\\\\n## SK AI Leader Academy\\\\n\\\\n### 지원과정\\\\n\\\\n![](https://blog.kakaocdn.net/dna/dLdJx8/btsPghyidpI/AAAAAAAAAAAAAAAAAAAAAMl0k7IrQC6DI7JLNwdemrv-KxjJelzaVEwLQHyM1Ag6/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=jX7IGgRXf9dSu4kDVE6l4rfzOcg%3D)![](https://blog.kakaocdn.net/dna/bmXHz9/btsPfuZsDmF/AAAAAAAAAAAAAAAAAAAAAMT6btxuWAhFhr7yxlLeGwecfute_e7RSJFfcEaD1rIR/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=Tfov1u24aWb8WV1FAk2fygy16nE%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/dLdJx8/btsPghyidpI/AAAAAAAAAAAAAAAAAAAAAMl0k7IrQC6DI7JLNwdemrv-KxjJelzaVEwLQHyM1Ag6/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=jX7IGgRXf9dSu4kDVE6l4rfzOcg%3D)\\\\n![](https://blog.kakaocdn.net/dna/bmXHz9/btsPfuZsDmF/AAAAAAAAAAAAAAAAAAAAAMT6btxuWAhFhr7yxlLeGwecfute_e7RSJFfcEaD1rIR/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=Tfov1u24aWb8WV1FAk2fygy16nE%3D)\\\\n\\\\n학교에서 AI 소프트웨어라는 수업을 들으면서 LLAMA 모델과 RAG를 활용하여 간단한 디스코드 챗봇을 만든 경험이 있었다. 이것저것 해보는 것을 좋아하는 나이기에, 이번에는 AI를 활용한 서비스를 개발해 보자는 마음으로 지원하게 되었다. 지원 단계는 서류 제출, 인성 검사, 면접 총 3단계로 이루어졌는데 모두 비대면으로 이루어져서 전형 진행에는 어려움이 없었다. 자소서는 총 4문항으로 내가 평소 AI에 대해 생각하던 내용과 했었던 활동에 대해 솔직하게 작성했다. 첫 기업 인성 검사라 살짝 불안했지만, 평소 스스로 나에 대해 생각했던 키워드를 바탕으로 문항들을 선택하니 통과할 수 있었다. 내 생각과 했던 활동들을 정리해서 돌아보고 면접을 봤다.\\\\n\\\\n결과는 합격이었다. 사실, SSAFY에 지원해서 합격했었는데, SSAFY의 취업 지원과 SKALA의 채용 연계 중에 고민하다 채용 연계가 더 메리트 있다고 생각하여 SKALA로 왔다. 결과 발표와 교육 시작까지 기간이 얼마 되지 않아, 급하게 정자역 근처 고시원에 방을 잡고 교육 준비를 했다. 프로그램은 교육 기간과 프로젝트 기간으로 나뉘지만, 기간 동안 본인에게 3번의 마음 및 상태 변화가 있어서 전, 중, 후 3개로 나누었다.\\\\n\\\\n### 전반기(~ 4월초)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/beOihF/btsPfZR4q0t/AAAAAAAAAAAAAAAAAAAAAF_udRsXX4H_ZXQX803uQUSbd4MNSelmg0R-aXM2EXqb/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=s2tgHcCYrUQ6jZrmLLkEMvse8Qg%3D)![](https://blog.kakaocdn.net/dna/2hXSH/btsPfix9zeO/AAAAAAAAAAAAAAAAAAAAAEr4qxnP2KWfBh8UdJHOTBdoZRCzTK5yVr7bgk6wINxm/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=o9OWvx2%2BQpr8pN%2FV7u9p8HUCXQU%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/beOihF/btsPfZR4q0t/AAAAAAAAAAAAAAAAAAAAAF_udRsXX4H_ZXQX803uQUSbd4MNSelmg0R-aXM2EXqb/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=s2tgHcCYrUQ6jZrmLLkEMvse8Qg%3D)\\\\n![](https://blog.kakaocdn.net/dna/2hXSH/btsPfix9zeO/AAAAAAAAAAAAAAAAAAAAAEr4qxnP2KWfBh8UdJHOTBdoZRCzTK5yVr7bgk6wINxm/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=o9OWvx2%2BQpr8pN%2FV7u9p8HUCXQU%3D)\\\\n\\\\n첫날이 시작되고 프로젝트 기간 전까지 함께 지내게 될 짝꿍과 팀원들이 정해졌다. 비전공자를 포함하여 다양한 학벌과 학위, 나이의 사람들이 있었는데, 취업 시장이 정말 어렵다는 것을 느낄 수 있었다. 첫 수업부터 Cloud와 MSA로 시작해서 개미 털기인 줄 알았으나, 이후 수업에서는 Java, Python 등 기초부터 수업을 진행하였다. 교육기간 동안 Vue, Spring, Lang chain 등 다양한 분야에 대해 배울 수 있어서 새로운 기술을 배울 수 있어서 좋았지만, 각 분야들이 대부분 4일 만의 기간 내에 언어부터 시작하여 라이브러리 사용까지 교육되다 보니 깊이가 얕아서 아쉬웠다.\\\\n\\\\n개인적으로는 이 기간에 정말 고민이나 걱정이 많아서 정신적으로 힘들었다. 작년부터 고민했었지만, 학생 신분이라 크게 생각하지는 않았었는데, 정말로 내가 하고 싶은 게 무엇인지 내가 무엇을 해야 행복한지 계속해서 생각했다. 3월 말이 되어서야 마음 정리를 끝낼 수 있었고 나의 목표를 정할 수 있었다.\\\\n\\\\n### 중반기(4월 초 ~ 5월 말)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/QuGaQ/btsPf04B6Ow/AAAAAAAAAAAAAAAAAAAAAPa4b1W0055HydHFGyuee7T_BxjUli-WrFC0ottBmrTd/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=1UOTMgJHCxI4DYwI9kcozug%2BCbY%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/QuGaQ/btsPf04B6Ow/AAAAAAAAAAAAAAAAAAAAAPa4b1W0055HydHFGyuee7T_BxjUli-WrFC0ottBmrTd/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=1UOTMgJHCxI4DYwI9kcozug%2BCbY%3D)\\\\n\\\\n4월부터는 대부분의 수업이 미니 프로젝트로 진행되었다. 팀으로 진행되기도 하고 개인이 혼자서 진행되기도 했다. 확실히, 미니 프로젝트를 진행하니 지난 수업들보다 집중도 잘 되고, 돌아가는 원리도 스스로 더 공부하게 되었다. 교육 중간 달에 하루는 선도기업 재직자 특강이라는 시간이 있었다. SK AX뿐만 아니라 Hynix와 Telecom 등 다양한 SK 계열사 현직자분들이 각자 종사하고 있는 산업을 소개해주고 취업 관련 얘기를 해주셨다. 각 산업에 대해 이해할 수 있었고, 각 산업에 대해 어떻게 준비해야 하는지 알게 되었다.\\\\n\\\\n중반기에는 전반기보다 생소한 내용들도 늘었고 배울 내용이 늘었지만, 예비군이나 면접 준비 등으로 온전히 수업에 집중하지 못한 게 아쉬웠다. 그래도, 본격적으로 정신을 잡고 공부에 집중할 수 있어서 실력적으로는 많이 성장한 것 같았다. 어느 날 구내식당에 정지선 셰프님이 와서 특선 메뉴를 선보여 주셨는데, 확실히 대기업의 클라스는 다르다는 것을 느낄 수 있었다. 교육 과정 진행 중 사명이 SK C&C에서 SK AX로 바뀌었는데, 굉장히 신기한 경험이었다.\\\\n\\\\n### 후반기(5월 말 ~)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/bQDZB9/btsPghLIevE/AAAAAAAAAAAAAAAAAAAAAHOTxX3LXuFtWSSnTHkieZk1HZ61iECPffAJLhv25EQf/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=8gbgUMMoVb7zfR7TBZiVJ29n17Y%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/bQDZB9/btsPghLIevE/AAAAAAAAAAAAAAAAAAAAAHOTxX3LXuFtWSSnTHkieZk1HZ61iECPffAJLhv25EQf/img.jpg?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=8gbgUMMoVb7zfR7TBZiVJ29n17Y%3D)\\\\n\\\\n최종 프로젝트 기간이 시작되었다. 최종 프로젝트는 먼저 팀이 정해지고, SK AX 구성원분들이 제시해 주신 프로젝트 목록 중 하나를 선정하여 진행하였다. 주제를 선정하고 구성원분과 미팅을 통해 요구사항을 파악한 후 프로젝트를 개발하였다. 개발을 진행하며 현장처럼 개발 산출물을 작성하여서 진행하였는데, 학교에서 단순히 배웠던 명세서나 다이어그램에서 발전해서 실제 문서를 작성해 보니 실제 개발 과정에서 산출물이 굉장히 중요하다는 것을 느낄 수 있었다.\\\\n\\\\n최종 프로젝트 기간 동안 팀에서 혼자 프론트엔드 개발을 담당했다. 이전에 React만 사용해 봤었는데, 이번 기회에 Next뿐만 아니라 Web Assembly까지 사용해 보고 싶었기 때문이다. 다른 팀 대비 인원이 한 명 부족하기도 하였고, SK AX 신입사원 채용 기간과 겹쳐 개발 일정이 촉박해서 WASM의 직접적인 사용까지 이어지지 못한 것이 아쉬웠다. 비록, 프로젝트 경진대회에서 수상을 하지 못했지만, 개발을 마무리 지을 수 있어서 다행이었다.\\\\n\\\\n### 후기\\\\n\\\\n![](https://blog.kakaocdn.net/dna/dFyNjb/btsPfBjWzq7/AAAAAAAAAAAAAAAAAAAAANeYhIYkTcJLHkMQWHvJsj1MZyKHcexF1iHNkFW7e-zo/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=6aRJBnTtrU4grzCYI59te9%2BFnhY%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/dFyNjb/btsPfBjWzq7/AAAAAAAAAAAAAAAAAAAAANeYhIYkTcJLHkMQWHvJsj1MZyKHcexF1iHNkFW7e-zo/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=6aRJBnTtrU4grzCYI59te9%2BFnhY%3D)\\\\n\\\\nSKALA 기간 동안 AI 서비스 개발뿐만 아니라, 다양한 사람들과 교류하며 많은 것들을 배울 수 있었다. 전공자 중 SI에 관심이 있는 사람이나, 비전공자여도 개발자가 되고 싶은 도메인 관련 학과 사람들이라면 추천할 것 같다. SKALA와의 여정은 여기서 마무리 짓고, 나의 목표를 이루기 위해 계속해서 전진할 것이다. 그동안 함께 하신 분들, 감사했습니다.🙇\\\\n\\\\n## SK AX 신입사원 채용\\\\n\\\\n### 서류 접수\\\\n\\\\n![](https://blog.kakaocdn.net/dna/8kWjf/btsPf2adefY/AAAAAAAAAAAAAAAAAAAAAEofG-bkOHXkBiF54YtsYV_A9bFqSbXdAv5s4SjuLwde/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=tUsa0kK%2BY4Bp8Buked5FHQEeJEc%3D)![](https://blog.kakaocdn.net/dna/zeSxE/btsPfMyReOx/AAAAAAAAAAAAAAAAAAAAAHuGRP6iPBzxMN6j5b9ufbIfeF81Mr8I6Zb7Ng0J52Aj/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=S1%2FmNMlUHZ6rvstOfBnPz%2F1AaFg%3D)\\\\n\\\\n(좌) 2024 채용 (우) 2025 채용\\\\n\\\\n![](https://blog.kakaocdn.net/dna/8kWjf/btsPf2adefY/AAAAAAAAAAAAAAAAAAAAAEofG-bkOHXkBiF54YtsYV_A9bFqSbXdAv5s4SjuLwde/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=tUsa0kK%2BY4Bp8Buked5FHQEeJEc%3D)\\\\n![](https://blog.kakaocdn.net/dna/zeSxE/btsPfMyReOx/AAAAAAAAAAAAAAAAAAAAAHuGRP6iPBzxMN6j5b9ufbIfeF81Mr8I6Zb7Ng0J52Aj/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=S1%2FmNMlUHZ6rvstOfBnPz%2F1AaFg%3D)\\\\n\\\\nSKALA의 채용은 별도로 이루어지지 않고, SK AX 신입사원 채용과 함께 진행되었다. SKCT만 통과하면 면접까지는 프리패스하는 혜택을 받을 수 있었다. 하지만, 작년과는 달라진 채용 공고가 나 같은 순수 컴퓨터공학 전공자에게는 과연 내가 끝까지 채용 전형을 마무리 지을 수 있겠느냐는 생각이 들었다. 올해부터는 컴퓨터공학 전공자보다는 도메인별 관련 전공자를 뽑아서 개발을 가르치겠다는 느낌이 들었다. 의문이 들었지만, 일단 채용 연계 혜택을 받을 수 있기에 1지망 반도체, 2지망 AI/Data로 지원하였다.\\\\n\\\\n### SKCT\\\\n\\\\n![](https://blog.kakaocdn.net/dna/ew1E4r/btsPfBdlpl5/AAAAAAAAAAAAAAAAAAAAAEeE0fI-DEvrgmEbKTAatTVr-B78CWz0kcPw1yKdLGVv/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=T6jLJohGkcO8yd1PQ3hp9Vs4kME%3D)\\\\n\\\\n![](https://blog.kakaocdn.net/dna/ew1E4r/btsPfBdlpl5/AAAAAAAAAAAAAAAAAAAAAEeE0fI-DEvrgmEbKTAatTVr-B78CWz0kcPw1yKdLGVv/img.png?credential=yqXZFxpELC7KVnFOS48ylbz2pIh7yKj8&expires=1759244399&allow_ip=&allow_referer=&signature=T6jLJohGkcO8yd1PQ3hp9Vs4kME%3D)\\\\n\\\\n처음 보는 적성고사였다. 대부분의 기업에서 개발자는 적성 고사보단 코딩테스트 및 CS 테스트를 치르기에 어떻게 적성 고사를 준비해야 할 지 감이 안 왔다. 일단, 문제집을 사서 풀긴 하였지만 생각보다 잘 풀리지는 않았다. 최종 프로젝트 기간과 겹쳐서 준비 기간도 길지 않았고, 미리미리 준비하지 않은 내 책임도 컸다. 그래도, 사전 모의고사 풀이 때는 나름 점수가 나쁘지 않게 나왔다고 생각했지만, 시험만 치면 긴장하는 버릇 때문에 정작 SKCT를 치게 되니 처음인 언어이해 파트가 잘 읽히지 않았다. 결국, 시험은 망치게 되었고 필기전형에서 떨어지게 되었다.\\\\n\\\\n### ATS\\xa0 채용\\\\n\\\\nSK AX의 자회사로 SKALA 교육생 모두에게 채용의 기회가 열렸다. 채용 결과 나오면 작성할 예정이다.\\\\n\\\\n### 후기\\\\n\\\\n채용 연계의 메리트로 SKALA에 지원하게 되었지만, 결국 끝까지 해내지 못했다. 채용 연계 혜택이 SKALA 진행 중에 정해진 것도 아쉬우면서도, SKCT가 아니라 코딩테스트였다면 통과했을까라는 생각이 들기도 했다. 이번 경험을 통해 앞으로 취업을 위해선, 적성 고사보단 내가 잘할 수 있는 코딩테스트를 위주로 준비할 것 같다. SK AX와의 여정도 여기서 마무리 짓도록 하겠다.\"}]' name='tavily_web_search' id='5d7c7436-b387-4346-9c04-ea28e94b84ea' tool_call_id='call_OVeaUgNoTCO5TE0PRTHrABgu'\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='**SKALA (SK AI Leader Academy)**는 SK AX에서 제공하는 채용 연계형 AI 서비스 개발 과정입니다. 이 과정은 약 5개월 동안 진행되며, 소프트웨어(SW), 데이터 및 AI 교육과 팀 프로젝트를 통해 AI 서비스 개발에 필요한 지식과 경험을 제공합니다. 교육을 이수한 후에는 SK AX 및 자회사에 신입 구성원으로 채용될 수 있는 기회가 주어집니다.\\n\\n### 주요 내용\\n- **교육 기간**: 약 5개월\\n- **교육 내용**: SW, 데이터, AI 관련 교육 및 팀 프로젝트\\n- **채용 연계**: 과정 종료 후 SKALA 이수자는 서류 전형 면제 및 특별 전형을 통해 채용 우대\\n- **지원 대상**: AI 서비스 개발에 관심이 있는 누구나 지원 가능, 전공 제한 없음\\n- **교육비**: 전액 무료 (국비 지원)\\n- **특전**: 출석 시 훈련 장려금 지급, 점심 및 저녁 식사 제공, 교육용 노트북 대여 등\\n\\n### 교육 과정\\n1. **SW Fundamental**: Front-end 및 Back-end 개발, 데이터베이스, 클라우드, DevOps\\n2. **Data · AI**: Python 프로그래밍, 데이터 분석, 머신러닝, 딥러닝\\n3. **AI Team Project**: 프로젝트 관리 방법론 및 팀 프로젝트 수행\\n4. **Special Course**: 산업별 IT 프로젝트 사례, IT 업계 트렌드, 취업 기본 소양\\n\\n### 지원 방법\\n- 지원은 온라인으로 가능하며, 서류 제출, 인성 검사, 면접 등의 과정을 거칩니다.\\n- SKALA 과정은 고용노동부의 K-디지털 트레이닝 사업의 일환으로 진행되며, 교육비는 전액 국비 지원됩니다.\\n\\n자세한 정보는 [SKALA 공식 웹사이트](http://skala.co.kr/)를 방문하시기 바랍니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 422, 'prompt_tokens': 17916, 'total_tokens': 18338, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None} id='run-8243f2d7-d4da-42c6-b910-7b73231404bb-0' usage_metadata={'input_tokens': 17916, 'output_tokens': 422, 'total_tokens': 18338}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": \"SK AX에서 진행하는 SKALA에 대해서 검색해 주세요\"}\n",
    "\n",
    "for event in graph.stream(inputs, stream_mode=\"values\"):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n==============\\nSTEP: {key}\\n==============\\n\")\n",
    "        print(value[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith Trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
