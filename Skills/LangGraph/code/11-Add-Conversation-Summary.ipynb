{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY Loading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH21-LangGraph\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH21-LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 대화기록 요약 추가 \n",
    "\n",
    "- 대화 기록 유지, 지속성 \n",
    "    - 대화를 지속하기 쉽게 만들어줌 \n",
    "    - 하지만 대화가 길어질수록 대화 기록이 누적되어 `context window`를 더 많이 차지하게 됨\n",
    "    - `LLM` 호출이 더 비싸고 길어지며, 잠재적으로 오류가 발생할 수 있어 바람직하지 않을 수 있음 \n",
    "    - 이를 해결하기 위한 한 가지 방법은 현재까지의 대화 요약본을 생성하고, 이를 최근 `N` 개의 메시지와 함께 사용하는 것 \n",
    "\n",
    "- 프로세스\n",
    "    - 대화가 너무 긴지 확인 (메시지 수나 메시지 길이로 확인 가능)\n",
    "    - 너무 길다면 요약본 생성 (이를 위한 프롬프트 필요)\n",
    "    - 마지막 `N` 개의 메시지를 제외한 나머지 삭제 (`DeleteMessage`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, RemoveMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 저장소 설정\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "# 메시지 상태와 요약 정보를 포함하는 상태 클래스\n",
    "class State(MessagesState):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    summary: str\n",
    "\n",
    "\n",
    "# 모델 초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_llm(state: State):\n",
    "    # 이전 요약 정보 확인\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # 이전 요약 정보가 있다면 시스템 메시지로 추가\n",
    "    if summary:\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    # 모델 호출\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 종료 또는 요약 결정 로직\n",
    "# Literal : 값의 범위를 제한하고 의도를 명확히 표현할 수 있게 해두는 도구 (Type Hint) \n",
    "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
    "    # 메시지 목록 확인\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 메시지 수가 6개 초과라면 요약 노드로 이동\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 내용 요약 및 메시지 정리 로직\n",
    "def summarize_conversation(state: State):\n",
    "    # 이전 요약 정보 확인\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # 이전 요약 정보가 있다면 요약 메시지 생성\n",
    "    if summary:\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above in Korean:\"\n",
    "        )\n",
    "    else:\n",
    "        # 요약 메시지 생성\n",
    "        summary_message = \"Create a summary of the conversation above in Korean:\"\n",
    "\n",
    "\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    \n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRAPH\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"conversation\", ask_llm)\n",
    "workflow.add_node(summarize_conversation)\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"conversation\",\n",
    "    should_continue,\n",
    ")\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Visualize Graph Error: Failed to render the graph using the Mermaid.INK API. Status code: 204.\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "visualize_graph(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      +-----------+           \n",
      "                      | __start__ |           \n",
      "                      +-----------+           \n",
      "                             *                \n",
      "                             *                \n",
      "                             *                \n",
      "                     +--------------+         \n",
      "                     | conversation |         \n",
      "                     +--------------+         \n",
      "                    ...             ...       \n",
      "                  ..                   ...    \n",
      "                ..                        ..  \n",
      "+------------------------+                  ..\n",
      "| summarize_conversation |                ..  \n",
      "+------------------------+             ...    \n",
      "                    ***             ...       \n",
      "                       **         ..          \n",
      "                         **     ..            \n",
      "                        +---------+           \n",
      "                        | __end__ |           \n",
      "                        +---------+           \n"
     ]
    }
   ],
   "source": [
    "print(app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**그래프 해석**\n",
    "\n",
    "- 기본 대화는 항상 `conversation`에서 시작\n",
    "- 요약이 필요한 조건일 때만 `summarize_conversation` 실행\n",
    "- 모든 흐름은 결국 `__end__`로 종료됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업데이트 정보 출력 함수\n",
    "def print_update(update):\n",
    "    # 업데이트 딕셔너리 순회\n",
    "    for k, v in update.items():\n",
    "        # 메시지 목록 출력\n",
    "        for m in v[\"messages\"]:\n",
    "            m.pretty_print()\n",
    "        # 요약 정보 존재 시 출력\n",
    "        if \"summary\" in v:\n",
    "            print(v[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "안녕하세요? 반갑습니다. 제 이름은 김철수 입니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요, 김철수님! 반갑습니다. 어떻게 도와드릴까요?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "제 이름이 뭔지 기억하세요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "네, 김철수님이라고 하셨습니다. 다른 질문이나 이야기하고 싶은 것이 있으신가요?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "제 직업은 AI 엔지니어 입니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "멋진 직업이네요, 김철수님! AI 엔지니어로서 어떤 분야에 주로 집중하고 계신가요? 또는 어떤 프로젝트에 참여하고 계신지 궁금합니다.\n"
     ]
    }
   ],
   "source": [
    "# 설정 \n",
    "config = {\"configurable\": {\"thread_id\": \"001\"}}\n",
    "\n",
    "# 첫 번째 사용자 메시지 생성 및 출력\n",
    "input_message = HumanMessage(content=\"안녕하세요? 반갑습니다. 제 이름은 김철수 입니다.\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 모드에서 첫 번째 메시지 처리 및 업데이트 출력\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "# 두 번째 사용자 메시지 생성 및 출력\n",
    "input_message = HumanMessage(content=\"제 이름이 뭔지 기억하세요?\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 모드에서 두 번째 메시지 처리 및 업데이트 출력\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)\n",
    "\n",
    "# 세 번째 사용자 메시지 생성 및 출력\n",
    "input_message = HumanMessage(content=\"제 직업은 AI 엔지니어 입니다.\")\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 모드에서 세 번째 메시지 처리 및 업데이트 출력\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='안녕하세요? 반갑습니다. 제 이름은 김철수 입니다.', id='4cc47bf6-f83d-4c04-acd6-f2ac9701bc5b'),\n",
       "  AIMessage(content='안녕하세요, 김철수님! 반갑습니다. 어떻게 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 22, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'finish_reason': 'stop', 'logprobs': None}, id='run-48f696cc-9a6b-494c-90ef-09811936e4f8-0', usage_metadata={'input_tokens': 22, 'output_tokens': 19, 'total_tokens': 41}),\n",
       "  HumanMessage(content='제 이름이 뭔지 기억하세요?', id='f0d82e5c-3338-49b5-9813-5dd9486ea9b7'),\n",
       "  AIMessage(content='네, 김철수님이라고 하셨습니다. 다른 질문이나 이야기하고 싶은 것이 있으신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 58, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'finish_reason': 'stop', 'logprobs': None}, id='run-e212f2c4-c97e-4556-aba8-8de3c214fbcf-0', usage_metadata={'input_tokens': 58, 'output_tokens': 23, 'total_tokens': 81}),\n",
       "  HumanMessage(content='제 직업은 AI 엔지니어 입니다.', id='3dac6030-3f08-4f62-81ea-7713b8ba161f'),\n",
       "  AIMessage(content='멋진 직업이네요, 김철수님! AI 엔지니어로서 어떤 분야에 주로 집중하고 계신가요? 또는 어떤 프로젝트에 참여하고 계신지 궁금합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 100, 'total_tokens': 145, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run-1a174e80-3edc-422a-a281-9d16ebfb6feb-0', usage_metadata={'input_tokens': 100, 'output_tokens': 45, 'total_tokens': 145})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상태 구성 값 검색\n",
    "values = app.get_state(config).values\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "2025년 AI 트랜드 에 대해 좀 더 알아보고 있어요. 최근 기사를 읽고 있습니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2025년의 AI 트렌드는 여러 가지 흥미로운 방향으로 발전할 것으로 예상됩니다. 몇 가지 주요 트렌드를 소개해드릴게요:\n",
      "\n",
      "1. **AI의 민주화**: 더 많은 사람들이 AI 기술을 쉽게 접근하고 사용할 수 있도록 하는 도구와 플랫폼이 증가할 것입니다. 이는 비전문가도 AI를 활용할 수 있게 해줄 것입니다.\n",
      "\n",
      "2. **Explainable AI (XAI)**: AI의 결정 과정을 이해하고 설명할 수 있는 기술이 중요해질 것입니다. 이는 특히 의료, 금융 등 중요한 분야에서 신뢰성을 높이는 데 기여할 것입니다.\n",
      "\n",
      "3. **AI와 윤리**: AI의 윤리적 사용에 대한 논의가 더욱 활발해질 것입니다. 데이터 프라이버시, 편향성 문제 등을 해결하기 위한 규제와 가이드라인이 필요할 것입니다.\n",
      "\n",
      "4. **AI와 자동화**: 다양한 산업에서 AI를 활용한 자동화가 증가할 것입니다. 이는 생산성을 높이고 비용을 절감하는 데 기여할 것입니다.\n",
      "\n",
      "5. **인간-AI 협업**: AI와 인간이 협력하여 문제를 해결하는 방식이 더욱 중요해질 것입니다. AI는 반복적인 작업을 처리하고, 인간은 창의적이고 전략적인 결정을 내리는 역할을 할 것입니다.\n",
      "\n",
      "6. **AI의 지속 가능성**: 환경 문제 해결을 위한 AI의 역할이 강조될 것입니다. 에너지 효율성을 높이거나 기후 변화에 대응하는 데 AI가 활용될 것입니다.\n",
      "\n",
      "이 외에도 다양한 트렌드가 있을 수 있으니, 최신 기사를 통해 계속해서 정보를 업데이트하는 것이 좋습니다. 어떤 특정한 주제에 대해 더 알고 싶으신가요?\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "================================\u001b[1m Remove Message \u001b[0m================================\n",
      "\n",
      "\n",
      "김철수님은 AI 엔지니어로서 2025년의 AI 트렌드에 대해 알아보고 있으며, 최근 기사를 읽고 있다고 하셨습니다. 이에 대해 저는 2025년의 주요 AI 트렌드로 AI의 민주화, Explainable AI (XAI), AI와 윤리, AI와 자동화, 인간-AI 협업, AI의 지속 가능성을 소개했습니다. 김철수님은 특정한 주제에 대해 더 알고 싶으신지 물으셨습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/37/2rwxb6k520l4tqxzpx1nh8lh0000gn/T/ipykernel_36858/3396824294.py:19: LangChainBetaWarning: The class `RemoveMessage` is in beta. It is actively being worked on, so the API may change.\n",
      "  delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n"
     ]
    }
   ],
   "source": [
    "# 사용자 입력 메시지 객체 생성\n",
    "input_message = HumanMessage(\n",
    "    content=\"2025년 AI 트랜드 에 대해 좀 더 알아보고 있어요. 최근 기사를 읽고 있습니다.\"\n",
    ")\n",
    "\n",
    "# 메시지 내용 출력\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 이벤트 실시간 처리 및 업데이트 출력\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='2025년 AI 트랜드 에 대해 좀 더 알아보고 있어요. 최근 기사를 읽고 있습니다.', id='57375dc3-94b3-40e4-aff3-de9ef79695ec'),\n",
       "  AIMessage(content='2025년의 AI 트렌드는 여러 가지 흥미로운 방향으로 발전할 것으로 예상됩니다. 몇 가지 주요 트렌드를 소개해드릴게요:\\n\\n1. **AI의 민주화**: 더 많은 사람들이 AI 기술을 쉽게 접근하고 사용할 수 있도록 하는 도구와 플랫폼이 증가할 것입니다. 이는 비전문가도 AI를 활용할 수 있게 해줄 것입니다.\\n\\n2. **Explainable AI (XAI)**: AI의 결정 과정을 이해하고 설명할 수 있는 기술이 중요해질 것입니다. 이는 특히 의료, 금융 등 중요한 분야에서 신뢰성을 높이는 데 기여할 것입니다.\\n\\n3. **AI와 윤리**: AI의 윤리적 사용에 대한 논의가 더욱 활발해질 것입니다. 데이터 프라이버시, 편향성 문제 등을 해결하기 위한 규제와 가이드라인이 필요할 것입니다.\\n\\n4. **AI와 자동화**: 다양한 산업에서 AI를 활용한 자동화가 증가할 것입니다. 이는 생산성을 높이고 비용을 절감하는 데 기여할 것입니다.\\n\\n5. **인간-AI 협업**: AI와 인간이 협력하여 문제를 해결하는 방식이 더욱 중요해질 것입니다. AI는 반복적인 작업을 처리하고, 인간은 창의적이고 전략적인 결정을 내리는 역할을 할 것입니다.\\n\\n6. **AI의 지속 가능성**: 환경 문제 해결을 위한 AI의 역할이 강조될 것입니다. 에너지 효율성을 높이거나 기후 변화에 대응하는 데 AI가 활용될 것입니다.\\n\\n이 외에도 다양한 트렌드가 있을 수 있으니, 최신 기사를 통해 계속해서 정보를 업데이트하는 것이 좋습니다. 어떤 특정한 주제에 대해 더 알고 싶으신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 363, 'prompt_tokens': 175, 'total_tokens': 538, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run-96dc8681-ae42-470a-a168-660802aacbce-0', usage_metadata={'input_tokens': 175, 'output_tokens': 363, 'total_tokens': 538})],\n",
       " 'summary': '김철수님은 AI 엔지니어로서 2025년의 AI 트렌드에 대해 알아보고 있으며, 최근 기사를 읽고 있다고 하셨습니다. 이에 대해 저는 2025년의 주요 AI 트렌드로 AI의 민주화, Explainable AI (XAI), AI와 윤리, AI와 자동화, 인간-AI 협업, AI의 지속 가능성을 소개했습니다. 김철수님은 특정한 주제에 대해 더 알고 싶으신지 물으셨습니다.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상태 구성 값 검색\n",
    "values = app.get_state(config).values\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='2025년 AI 트랜드 에 대해 좀 더 알아보고 있어요. 최근 기사를 읽고 있습니다.', id='57375dc3-94b3-40e4-aff3-de9ef79695ec'),\n",
       " AIMessage(content='2025년의 AI 트렌드는 여러 가지 흥미로운 방향으로 발전할 것으로 예상됩니다. 몇 가지 주요 트렌드를 소개해드릴게요:\\n\\n1. **AI의 민주화**: 더 많은 사람들이 AI 기술을 쉽게 접근하고 사용할 수 있도록 하는 도구와 플랫폼이 증가할 것입니다. 이는 비전문가도 AI를 활용할 수 있게 해줄 것입니다.\\n\\n2. **Explainable AI (XAI)**: AI의 결정 과정을 이해하고 설명할 수 있는 기술이 중요해질 것입니다. 이는 특히 의료, 금융 등 중요한 분야에서 신뢰성을 높이는 데 기여할 것입니다.\\n\\n3. **AI와 윤리**: AI의 윤리적 사용에 대한 논의가 더욱 활발해질 것입니다. 데이터 프라이버시, 편향성 문제 등을 해결하기 위한 규제와 가이드라인이 필요할 것입니다.\\n\\n4. **AI와 자동화**: 다양한 산업에서 AI를 활용한 자동화가 증가할 것입니다. 이는 생산성을 높이고 비용을 절감하는 데 기여할 것입니다.\\n\\n5. **인간-AI 협업**: AI와 인간이 협력하여 문제를 해결하는 방식이 더욱 중요해질 것입니다. AI는 반복적인 작업을 처리하고, 인간은 창의적이고 전략적인 결정을 내리는 역할을 할 것입니다.\\n\\n6. **AI의 지속 가능성**: 환경 문제 해결을 위한 AI의 역할이 강조될 것입니다. 에너지 효율성을 높이거나 기후 변화에 대응하는 데 AI가 활용될 것입니다.\\n\\n이 외에도 다양한 트렌드가 있을 수 있으니, 최신 기사를 통해 계속해서 정보를 업데이트하는 것이 좋습니다. 어떤 특정한 주제에 대해 더 알고 싶으신가요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 363, 'prompt_tokens': 175, 'total_tokens': 538, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run-96dc8681-ae42-470a-a168-660802aacbce-0', usage_metadata={'input_tokens': 175, 'output_tokens': 363, 'total_tokens': 538})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = values[\"messages\"]\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "제 이름이 무엇인지 기억하세요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "네, 당신의 이름은 김철수님입니다. 도움이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 사용자 메시지 객체 생성\n",
    "input_message = HumanMessage(content=\"제 이름이 무엇인지 기억하세요?\")\n",
    "\n",
    "# 메시지 내용 출력\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 이벤트 실시간 처리 및 업데이트\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "제 직업도 혹시 기억하고 계세요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "네, 김철수님은 AI 엔지니어로 일하고 계십니다. AI와 관련된 주제에 대해 더 알고 싶으신 점이 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 사용자 메시지 객체 생성\n",
    "input_message = HumanMessage(content=\"제 직업도 혹시 기억하고 계세요?\")\n",
    "\n",
    "# 메시지 내용 출력\n",
    "input_message.pretty_print()\n",
    "\n",
    "# 스트림 이벤트 실시간 처리 및 업데이트 출력\n",
    "for event in app.stream({\"messages\": [input_message]}, config, stream_mode=\"updates\"):\n",
    "    print_update(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
