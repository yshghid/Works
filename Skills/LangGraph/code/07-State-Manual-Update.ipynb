{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY Loading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH21-LangGraph\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH21-LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Manual Update \n",
    "\n",
    "- LangGraph은 중간 단계의 State를 수동으로 업데이트 할 수 있는 방안을 제공함 \n",
    "- 이를 통해 에이전트 행동을 수정하여 경로를 제어할 수 있음 \n",
    "- 또한 에이전트의 실수를 수정하거나, 대체 경로를 탐색하는 것처럼 특정 목표에 따라 에이전트의 동작을 변경할 때 유용함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a09758/KDT/AI-Agent-대중소상생/skala_gai/.venv1/lib/python3.11/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_teddynote.graphs import visualize_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## 1. State ##########\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "########## 2. TOOLS ##########\n",
    "# 도구 초기화\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "# 도구 목록 정의\n",
    "tools = [tool]\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# LLM + 도구 \n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "########## 3. NODE ##########\n",
    "# 챗봇 함수 정의\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# Graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 도구 노드 생성 및 추가\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Conditional Edge\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "\n",
    "########## 4. EDGE ##########\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "\n",
    "########## 5. MEMORY ##########\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "########## 6. COMPILE  ##########\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "########## 7. VISUALIZE ##########\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"LangGraph 가 무엇인지 조사하여 알려주세요!\"\n",
    "\n",
    "# 초기 입력 상태를 정의\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "# config 설정\n",
    "config = RunnableConfig(\n",
    "    configurable={\"thread_id\": \"001\"},  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**channels**\n",
    "\n",
    "- LangGraph 내부에서 노드 간 데이터가 흐르는 경로(통로) \n",
    "- 각 노드의 입력과 출력을 연결하는 데이터 이동 경로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['messages', '__start__', 'branch:to:chatbot', 'branch:to:tools']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래프 채널 목록 출력\n",
    "list(graph.channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## interrupt 상태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 가 무엇인지 조사하여 알려주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_cxbuVl3tfpNPUcVfB73tNQXK)\n",
      " Call ID: call_cxbuVl3tfpNPUcVfB73tNQXK\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림 호출\n",
    "# 중단 지점(interrupt_before=[“tools”])에서 중간 상태 확인\n",
    "events = graph.stream(\n",
    "    input=input, config=config, interrupt_before=[\"tools\"], stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지의 예쁜 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_cxbuVl3tfpNPUcVfB73tNQXK)\n",
      " Call ID: call_cxbuVl3tfpNPUcVfB73tNQXK\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "# 그래프 상태 스냅샷 생성\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 가장 최근 메시지 추출\n",
    "last_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 출력\n",
    "last_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도구 결과 수동 수정\n",
    "\n",
    "- `TavilySearch` 도구에서 검색 결과 수정하여 새로운 ToolMessage 생성\n",
    "- tool_call_id를 기존 메시지에서 추출 후 동일 ID로 새 메시지 생성\n",
    "- 그래프 상태 업데이트 (graph.update_state)로 반영\n",
    "- 이후 흐름 계속 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "source": [
    "modified_search_result = \"\"\"[수정된 웹 검색 결과] \n",
    "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
    "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
    "\n",
    "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
    "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\"\"\"\n",
    "\n",
    "print(modified_search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_cxbuVl3tfpNPUcVfB73tNQXK\n"
     ]
    }
   ],
   "source": [
    "# 수정하고자 하는 `ToolMessage` 의 `tool_call_id` 추출\n",
    "tool_call_id = last_message.tool_calls[0][\"id\"]\n",
    "print(tool_call_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**메시지 타입**\n",
    "\n",
    "- HumanMessage : 사용자 입력 전달 \n",
    "- AIMessage : LLM의 텍스트 응답 메시지, 일반적인 대화 응답 \n",
    "- SystemMessage : 대화 설정 또는 시스템 프롬프트 \n",
    "- ToolMessage : 도구 실행 결과 메시지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "source": [
    "new_messages = [\n",
    "    # LLM API의 도구 호출과 일치하는 ToolMessage 필요\n",
    "    ToolMessage(\n",
    "        content=modified_search_result,\n",
    "        tool_call_id=tool_call_id,\n",
    "    ),\n",
    "    # LLM의 응답에 직접적으로 내용 추가\n",
    "    # AIMessage(content=modified_search_result),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StateGraph의 `update_state` \n",
    "\n",
    "- `update_state` : 주어진 값으로 그래프의 상태를 업데이트\n",
    "- 마치 `as_node`에서 값이 온 것처럼 동작함\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `config` (RunnableConfig): 실행 구성\n",
    "- `values` (Optional[Union[dict[str, Any], Any]]): 업데이트할 값들\n",
    "- `as_node` (Optional[str]): 값의 출처로 간주할 노드 이름. 기본값은 None\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- RunnableConfig\n",
    "\n",
    "**주요 기능**\n",
    "\n",
    "1. 체크포인터를 통해 이전 상태를 로드하고 새로운 상태를 저장\n",
    "2. 서브그래프에 대한 상태 업데이트를 처리\n",
    "3. `as_node`가 지정되지 않은 경우, 마지막으로 상태를 업데이트한 노드를 찾음\n",
    "4. 지정된 노드의 writer들을 실행하여 상태를 업데이트\n",
    "5. 업데이트된 상태를 체크포인트에 저장\n",
    "\n",
    "**주요 로직**\n",
    "\n",
    "1. 체크포인터를 확인하고, 없으면 ValueError를 발생시킴\n",
    "2. 서브그래프에 대한 업데이트인 경우, 해당 서브그래프의 `update_state` 메서드를 호출\n",
    "3. 이전 체크포인트를 로드하고, 필요한 경우 `as_node`를 결정\n",
    "4. 지정된 노드의 writer들을 사용하여 상태를 업데이트\n",
    "5. 업데이트된 상태를 새로운 체크포인트로 저장\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 이 메서드는 그래프의 상태를 수동으로 업데이트할 때 사용\n",
    "- 체크포인터를 사용하여 상태의 버전 관리와 지속성 보장\n",
    "- `as_node`를 지정하지 않으면 자동으로 결정되지만, 모호한 경우 오류가 발생할 수 있음\n",
    "- 상태 업데이트 중 SharedValues에 쓰기 작업은 허용되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(최근 1개의 메시지 출력)\n",
      "\n",
      "content='[수정된 웹 검색 결과] \\nLangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\\nLangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\\n\\n자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\\n[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.' id='7a5ee578-3449-494b-8492-eabdbdc4b10c' tool_call_id='call_cxbuVl3tfpNPUcVfB73tNQXK'\n"
     ]
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    # 업데이트할 상태 지정\n",
    "    config,\n",
    "    # 제공할 업데이트된 값. `State`의 메시지는 \"추가 전용\"으로 기존 상태에 추가됨\n",
    "    {\"messages\": new_messages},\n",
    "    as_node=\"tools\",\n",
    ")\n",
    "\n",
    "print(\"(최근 1개의 메시지 출력)\\n\")\n",
    "print(graph.get_state(config).values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatbot',)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 구축할 수 있도록 지원하는 오픈 소스 라이브러리입니다. 이 라이브러리는 LLM(대형 언어 모델)을 활용하여 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능 등을 제공합니다.\n",
      "\n",
      "더 자세한 정보와 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)과 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785)에서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 가 무엇인지 조사하여 알려주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_cxbuVl3tfpNPUcVfB73tNQXK)\n",
      " Call ID: call_cxbuVl3tfpNPUcVfB73tNQXK\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 구축할 수 있도록 지원하는 오픈 소스 라이브러리입니다. 이 라이브러리는 LLM(대형 언어 모델)을 활용하여 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능 등을 제공합니다.\n",
      "\n",
      "더 자세한 정보와 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)과 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785)에서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 최근 세 개의 메시지 출력\n",
    "for message in snapshot.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# 다음 상태 출력\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interrupt 후 메시지 상태 업데이트 \n",
    "\n",
    "- `TavilySearch` 도구에서 검색 쿼리 수정\n",
    "- `thread_id` : 랜덤한 해시값을 생성하는 `generate_random_hash` 함수를 사용하여 적용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_id: 429de3\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import generate_random_hash\n",
    "\n",
    "thread_id = generate_random_hash()\n",
    "print(f\"thread_id: {thread_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_uR6h7jVBHy2hObv0r1l0JxYF)\n",
      " Call ID: call_uR6h7jVBHy2hObv0r1l0JxYF\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "question = \"LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\"\n",
    "\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "events = graph.stream(\n",
    "    input=input,\n",
    "    config=config,\n",
    "    interrupt_before=[\"tools\"],\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 를 복사\n",
    "config_copy = config.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID run--b458ab8c-e1ae-40c7-9f7b-7830ea3e40cb-0\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 스냅샷 상태 \n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# messages 의 마지막 메시지 \n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"Message ID\", existing_message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph'}, 'id': 'call_uR6h7jVBHy2hObv0r1l0JxYF', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 도구 호출 출력\n",
    "print(existing_message.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph Studio'},\n",
       " 'id': 'call_uR6h7jVBHy2hObv0r1l0JxYF',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool_calls 를 복사하여 새로운 도구 호출 생성\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "\n",
    "# 쿼리 매개변수 업데이트\n",
    "new_tool_call[\"args\"] = {\"query\": \"LangGraph Studio\"}\n",
    "new_tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run--b458ab8c-e1ae-40c7-9f7b-7830ea3e40cb-0\n"
     ]
    }
   ],
   "source": [
    "# AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    id=existing_message.id,  # ID는 메시지를 상태에 추가하는 대신 교체하는 방법으로 처리 (별5개)\n",
    ")\n",
    "\n",
    "print(new_message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_uR6h7jVBHy2hObv0r1l0JxYF)\n",
      " Call ID: call_uR6h7jVBHy2hObv0r1l0JxYF\n",
      "  Args:\n",
      "    query: LangGraph Studio\n"
     ]
    }
   ],
   "source": [
    "# 수정한 메시지 출력\n",
    "new_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph Studio'}, 'id': 'call_uR6h7jVBHy2hObv0r1l0JxYF', 'type': 'tool_call'}\n",
      "\n",
      "Message ID run--b458ab8c-e1ae-40c7-9f7b-7830ea3e40cb-0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '429de3',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f052f87-712d-600e-8002-7f65f41b3ec7'}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트된 도구 호출 출력\n",
    "print(new_message.tool_calls[0])\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"\\nMessage ID\", new_message.id)\n",
    "\n",
    "# 상태 업데이트\n",
    "graph.update_state(config, {\"messages\": [new_message]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph Studio'},\n",
       "  'id': 'call_uR6h7jVBHy2hObv0r1l0JxYF',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마지막 메시지의 도구 호출 가져오기\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_uR6h7jVBHy2hObv0r1l0JxYF)\n",
      " Call ID: call_uR6h7jVBHy2hObv0r1l0JxYF\n",
      "  Args:\n",
      "    query: LangGraph Studio\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"LangGraph Studio\", \"url\": \"https://langchain-ai.lang.chat/langgraph/concepts/langgraph_studio/\", \"content\": \"LangGraph Studio is a specialized agent IDE that enables visualization, interaction, and debugging of agentic systems that implement the LangGraph Server API protocol. Studio also integrates with LangSmith to enable tracing, evaluation, and prompt engineering. Features¶ Key features of LangGraph Studio: Visualize your graph architecture\", \"score\": 0.95176035, \"raw_content\": \"![logo](../../static/wordmark_dark.svg)\\n![logo](../../static/wordmark_light.svg)\\n![logo](../../static/wordmark_dark.svg)\\n![logo](../../static/wordmark_light.svg)\\n\\n# LangGraph Studio[¶](#langgraph-studio \\\"Permanent link\\\")\\n\\nPrerequisites\\n\\nLangGraph Studio is a specialized agent IDE that enables visualization, interaction, and debugging of agentic systems that implement the LangGraph Server API protocol. Studio also integrates with LangSmith to enable tracing, evaluation, and prompt engineering.\\n\\n![](../img/lg_studio.png)\\n\\n![](../img/lg_studio.png)\\n\\n## Features[¶](#features \\\"Permanent link\\\")\\n\\nKey features of LangGraph Studio:\\n\\nLangGraph Studio works for graphs that are deployed on [LangGraph Platform](../../cloud/quick_start/) or for graphs that are running locally via the [LangGraph Server](../../tutorials/langgraph-platform/local-server/).\\n\\nStudio supports two modes:\\n\\n### Graph mode[¶](#graph-mode \\\"Permanent link\\\")\\n\\nGraph mode exposes the full feature-set of Studio and is useful when you would like as many details about the execution of your agent, including the nodes traversed, intermediate states, and LangSmith integrations (such as adding to datasets and playground).\\n\\n### Chat mode[¶](#chat-mode \\\"Permanent link\\\")\\n\\nChat mode is a simpler UI for iterating on and testing chat-specific agents. It is useful for business users and those who want to test overall agent behavior. Chat mode is only supported for graph's whose state includes or extends [`MessagesState`](https://langchain-ai.lang.chat/langgraph/how-tos/graph-api/#messagesstate).\\n\\n`MessagesState`\\n\\n## Learn more[¶](#learn-more \\\"Permanent link\\\")\"}, {\"title\": \"langchain-ai/langgraph-studio - GitHub\", \"url\": \"https://github.com/langchain-ai/langgraph-studio\", \"content\": \"[Skip to content](https://github.com/langchain-ai/langgraph-studio#start-of-content) *   [Code](https://github.com/langchain-ai/langgraph-studio) *   [Issues 47](https://github.com/langchain-ai/langgraph-studio/issues) *   [Pull requests 0](https://github.com/langchain-ai/langgraph-studio/pulls) *   [Discussions](https://github.com/langchain-ai/langgraph-studio/discussions) *   [Actions](https://github.com/langchain-ai/langgraph-studio/actions) [There was an error while loading.](https://github.com/langchain-ai/langgraph-studio/security)Please reload this page. *   [Insights](https://github.com/langchain-ai/langgraph-studio/pulse) *   [Code](https://github.com/langchain-ai/langgraph-studio) *   [Issues](https://github.com/langchain-ai/langgraph-studio/issues) *   [Pull requests](https://github.com/langchain-ai/langgraph-studio/pulls) *   [Discussions](https://github.com/langchain-ai/langgraph-studio/discussions) *   [Actions](https://github.com/langchain-ai/langgraph-studio/actions) *   [Security](https://github.com/langchain-ai/langgraph-studio/security) *   [Insights](https://github.com/langchain-ai/langgraph-studio/pulse) *   [README](https://github.com/langchain-ai/langgraph-studio#) [](https://github.com/langchain-ai/langgraph-studio#langgraph-studio-desktop-beta) [](https://github.com/langchain-ai/langgraph-studio#download) Download the latest `.dmg` file of LangGraph Studio by clicking [here](https://langgraph-studio.vercel.app/api/mac/latest) or by visiting the [releases page](https://github.com/langchain-ai/langgraph-studio/releases). [](https://github.com/langchain-ai/langgraph-studio#setup) [](https://github.com/langchain-ai/langgraph-studio#open-a-project) [![Image 6: Graph Screen](https://github.com/langchain-ai/langgraph-studio/raw/main/img/graph_screen.png)](https://github.com/langchain-ai/langgraph-studio/blob/main/img/graph_screen.png) [](https://github.com/langchain-ai/langgraph-studio#invoke-graph) [](https://github.com/langchain-ai/langgraph-studio#start-a-new-run) [](https://github.com/langchain-ai/langgraph-studio#configure-graph-run) [](https://github.com/langchain-ai/langgraph-studio#create-and-edit-threads) [](https://github.com/langchain-ai/langgraph-studio#create-a-thread) [](https://github.com/langchain-ai/langgraph-studio#select-a-thread) [](https://github.com/langchain-ai/langgraph-studio#edit-thread-state) [](https://github.com/langchain-ai/langgraph-studio#how-to-add-interrupts-to-your-graph) [](https://github.com/langchain-ai/langgraph-studio#add-interrupts-to-a-list-of-nodes) [](https://github.com/langchain-ai/langgraph-studio#add-interrupt-to-a-specific-node) [](https://github.com/langchain-ai/langgraph-studio#human-in-the-loop) [](https://github.com/langchain-ai/langgraph-studio#edit-project-config) [](https://github.com/langchain-ai/langgraph-studio#edit-graph-code) [](https://github.com/langchain-ai/langgraph-studio#troubleshooting) [](https://github.com/langchain-ai/langgraph-studio#how-do-i-access-local-services-and-models-such-as-ollama-chroma-etc) See [#112](https://github.com/langchain-ai/langgraph-studio/issues/112) for more details. [](https://github.com/langchain-ai/langgraph-studio#failing-to-install-native-dependencies-during-build) [Readme](https://github.com/langchain-ai/langgraph-studio#readme-ov-file) [Activity](https://github.com/langchain-ai/langgraph-studio/activity) [Custom properties](https://github.com/langchain-ai/langgraph-studio/custom-properties) [**2.9k** stars](https://github.com/langchain-ai/langgraph-studio/stargazers) [**32** watching](https://github.com/langchain-ai/langgraph-studio/watchers) [**188** forks](https://github.com/langchain-ai/langgraph-studio/forks) [Releases 31](https://github.com/langchain-ai/langgraph-studio/releases) [0.0.37 Latest Mar 11, 2025](https://github.com/langchain-ai/langgraph-studio/releases/tag/v0.0.37) [+ 30 releases](https://github.com/langchain-ai/langgraph-studio/releases) [Contributors 9](https://github.com/langchain-ai/langgraph-studio/graphs/contributors)\", \"score\": 0.7668008, \"raw_content\": \"GitHub - langchain-ai/langgraph-studio: Desktop app for prototyping and debugging LangGraph applications locally.\\n\\n===============\\n\\n[Skip to content](https://github.com/langchain-ai/langgraph-studio#start-of-content)\\nNavigation Menu\\n---------------\\n\\nToggle navigation\\n\\n[](https://github.com/)\\n\\n[Sign in](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Flanggraph-studio)\\n\\nAppearance settings\\n\\n*    Product \\n\\n    *   [GitHub Copilot Write better code with AI](https://github.com/features/copilot)\\n    *   [GitHub Models New Manage and compare prompts](https://github.com/features/models)\\n    *   [GitHub Advanced Security Find and fix vulnerabilities](https://github.com/security/advanced-security)\\n    *   [Actions Automate any workflow](https://github.com/features/actions)\\n    *   [Codespaces Instant dev environments](https://github.com/features/codespaces)\\n\\n    *   [Issues Plan and track work](https://github.com/features/issues)\\n    *   [Code Review Manage code changes](https://github.com/features/code-review)\\n    *   [Discussions Collaborate outside of code](https://github.com/features/discussions)\\n    *   [Code Search Find more, search less](https://github.com/features/code-search)\\n\\nExplore\\n    *   [Why GitHub](https://github.com/why-github)\\n    *   [All features](https://github.com/features)\\n    *   [Documentation](https://docs.github.com/)\\n    *   [GitHub Skills](https://skills.github.com/)\\n    *   [Blog](https://github.blog/)\\n\\n*    Solutions \\n\\nBy company size\\n    *   [Enterprises](https://github.com/enterprise)\\n    *   [Small and medium teams](https://github.com/team)\\n    *   [Startups](https://github.com/enterprise/startups)\\n    *   [Nonprofits](https://github.com/solutions/industry/nonprofits)\\n\\nBy use case\\n    *   [DevSecOps](https://github.com/solutions/use-case/devsecops)\\n    *   [DevOps](https://github.com/solutions/use-case/devops)\\n    *   [CI/CD](https://github.com/solutions/use-case/ci-cd)\\n    *   [View all use cases](https://github.com/solutions/use-case)\\n\\nBy industry\\n    *   [Healthcare](https://github.com/solutions/industry/healthcare)\\n    *   [Financial services](https://github.com/solutions/industry/financial-services)\\n    *   [Manufacturing](https://github.com/solutions/industry/manufacturing)\\n    *   [Government](https://github.com/solutions/industry/government)\\n    *   [View all industries](https://github.com/solutions/industry)\\n\\n[View all solutions](https://github.com/solutions)\\n\\n*    Resources \\n\\nTopics\\n    *   [AI](https://github.com/resources/articles/ai)\\n    *   [DevOps](https://github.com/resources/articles/devops)\\n    *   [Security](https://github.com/resources/articles/security)\\n    *   [Software Development](https://github.com/resources/articles/software-development)\\n    *   [View all](https://github.com/resources/articles)\\n\\nExplore\\n    *   [Learning Pathways](https://resources.github.com/learn/pathways)\\n    *   [Events & Webinars](https://resources.github.com/)\\n    *   [Ebooks & Whitepapers](https://github.com/resources/whitepapers)\\n    *   [Customer Stories](https://github.com/customer-stories)\\n    *   [Partners](https://partner.github.com/)\\n    *   [Executive Insights](https://github.com/solutions/executive-insights)\\n\\n*    Open Source \\n\\n    *   [GitHub Sponsors Fund open source developers](https://github.com/sponsors)\\n\\n    *   [The ReadME Project GitHub community articles](https://github.com/readme)\\n\\nRepositories\\n    *   [Topics](https://github.com/topics)\\n    *   [Trending](https://github.com/trending)\\n    *   [Collections](https://github.com/collections)\\n\\n*    Enterprise \\n\\n    *   [Enterprise platform AI-powered developer platform](https://github.com/enterprise)\\n\\nAvailable add-ons\\n    *   [GitHub Advanced Security Enterprise-grade security features](https://github.com/security/advanced-security)\\n    *   [Copilot for business Enterprise-grade AI features](https://github.com/features/copilot/copilot-business)\\n    *   [Premium Support Enterprise-grade 24/7 support](https://github.com/premium-support)\\n\\n*   [Pricing](https://github.com/pricing)\\n\\nSearch or jump to...\\n\\nSearch code, repositories, users, issues, pull requests...\\n==========================================================\\n\\n Search  \\n\\nClear\\n\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n\\nProvide feedback\\n================\\n\\nWe read every piece of feedback, and take your input very seriously.\\n\\n- [x] Include my email address so I can be contacted \\n\\n Cancel  Submit feedback \\n\\nSaved searches\\n==============\\n\\nUse saved searches to filter your results more quickly\\n------------------------------------------------------\\n\\nName \\n\\nQuery \\n\\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\\n\\n Cancel  Create saved search \\n\\n[Sign in](https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Flanggraph-studio)\\n\\n[Sign up](https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=langchain-ai%2Flanggraph-studio)\\n\\nAppearance settings\\n\\nResetting focus\\n\\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\\n\\n{{ message }}\\n\\n[langchain-ai](https://github.com/langchain-ai)/**[langgraph-studio](https://github.com/langchain-ai/langgraph-studio)**Public\\n\\n*   [Notifications](https://github.com/login?return_to=%2Flangchain-ai%2Flanggraph-studio)You must be signed in to change notification settings\\n*   [Fork 188](https://github.com/login?return_to=%2Flangchain-ai%2Flanggraph-studio)\\n*   [Star 2.9k](https://github.com/login?return_to=%2Flangchain-ai%2Flanggraph-studio) \\n\\nDesktop app for prototyping and debugging LangGraph applications locally.\\n\\n[studio.langchain.com](https://studio.langchain.com/ \\\"https://studio.langchain.com\\\")\\n\\n[2.9k stars](https://github.com/langchain-ai/langgraph-studio/stargazers)[188 forks](https://github.com/langchain-ai/langgraph-studio/forks)[Branches](https://github.com/langchain-ai/langgraph-studio/branches)[Tags](https://github.com/langchain-ai/langgraph-studio/tags)[Activity](https://github.com/langchain-ai/langgraph-studio/activity)\\n\\n[Star](https://github.com/login?return_to=%2Flangchain-ai%2Flanggraph-studio)\\n\\n[Notifications](https://github.com/login?return_to=%2Flangchain-ai%2Flanggraph-studio)You must be signed in to change notification settings\\n\\n*   [Code](https://github.com/langchain-ai/langgraph-studio)\\n*   [Issues 47](https://github.com/langchain-ai/langgraph-studio/issues)\\n*   [Pull requests 0](https://github.com/langchain-ai/langgraph-studio/pulls)\\n*   [Discussions](https://github.com/langchain-ai/langgraph-studio/discussions)\\n*   [Actions](https://github.com/langchain-ai/langgraph-studio/actions)\\n*   [Security](https://github.com/langchain-ai/langgraph-studio/security)[](https://github.com/langchain-ai/langgraph-studio/security)[](https://github.com/langchain-ai/langgraph-studio/security)[](https://github.com/langchain-ai/langgraph-studio/security)[### Uh oh!](https://github.com/langchain-ai/langgraph-studio/security)\\n[There was an error while loading.](https://github.com/langchain-ai/langgraph-studio/security)Please reload this page.    \\n*   [Insights](https://github.com/langchain-ai/langgraph-studio/pulse)\\n\\nAdditional navigation options\\n\\n*   [Code](https://github.com/langchain-ai/langgraph-studio)\\n*   [Issues](https://github.com/langchain-ai/langgraph-studio/issues)\\n*   [Pull requests](https://github.com/langchain-ai/langgraph-studio/pulls)\\n*   [Discussions](https://github.com/langchain-ai/langgraph-studio/discussions)\\n*   [Actions](https://github.com/langchain-ai/langgraph-studio/actions)\\n*   [Security](https://github.com/langchain-ai/langgraph-studio/security)\\n*   [Insights](https://github.com/langchain-ai/langgraph-studio/pulse)\\n\\nlangchain-ai/langgraph-studio\\n=============================\\n\\nmain\\n\\n[Branches](https://github.com/langchain-ai/langgraph-studio/branches)[Tags](https://github.com/langchain-ai/langgraph-studio/tags)\\n\\n[](https://github.com/langchain-ai/langgraph-studio/branches)[](https://github.com/langchain-ai/langgraph-studio/tags)\\n\\nGo to file\\n\\nCode\\n\\nFolders and files\\n-----------------\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| Latest commit ------------- History ------- [52 Commits](https://github.com/langchain-ai/langgraph-studio/commits/main/) [](https://github.com/langchain-ai/langgraph-studio/commits/main/) |\\n| [img](https://github.com/langchain-ai/langgraph-studio/tree/main/img \\\"img\\\") | [img](https://github.com/langchain-ai/langgraph-studio/tree/main/img \\\"img\\\") |  |  |\\n| [README.md](https://github.com/langchain-ai/langgraph-studio/blob/main/README.md \\\"README.md\\\") | [README.md](https://github.com/langchain-ai/langgraph-studio/blob/main/README.md \\\"README.md\\\") |  |  |\\n| [cover.svg](https://github.com/langchain-ai/langgraph-studio/blob/main/cover.svg \\\"cover.svg\\\") | [cover.svg](https://github.com/langchain-ai/langgraph-studio/blob/main/cover.svg \\\"cover.svg\\\") |  |  |\\n| View all files |\\n\\nRepository files navigation\\n---------------------------\\n\\n*   [README](https://github.com/langchain-ai/langgraph-studio#)\\n\\n[![Image 1: LangGraph Studio](https://github.com/langchain-ai/langgraph-studio/raw/main/cover.svg)](https://github.com/langchain-ai/langgraph-studio/blob/main/cover.svg)\\n\\nLangGraph Studio Desktop (Beta)\\n===============================\\n\\n[](https://github.com/langchain-ai/langgraph-studio#langgraph-studio-desktop-beta)\\n\\nLangGraph Studio offers a new way to develop LLM applications by providing a specialized agent IDE that enables visualization, interaction, and debugging of complex agentic applications\\n\\nWith visual graphs and the ability to edit state, you can better understand agent workflows and iterate faster. LangGraph Studio integrates with [LangSmith](https://smith.langchain.com/) so you can collaborate with teammates to debug failure modes.\\n\\nWhile in Beta, LangGraph Studio is available for free to all LangSmith users on any plan tier. [Sign up for LangSmith here](http://smith.langchain.com/).\\n\\nNote\\n\\nWe recommend that users [run a local LangGraph server and use the web version of LangGraph Studio](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/) instead of using the LangGraph Studio Desktop application. This is a newer feature that improves the development experience, as it works without Docker, significantly shortens startup times, supports code hot-reloading, and works across all platforms.\\n\\n[![Image 2: intro.gif](https://github.com/langchain-ai/langgraph-studio/raw/main/img/intro.gif)](https://github.com/langchain-ai/langgraph-studio/blob/main/img/intro.gif)[![Image 3: intro.gif](https://github.com/langchain-ai/langgraph-studio/raw/main/img/intro.gif)](https://github.com/langchain-ai/langgraph-studio/blob/main/img/intro.gif)[](https://github.com/langchain-ai/langgraph-studio/blob/main/img/intro.gif)\\n\\nDownload\\n--------\\n\\n[](https://github.com/langchain-ai/langgraph-studio#download)\\n\\nDownload the latest `.dmg` file of LangGraph Studio by clicking [here](https://langgraph-studio.vercel.app/api/mac/latest) or by visiting the [releases page](https://github.com/langchain-ai/langgraph-studio/releases).\\n\\nThe desktop application only supports macOS. Other users can [run a local LangGraph server and use the web studio](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/#langgraph-studio-web-ui). We also depend on Docker Engine to be running, currently we only support the following runtimes:\\n\\n*   [Docker Desktop](https://docs.docker.com/engine/install/)\\n*   [Orbstack](https://orbstack.dev/)\\n\\nSetup\\n-----\\n\\n[](https://github.com/langchain-ai/langgraph-studio#setup)\\n\\nLangGraph Studio requires docker-compose version 2.22.0+ or higher. Please make sure you have [Docker Desktop](https://docs.docker.com/engine/install/) or [Orbstack](https://orbstack.dev/) installed and running before continuing.\\n\\nTo use LangGraph Studio, make sure you have a [project with a LangGraph app](https://langchain-ai.github.io/langgraph/cloud/deployment/setup/) set up.\\n\\nFor this example, we will use this example repository [here](https://github.com/langchain-ai/langgraph-example) which uses a `requirements.txt` file for dependencies:\\n\\nundefinedshell\\ngit clone https://github.com/langchain-ai/langgraph-example.git\\nundefined\\n\\nIf you would like to use a `pyproject.toml` file instead for managing dependencies, you can use [this](https://github.com/langchain-ai/langgraph-example-pyproject) example repository.\\n\\nundefinedshell\\ngit clone https://github.com/langchain-ai/langgraph-example-pyproject.git\\nundefined\\n\\nYou will then want to create a `.env` file with the relevant environment variables:\\n\\nundefinedshell\\ncp .env.example .env\\nundefined\\n\\nYou should then open up the `.env` file and fill in with relevant OpenAI, Anthropic, and [Tavily](https://app.tavily.com/sign-in) API keys.\\n\\nIf you already have them set in your environment, you can save them to this .env file with the following commands:\\n\\nundefinedshell\\necho \\\"OPENAI_API_KEY=\\\\\\\"$OPENAI_API_KEY\\\\\\\"\\\" > .env\\necho \\\"ANTHROPIC_API_KEY=\\\\\\\"$ANTHROPIC_API_KEY\\\\\\\"\\\" >> .env\\necho \\\"TAVILY_API_KEY=\\\\\\\"$TAVILY_API_KEY\\\\\\\"\\\" >> .env\\nundefined\\n\\n**Note: do NOT add a LANGSMITH_API_KEY to the .env file.** We will do this automatically for you when you authenticate, and manually setting this may cause errors.\\n\\nOnce you've set up the project, you can use it in LangGraph Studio. Let's dive in!\\n\\nOpen a project\\n--------------\\n\\n[](https://github.com/langchain-ai/langgraph-studio#open-a-project)\\n\\nWhen you open LangGraph Studio desktop app for the first time, you need to login via LangSmith.\\n\\n[![Image 4: Login Screen](https://github.com/langchain-ai/langgraph-studio/raw/main/img/login_screen.png)](https://github.com/langchain-ai/langgraph-studio/blob/main/img/login_screen.png)\\n\\nOnce you have successfully authenticated, you can choose the LangGraph application folder to use — you can either drag and drop or manually select it in the file picker. If you are using the example project, the folder would be `langgraph-example`.\\n\\nImportant\\n\\nThe application directory you select needs to contain correctly configured `langgraph.json` file. See more information on how to configure it [here](https://langchain-ai.github.io/langgraph/cloud/reference/cli/#configuration-file) and how to set up a LangGraph app [here](https://langchain-ai.github.io/langgraph/cloud/deployment/setup/).\\n\\n[![Image 5: Select Project Screen](https://github.com/langchain-ai/langgraph-studio/raw/main/img/select_project_screen.png)](https://github.com/langchain-ai/langgraph-studio/blob/main/img/select_project_screen.png)\\n\\nOnce you select a valid project, LangGraph Studio will start a LangGraph API server and you should see a UI with your graph rendered.\\n\\n[![Image 6: Graph Screen](https://github.com/langchain-ai/langgraph-studio/raw/main/img/graph_screen.png)](https://github.com/langchain-ai/langgraph-studio/blob/main/img/graph_screen.png)\\n\\nInvoke graph\\n------------\\n\\n[](https://github.com/langchain-ai/langgraph-studio#invoke-graph)\\n\\nNow we can run the graph! LangGraph Studio lets you run your graph with different inputs and configurations.\\n\\n### Start a new run\\n\\n[](https://github.com/langchain-ai/langgraph-studio#start-a-new-run)\\n\\nTo start a new run:\\n\\n1.   In the dropdown menu (top-left corner of the left-hand pane), select a graph. In our example the graph is called `agent`. The list of graphs corresponds to the `graphs` keys in your `langgraph.json` configuration.\\n2.   In the bottom of the left-hand pane, edit the `Input` section.\\n3.   Click `Submit` to invoke the selected graph.\\n4.   View output of the invocation in the right-hand pane.\\n\\nThe following video shows how to start a new run:\\n\\ngraph_invoke.mp4\\n\\n### Configure graph run\\n\\n[](https://github.com/langchain-ai/langgraph-studio#configure-graph-run)\\n\\nTo change configuration for a given graph run, press `Configurable` button in the `Input` section. Then click `Submit` to invoke the graph.\\n\\nImportant\\n\\nIn order for the `Configurable` menu to be visible, make sure to specify config schema when creating `StateGraph`. You can read more about how to add config schema to your graph [here](https://langchain-ai.github.io/langgraph/how-tos/configuration/#configure-the-graph).\\n\\nThe following video shows how to edit configuration and start a new run:\\n\\ngraph_config.mp4\\n\\nCreate and edit threads\\n-----------------------\\n\\n[](https://github.com/langchain-ai/langgraph-studio#create-and-edit-threads)\\n\\n### Create a thread\\n\\n[](https://github.com/langchain-ai/langgraph-studio#create-a-thread)\\n\\nWhen you open LangGraph Studio, you will automatically be in a new thread window. If you have an existing thread open, follow these steps to create a new thread:\\n\\n1.   In the top-right corner of the right-hand pane, press `+` to open a new thread menu.\\n\\nThe following video shows how to create a thread:\\n\\ncreate_thread.mp4\\n\\n### Select a thread\\n\\n[](https://github.com/langchain-ai/langgraph-studio#select-a-thread)\\n\\nTo select a thread:\\n\\n1.   Click on `New Thread` / `Thread <thread-id>` label at the top of the right-hand pane to open a thread list dropdown.\\n2.   Select a thread that you wish to view / edit.\\n\\nThe following video shows how to select a thread:\\n\\nselect_thread.mp4\\n\\n### Edit thread state\\n\\n[](https://github.com/langchain-ai/langgraph-studio#edit-thread-state)\\n\\nLangGraph Studio allows you to edit the thread state and fork the threads to create alternative graph execution with the updated state. To do it:\\n\\n1.   Select a thread you wish to edit.\\n2.   In the right-hand pane hover over the step you wish to edit and click on \\\"pencil\\\" icon to edit.\\n3.   Make your edits.\\n4.   Click `Fork` to update the state and create a new graph execution with the updated state.\\n\\nThe following video shows how to edit a thread in the studio:\\n\\nfork_thread.mp4\\n\\nHow to add interrupts to your graph\\n-----------------------------------\\n\\n[](https://github.com/langchain-ai/langgraph-studio#how-to-add-interrupts-to-your-graph)\\n\\nYou might want to execute your graph step by step, or stop graph execution before/after a specific node executes. You can do so by adding interrupts. Interrupts can be set for all nodes (i.e. walk through the agent execution step by step) or for specific nodes. An interrupt in LangGraph Studio means that the graph execution will be interrupted both before and after a given node runs.\\n\\n### Add interrupts to a list of nodes\\n\\n[](https://github.com/langchain-ai/langgraph-studio#add-interrupts-to-a-list-of-nodes)\\n\\nTo walk through the agent execution step by step, you can add interrupts to a all or a subset of nodes in the graph:\\n\\n1.   In the dropdown menu (top-right corner of the left-hand pane), click `Interrupt`.\\n2.   Select a subset of nodes to interrupt on, or click `Interrupt on all`.\\n\\nThe following video shows how to add interrupts to all nodes:\\n\\ngraph_interrupts_all.mp4\\n\\n### Add interrupt to a specific node\\n\\n[](https://github.com/langchain-ai/langgraph-studio#add-interrupt-to-a-specific-node)\\n\\n1.   Navigate to the left-hand pane with the graph visualization.\\n2.   Hover over a node you want to add an interrupt to. You should see a `+` button show up on the left side of the node.\\n3.   Click `+` to invoke the selected graph.\\n4.   Run the graph by adding `Input` / configuration and clicking `Submit`\\n\\nThe following video shows how to add interrupts to a specific node:\\n\\ngraph_interrupts.mp4\\n\\nTo remove the interrupt, simply follow the same step and press `x` button on the left side of the node.\\n\\nHuman-in-the-loop\\n-----------------\\n\\n[](https://github.com/langchain-ai/langgraph-studio#human-in-the-loop)\\n\\nIn addition to interrupting on a node and editing the graph state, you might want to support human-in-the-loop workflows with the ability to manually update state. Here is a modified version of `agent.py` with `agent` and `human` nodes, where the graph execution will be interrupted on `human` node. This will let you send input as part of the `human` node. This can be useful when you want the agent to get user input. This essentially replaces how you might use `input()` if you were running this from the command line.\\n\\nundefinedpython\\nfrom typing import Literal\\n\\nfrom langchain_openai import ChatOpenAI\\nfrom langgraph.graph import MessagesState, StateGraph, END\\nfrom langgraph.types import Command, interrupt\\n\\nmodel = ChatOpenAI(temperature=0, model_name=\\\"gpt-4o\\\")\\n\\ndef call_model(state: MessagesState) -> Command[Literal[\\\"human\\\", END]]:\\n    messages = state[\\\"messages\\\"]\\n    response = model.invoke(messages)\\n\\n    return Command(\\n        goto=\\\"human\\\",\\n        update={\\\"messages\\\": [response]},\\n    )\\n\\ndef human_feedback(state: MessagesState) -> Command[Literal[\\\"agent\\\"]]:\\n    \\\"\\\"\\\"A node for collecting user input.\\\"\\\"\\\"\\n    print(\\\"Waiting for user input...\\\")\\n    user_input = interrupt(value=\\\"Ready for user input.\\\")\\n\\n    print(\\\"user input:\\\", user_input)\\n\\n    return Command(\\n        goto=\\\"agent\\\",\\n        update={\\n            \\\"messages\\\": [\\n                {\\n                    \\\"role\\\": \\\"human\\\",\\n                    \\\"content\\\": user_input,\\n                }\\n            ]\\n        },\\n    )\\n\\nworkflow = StateGraph(MessagesState)\\nworkflow.set_entry_point(\\\"agent\\\")\\nworkflow.add_node(\\\"agent\\\", call_model)\\nworkflow.add_node(\\\"human\\\", human_feedback)\\n\\ngraph = workflow.compile()\\nundefined\\n\\nThe following video shows how to manually send state updates (i.e. messages in our example) when interrupted:\\n\\ngraph_hitl.mp4\\n\\nEdit project config\\n-------------------\\n\\n[](https://github.com/langchain-ai/langgraph-studio#edit-project-config)\\n\\nLangGraph Studio allows you to modify your project config (`langgraph.json`) interactively.\\n\\nTo modify the config from the studio, follow these steps:\\n\\n1.   Click `Configure` on the bottom right. This will open an interactive config menu with the values that correspond to the existing `langgraph.json`.\\n2.   Make your edits.\\n3.   Click `Save and Restart` to reload the LangGraph API server with the updated config.\\n\\nThe following video shows how to edit project config from the studio:\\n\\ngraph_edit_json.mp4\\n\\nEdit graph code\\n---------------\\n\\n[](https://github.com/langchain-ai/langgraph-studio#edit-graph-code)\\n\\nWith LangGraph Studio you can modify your graph code and sync the changes live to the interactive graph.\\n\\nTo modify your graph from the studio, follow these steps:\\n\\n1.   Click `Open in VS Code` on the bottom right. This will open the project that is currently opened in LangGraph studio.\\n2.   Make changes to the `.py` files where the compiled graph is defined or associated dependencies.\\n3.   LangGraph studio will automatically reload once the changes are saved in the project directory.\\n\\nThe following video shows how to open code editor from the studio:\\n\\ngraph_edit_code.mp4\\n\\nAfter you modify the underlying code you can also replay a node in the graph. For example, if an agent responds poorly, you can update the agent node implementation in your code editor and rerun it. This can make it much easier to iterate on long-running agents.\\n\\nreplay.mp4\\n\\nTroubleshooting\\n---------------\\n\\n[](https://github.com/langchain-ai/langgraph-studio#troubleshooting)\\n\\n### How do I access local services and models such as Ollama, Chroma, etc?\\n\\n[](https://github.com/langchain-ai/langgraph-studio#how-do-i-access-local-services-and-models-such-as-ollama-chroma-etc)\\n\\nLangGraph Studio relies on Docker Compose to run the API, Redis and Postgres, which in turn creates its own network. Thus, to access local services you need to use `host.docker.internal` as the hostname instead of `localhost`. See [#112](https://github.com/langchain-ai/langgraph-studio/issues/112) for more details.\\n\\n### Failing to install native dependencies during build\\n\\n[](https://github.com/langchain-ai/langgraph-studio#failing-to-install-native-dependencies-during-build)\\n\\nBy default, we try to make the image as small as possible, thus some dependencies such as `gcc` or `build-essentials` are missing from the base image. If you need to install additional dependencies, you can do so by adding additional Dockerfile instructions in the `dockerfile_lines` section of your `langgraph.json` file:\\n\\n```\\n{\\n    \\\"dockerfile_lines\\\": [\\n        \\\"RUN apt-get update && apt-get install -y gcc\\\"\\n    ]\\n}\\n```\\n\\nSee [How to customize Dockerfile](https://langchain-ai.github.io/langgraph/cloud/deployment/custom_docker) for more details.\\n\\nAbout\\n-----\\n\\nDesktop app for prototyping and debugging LangGraph applications locally.\\n\\n[studio.langchain.com](https://studio.langchain.com/ \\\"https://studio.langchain.com\\\")\\n\\n### Topics\\n\\n[ai](https://github.com/topics/ai \\\"Topic: ai\\\")[desktop](https://github.com/topics/desktop \\\"Topic: desktop\\\")[agents](https://github.com/topics/agents \\\"Topic: agents\\\")[langgraph](https://github.com/topics/langgraph \\\"Topic: langgraph\\\")\\n\\n### Resources\\n\\n[Readme](https://github.com/langchain-ai/langgraph-studio#readme-ov-file)\\n\\n### Uh oh!\\n\\nThere was an error while loading. Please reload this page.\\n\\n[Activity](https://github.com/langchain-ai/langgraph-studio/activity)\\n\\n[Custom properties](https://github.com/langchain-ai/langgraph-studio/custom-properties)\\n\\n### Stars\\n\\n[**2.9k** stars](https://github.com/langchain-ai/langgraph-studio/stargazers)\\n\\n### Watchers\\n\\n[**32** watching](https://github.com/langchain-ai/langgraph-studio/watchers)\\n\\n### Forks\\n\\n[**188** forks](https://github.com/langchain-ai/langgraph-studio/forks)\\n\\n[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Flanggraph-studio&report=langchain-ai+%28user%29)\\n\\n[Releases 31](https://github.com/langchain-ai/langgraph-studio/releases)\\n------------------------------------------------------------------------\\n\\n[0.0.37 Latest Mar 11, 2025](https://github.com/langchain-ai/langgraph-studio/releases/tag/v0.0.37)\\n\\n[+ 30 releases](https://github.com/langchain-ai/langgraph-studio/releases)\\n\\n### Uh oh!\\n\\nThere was an error while loading. Please reload this page.\\n\\n[Contributors 9](https://github.com/langchain-ai/langgraph-studio/graphs/contributors)\\n--------------------------------------------------------------------------------------\\n\\n*   [![Image 7: @dqbd](https://avatars.githubusercontent.com/u/1443449?s=64&v=4)](https://github.com/dqbd)\\n*   [![Image 8: @hwchase17](https://avatars.githubusercontent.com/u/11986836?s=64&v=4)](https://github.com/hwchase17)\\n*   [![Image 9: @vbarda](https://avatars.githubusercontent.com/u/19161700?s=64&v=4)](https://github.com/vbarda)\\n*   [![Image 10: @Masstronaut](https://avatars.githubusercontent.com/u/9017393?s=64&v=4)](https://github.com/Masstronaut)\\n*   [![Image 11: @efriis](https://avatars.githubusercontent.com/u/9557659?s=64&v=4)](https://github.com/efriis)\\n*   [![Image 12: @nfcampos](https://avatars.githubusercontent.com/u/56902?s=64&v=4)](https://github.com/nfcampos)\\n*   [![Image 13: @andrewnguonly](https://avatars.githubusercontent.com/u/7654246?s=64&v=4)](https://github.com/andrewnguonly)\\n*   [![Image 14: @gfortaine](https://avatars.githubusercontent.com/u/15104841?s=64&v=4)](https://github.com/gfortaine)\\n*   [![Image 15: @isahers1](https://avatars.githubusercontent.com/u/78627776?s=64&v=4)](https://github.com/isahers1)\\n\\nFooter\\n------\\n\\n[](https://github.com/) © 2025 GitHub,Inc. \\n\\n### Footer navigation\\n\\n*   [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\\n*   [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\\n*   [Security](https://github.com/security)\\n*   [Status](https://www.githubstatus.com/)\\n*   [Docs](https://docs.github.com/)\\n*   [Contact](https://support.github.com/?tags=dotcom-footer)\\n*    Manage cookies \\n*    Do not share my personal information \\n\\n You can’t perform that action at this time.\\n\"}, {\"title\": \"LangGraph - LangChain\", \"url\": \"https://www.langchain.com/langgraph\", \"content\": \"Design agent-driven user experiences with LangGraph Platform's APIs. Quickly deploy and scale your application with infrastructure built for agents. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.” LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\", \"score\": 0.6383174, \"raw_content\": \"LangGraph\\n\\n===============\\n\\n![Image 1: Revisit consent button](https://uploads-ssl.webflow.com/65ff950538088944d66126b3/662ef3209b872e92e41212f6_cookieicon.png)\\n\\nWe value your privacy\\n\\nWe use cookies to analyze our traffic. By clicking \\\"Accept All\\\", you consent to our use of cookies.[Privacy Policy](https://www.langchain.com/privacy-policy)\\n\\nCustomize Reject All Accept All\\n\\nCustomize Consent Preferences![Image 2: Close](https://cdn-cookieyes.com/assets/images/close.svg)\\n\\nWe may use cookies to help you navigate efficiently and perform certain functions. You will find detailed information about all cookies under each consent category below.\\n\\nThe cookies that are categorized as \\\"Necessary\\\" are stored on your browser as they are essential for enabling the basic functionalities of the site....Show more\\n\\nNecessary Always Active\\n\\nNecessary cookies are required to enable the basic features of this site, such as providing secure log-in or adjusting your consent preferences. These cookies do not store any personally identifiable data.\\n\\nFunctional\\n\\n- [x] \\n\\nFunctional cookies help perform certain functionalities like sharing the content of the website on social media platforms, collecting feedback, and other third-party features.\\n\\nAnalytics\\n\\n- [x] \\n\\nAnalytical cookies are used to understand how visitors interact with the website. These cookies help provide information on metrics such as the number of visitors, bounce rate, traffic source, etc.\\n\\nPerformance\\n\\nPerformance cookies are used to understand and analyze the key performance indexes of the website which helps in delivering a better user experience for the visitors.\\n\\nAdvertisement\\n\\n- [x] \\n\\nAdvertisement cookies are used to provide visitors with customized advertisements based on the pages you visited previously and to analyze the effectiveness of the ad campaigns.\\n\\nUncategorized\\n\\n- [x] \\n\\nOther uncategorized cookies are those that are being analyzed and have not been classified into a category as yet.\\n\\n Reject All  Save My Preferences  Accept All \\n\\n[](https://www.langchain.com/)\\n\\nProducts\\n\\nFrameworks\\n\\n[LangGraph](https://www.langchain.com/langgraph)[LangChain](https://www.langchain.com/langchain)\\n\\nPlatforms\\n\\n[LangSmith](https://www.langchain.com/langsmith)[LangGraph Platform](https://www.langchain.com/langgraph-platform)\\n\\nResources\\n\\n[Resources Hub](https://www.langchain.com/resources)[Blog](https://blog.langchain.com/)[Customer Stories](https://www.langchain.com/customers)[LangChain Academy](https://academy.langchain.com/)[Community](https://www.langchain.com/community)[Experts](https://www.langchain.com/experts)[Changelog](https://changelog.langchain.com/)\\n\\nDocs\\n\\nPython\\n\\n[LangGraph](https://langchain-ai.github.io/langgraph/tutorials/introduction/)[LangSmith](https://docs.smith.langchain.com/)[LangChain](https://python.langchain.com/docs/introduction/)\\n\\nJavaScript\\n\\n[LangGraph](https://langchain-ai.github.io/langgraphjs/tutorials/quickstart/)[LangSmith](https://docs.smith.langchain.com/)[LangChain](https://js.langchain.com/docs/introduction/)\\n\\nCompany\\n\\n[About](https://www.langchain.com/about)[Careers](https://www.langchain.com/careers)\\n\\nPricing\\n\\n[LangSmith](https://www.langchain.com/pricing-langsmith)[LangGraph Platform](https://www.langchain.com/pricing-langgraph-platform)\\n\\n[Get a demo](https://www.langchain.com/contact-sales)\\n\\n[Sign up](https://smith.langchain.com/)\\n\\nBalance agent control with agency\\n=================================\\n\\nGain control with LangGraph to design agents \\n\\nthat reliably handle complex tasks.\\n\\n[Start building](https://langchain-ai.github.io/langgraph/)\\n\\n![Image 3](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66db8c2317fe5b9ad2b84ea0_lcacademylogo.png)\\nIntroduction to LangGraph\\n-------------------------\\n\\nLearn the basics of LangGraph in this LangChain Academy Course. You'll learn how to build agents that automate real-world tasks with LangGraph orchestration.\\n\\n[Enroll for free](https://academy.langchain.com/courses/intro-to-langgraph)[Book enterprise training](https://airtable.com/appGjCAN6126Jm7K8/pagNAp7niHQzRH8zk/form)\\n\\nTrusted by companies shaping the future of agents\\n-------------------------------------------------\\n\\n[See LangGraph use cases in production](https://www.langchain.com/built-with-langgraph)\\n\\n![Image 4](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1aa251143166667aec3_logo_Rakuten.svg)\\n\\n![Image 5](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1d39b2c6c806093f171_GitLab_logo_(2)%201.svg)\\n\\n![Image 6](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg)\\n\\n![Image 7](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1ddfdc1291f495b3697_AppFolio%2C_Inc._Wordmark%2C_2021%201.svg)\\n\\n![Image 8](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/680b77461846a7cf254d8391_Klarna_Logo_black%201.svg)\\n\\n![Image 9](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/681b568070e9f341ed73b877_logo_Cisco.svg)\\n\\n![Image 10](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d206eefdb37789451855_The_Home_Depot-Logo.wine%201.svg)\\n\\n![Image 11](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg)\\n\\n![Image 12](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d18a7cef47c38c0eeb48_C._H._Robinson_logo%201.svg)\\n\\n![Image 13](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1ee0c9249f8c32e645d_logo_Komodo.svg)\\n\\n![Image 14](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1aa251143166667aec3_logo_Rakuten.svg)\\n\\n![Image 15](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1d39b2c6c806093f171_GitLab_logo_(2)%201.svg)\\n\\n![Image 16](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg)\\n\\n![Image 17](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1ddfdc1291f495b3697_AppFolio%2C_Inc._Wordmark%2C_2021%201.svg)\\n\\n![Image 18](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/680b77461846a7cf254d8391_Klarna_Logo_black%201.svg)\\n\\n![Image 19](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/681b568070e9f341ed73b877_logo_Cisco.svg)\\n\\n![Image 20](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d206eefdb37789451855_The_Home_Depot-Logo.wine%201.svg)\\n\\n![Image 21](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg)\\n\\n![Image 22](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d18a7cef47c38c0eeb48_C._H._Robinson_logo%201.svg)\\n\\n![Image 23](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1ee0c9249f8c32e645d_logo_Komodo.svg)\\n\\n![Image 24](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1aa251143166667aec3_logo_Rakuten.svg)\\n\\n![Image 25](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1d39b2c6c806093f171_GitLab_logo_(2)%201.svg)\\n\\n![Image 26](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg)\\n\\n![Image 27](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1ddfdc1291f495b3697_AppFolio%2C_Inc._Wordmark%2C_2021%201.svg)\\n\\n![Image 28](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/680b77461846a7cf254d8391_Klarna_Logo_black%201.svg)\\n\\n![Image 29](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/681b568070e9f341ed73b877_logo_Cisco.svg)\\n\\n![Image 30](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d206eefdb37789451855_The_Home_Depot-Logo.wine%201.svg)\\n\\n![Image 31](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg)\\n\\n![Image 32](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d18a7cef47c38c0eeb48_C._H._Robinson_logo%201.svg)\\n\\n![Image 33](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1ee0c9249f8c32e645d_logo_Komodo.svg)\\n\\n![Image 34](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1aa251143166667aec3_logo_Rakuten.svg)\\n\\n![Image 35](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1d39b2c6c806093f171_GitLab_logo_(2)%201.svg)\\n\\n![Image 36](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1c1c55df212370b53fd_logo_Elastic.svg)\\n\\n![Image 37](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1ddfdc1291f495b3697_AppFolio%2C_Inc._Wordmark%2C_2021%201.svg)\\n\\n![Image 38](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/680b77461846a7cf254d8391_Klarna_Logo_black%201.svg)\\n\\n![Image 39](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/681b568070e9f341ed73b877_logo_Cisco.svg)\\n\\n![Image 40](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d206eefdb37789451855_The_Home_Depot-Logo.wine%201.svg)\\n\\n![Image 41](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1e509525a5b39a81208_unify%20logo%20-%20black%201.svg)\\n\\n![Image 42](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d18a7cef47c38c0eeb48_C._H._Robinson_logo%201.svg)\\n\\n![Image 43](https://cdn.prod.website-files.com/65c81e88c254bb0f97633a71/6811d1ee0c9249f8c32e645d_logo_Komodo.svg)\\n\\n![Image 44](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b080e4b3ca12dc5d5d439_Langgraph%20UI-2.webp)\\n\\nControllable cognitive architecture for any task\\n------------------------------------------------\\n\\nLangGraph's flexible framework supports diverse control flows – single agent, multi-agent, hierarchical, sequential – and robustly handles realistic, complex scenarios. \\n\\nEnsure reliability with easy-to-add moderation and quality loops that prevent agents from veering off course.\\n\\nUse LangGraph Platform to templatize your cognitive architecture so that tools, prompts, and models are easily configurable with LangGraph Platform Assistants.\\n\\n[See the docs](https://langchain-ai.github.io/langgraph/)\\n\\nThousands of companies build AI apps better with LangChain products.\\n--------------------------------------------------------------------\\n\\nRead our select customer stories.\\n\\nDesigned for human-agent collaboration\\n--------------------------------------\\n\\nWith built-in statefulness, LangGraph agents seamlessly collaborate with humans by writing drafts for review and awaiting approval before acting. Easily inspect the agent’s actions and \\\"time-travel\\\" to roll back and take a different action to correct course.\\n\\n[Read a conceptual guide](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/#human-in-the-loop)\\n\\n![Image 45](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667c93d559216bb904fe85a8_gif7%20(1).gif)\\n\\nHow does LangGraph help?\\n------------------------\\n\\nGuide, moderate, and control your agent with human-in-the-loop.\\n---------------------------------------------------------------\\n\\nPrevent agents from veering off course with easy-to-add moderation and quality controls. Add human-in-the-loop checks to steer and approve agent actions.\\n\\n[Learn how to add human-in-the-loop](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)\\n\\n![Image 46](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/680ba0cdfb351a3c4c2d2b42_Human-in-the-loop-GIF_v4.gif)\\n\\n![Image 47](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/68152f21a3b30d65d6c71bb3_Customizable-Agent-Architectures_v3%20(1).gif)\\n\\nBuild expressive, customizable agent workflows.\\n-----------------------------------------------\\n\\nLangGraph’s low-level primitives provide the flexibility needed to create fully customizable agents. Design diverse control flows — single, multi-agent, hierarchical — all using one framework.\\n\\n[See different agent architectures](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)\\n\\nPersist context for long-term interactions.\\n-------------------------------------------\\n\\nLangGraph’s built-in memory stores conversation histories and maintains context over time, enabling rich, personalized interactions across sessions.\\n\\n[Learn about agent memory](https://langchain-ai.github.io/langgraph/concepts/memory/)\\n\\n![Image 48](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/684b39acf796422a803c3a03_Memory-GIF-edited.gif)\\n\\n![Image 49](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/681965cbf5d9a5d1770efa9d_Streaming-Intermediate-Steps_v5%20(1).gif)\\n\\nFirst-class streaming for better UX design.\\n-------------------------------------------\\n\\nBridge user expectations and agent capabilities with native token-by-token streaming, showing agent reasoning and actions in real time.\\n\\n[See how to use streaming](https://langchain-ai.github.io/langgraph/how-tos/streaming/)\\n\\n![Image 50](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667c57f274b66a77e2a26b82_CleanShot2024-06-26at17.08.03-ezgif.com-video-to-gif-converter.gif)\\n\\nFirst class streaming support for better UX design\\n--------------------------------------------------\\n\\nBridge user expectations and agent capabilities with native token-by-token streaming and streaming of intermediate steps, helpful for showing agent reasoning and actions back to the user as they happen. Use LangGraph Platform's API to deliver dynamic and interactive user experiences.\\n\\n[Learn more](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/)\\n\\n![Image 51](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66db8c2317fe5b9ad2b84ea0_lcacademylogo.png)\\n\\nIntroduction to LangGraph\\n-------------------------\\n\\nLearn the basics of LangGraph in this LangChain Academy Course. You'll learn how to build agents that automate real-world tasks with LangGraph orchestration.\\n\\n[Enroll for free](https://academy.langchain.com/courses/intro-to-langgraph)[Book a training](https://airtable.com/appGjCAN6126Jm7K8/pagNAp7niHQzRH8zk/form)\\n\\n[![Image 52](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/678e35d6c553c4fb20f9b753_Frame%2099644.webp)![Image 53](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6787ae0bce5c99dd808545ce_card%202.webp)](https://academy.langchain.com/courses/intro-to-langgraph)\\n\\nDeploy agents at scale, monitor carefully, iterate boldly\\n---------------------------------------------------------\\n\\nDesign agent-driven user experiences with LangGraph Platform's APIs. Quickly deploy and scale your application with infrastructure built for agents. Choose from multiple deployment options.\\n\\n### Fault-tolerant scalability\\n\\nHandle large workloads gracefully with horizontally-scaling servers, task queues, and built-in persistence. Enhance resilience with intelligent caching and automated retries.\\n\\n### Dynamic APIs for designing agent experience\\n\\nCraft personalized user experiences with APIs featuring long-term memory to recall information across conversation sessions. Track, update, and rewind your app's state for easy human steering and interaction. Kick off long-running background jobs for research-style or multi-step work.\\n\\n### Integrated developer experience\\n\\nSimplify prototyping, debugging, and sharing of agents in our visual LangGraph Studio. Deploy your application with 1-click deploy with our SaaS offering or within your own VPC. Then, monitor app performance with LangSmith.\\n\\nWithout LangGraph Platform\\n\\nWrite your own API endpoints for human-in-the-loop, background jobs, and more. Manage state and checkpointing. Handle horizontal scaling and engineer fault tolerance. Continual maintenance and on-call.\\n\\nWith LangGraph Platform\\n\\nFocus on the app logic, not the infrastructure. Full batteries included — APIs, scalability, streaming, built in.\\n\\n### Developers trust LangGraph to build reliable agents.\\n\\nLangGraph helps teams of all sizes, across all industries, build reliable agents ready for production.\\n\\n[Hear how industry leaders use LangGraph](https://www.langchain.com/built-with-langgraph)\\n\\n![Image 54](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65c5308aea1371b447cc4af9_elastic-ar21.png)\\n\\n“LangChain is streets ahead with what they've put forward with LangGraph. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.”\\n\\n![Image 55](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b26a1b4576291d6a9335b_garrett%20spong%201.webp)\\n\\nGarrett Spong\\n\\nPrincipal SWE \\n\\n![Image 56](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679de9dc4e7bee218d4b058_Norwegian-Cruise-Line-Logo%202-2.webp)\\n\\n“LangGraph has been instrumental for our AI development. Its robust framework for building stateful, multi-actor applications with LLMs has transformed how we evaluate and optimize the performance of our AI guest-facing solutions. LangGraph enables granular control over the agent's thought process, which has empowered us to make data-driven and deliberate decisions to meet the diverse needs of our guests.”\\n\\n![Image 57](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b265bed5f5a9d26d6b7d6_andres%20torres%201.webp)\\n\\nAndres Torres\\n\\nSr. Solutions Architect\\n\\n![Image 58](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667c6f809f0ebc7b1d72a99b_Replit.png)\\n\\n“It's easy to build the prototype of a coding agent, but deceptively hard to improve its reliability. Replit wants to give a coding agent to millions of users — reliability is our top priority, and will remain so for a long time. LangGraph is giving us the control and ergonomics we need to build and ship powerful coding agents.”\\n\\n“As Ally advances its exploration of Generative AI,\\n\\n![Image 59](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667c6fcaaa21bcf2fe006dbe_1690576438641%20(1)%201.webp)\\n\\nMichele Catasta\\n\\nPresident\\n\\n![Image 60](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679e1baf7ea357d0763cde1_ally-bank%201-2.png)\\n\\n“As Ally advances its exploration of Generative AI, our tech labs is excited by LangGraph, the new library from LangChain, which is central to our experiments with multi-actor agentic workflows. We are committed to deepening our partnership with LangChain.”\\n\\n“As Ally advances its exploration of Generative AI,\\n\\n![Image 61](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679e2d31352c6bd56c84280_ally.png)\\n\\nSathish Muthukrishnan\\n\\nChief Information, Data and Digital Officer\\n\\n![Image 62](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65c5308aea1371b447cc4af9_elastic-ar21.png)\\n\\n“LangChain is streets ahead with what they've put forward with LangGraph. LangGraph sets the foundation for how we can build and scale AI workloads — from conversational agents, complex task automation, to custom LLM-backed experiences that 'just work'. The next chapter in building complex production-ready features with LLMs is agentic, and with LangGraph and LangSmith, LangChain delivers an out-of-the-box solution to iterate quickly, debug immediately, and scale effortlessly.”\\n\\n![Image 63](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b26a1b4576291d6a9335b_garrett%20spong%201.webp)\\n\\nGarrett Spong\\n\\nPrincipal SWE \\n\\n![Image 64](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679de9dc4e7bee218d4b058_Norwegian-Cruise-Line-Logo%202-2.webp)\\n\\n“LangGraph has been instrumental for our AI development. Its robust framework for building stateful, multi-actor applications with LLMs has transformed how we evaluate and optimize the performance of our AI guest-facing solutions. LangGraph enables granular control over the agent's thought process, which has empowered us to make data-driven and deliberate decisions to meet the diverse needs of our guests.”\\n\\n![Image 65](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667b265bed5f5a9d26d6b7d6_andres%20torres%201.webp)\\n\\nAndres Torres\\n\\nSr. Solutions Architect\\n\\n![Image 66](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667c6f809f0ebc7b1d72a99b_Replit.png)\\n\\n“It's easy to build the prototype of a coding agent, but deceptively hard to improve its reliability. Replit wants to give a coding agent to millions of users — reliability is our top priority, and will remain so for a long time. LangGraph is giving us the control and ergonomics we need to build and ship powerful coding agents.”\\n\\n“As Ally advances its exploration of Generative AI,\\n\\n![Image 67](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/667c6fcaaa21bcf2fe006dbe_1690576438641%20(1)%201.webp)\\n\\nMichele Catasta\\n\\nPresident\\n\\n![Image 68](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679e1baf7ea357d0763cde1_ally-bank%201-2.png)\\n\\n“As Ally advances its exploration of Generative AI, our tech labs is excited by LangGraph, the new library from LangChain, which is central to our experiments with multi-actor agentic workflows. We are committed to deepening our partnership with LangChain.”\\n\\n“As Ally advances its exploration of Generative AI,\\n\\n![Image 69](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/6679e2d31352c6bd56c84280_ally.png)\\n\\nSathish Muthukrishnan\\n\\nChief Information, Data and Digital Officer\\n\\nLangGraph FAQs\\n--------------\\n\\nHow is LangGraph different from other agent frameworks?\\n\\nOther agentic frameworks can work for simple, generic tasks but fall short for complex tasks bespoke to a company’s needs. LangGraph provides a more expressive framework to handle companies’ unique tasks without restricting users to a single black-box cognitive architecture.\\n\\nDoes LangGraph impact the performance of my app?\\n\\nLangGraph will not add any overhead to your code and is specifically designed with streaming workflows in mind.\\n\\nIs LangGraph open source? Is it free?\\n\\nYes. LangGraph is an MIT-licensed open-source library and is free to use.\\n\\nHow are LangGraph and LangGraph Platform different?\\n\\nLangGraph is a stateful, orchestration framework that brings added control to agent workflows. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\\n\\nLangGraph (open source)\\n\\nLangGraph Platform\\n\\nFeatures\\n\\nDescription\\n\\nStateful orchestration framework for agentic applications\\n\\nScalable infrastructure for deploying LangGraph applications\\n\\nSDKs\\n\\nPython and JavaScript\\n\\nPython and JavaScript\\n\\nHTTP APIs\\n\\nNone\\n\\nYes - useful for retrieving & updating state or long-term memory, or creating a configurable assistant\\n\\nStreaming\\n\\nBasic\\n\\nDedicated mode for token-by-token messages\\n\\nCheckpointer\\n\\nCommunity contributed\\n\\nSupported out-of-the-box\\n\\nPersistence Layer\\n\\nSelf-managed\\n\\nManaged Postgres with efficient storage\\n\\nDeployment\\n\\nSelf-managed\\n\\n- Cloud\\n\\n- Hybrid\\n\\n- Full self-hosted\\n\\nScalability\\n\\nSelf-managed\\n\\nAuto-scaling of task queues and servers\\n\\nFault-tolerance\\n\\nSelf-managed\\n\\nAutomated retries\\n\\nConcurrency Control\\n\\nSimple threading\\n\\nSupports double-texting\\n\\nScheduling\\n\\nNone\\n\\nCron scheduling\\n\\nMonitoring\\n\\nOpt-in LangSmith integration for observability\\n\\nIntegrated with LangSmith for observability\\n\\nIDE integration\\n\\nLangGraph Studio for Desktop\\n\\nLangGraph Studio for Desktop & Cloud\\n\\nWhat are my deployment options for LangGraph Platform?\\n\\nWe currently have the following deployment options for LangGraph applications:\\n\\n‍\\n\\n**Cloud SaaS:**Fully managed and hosted as part of LangSmith (our unified observability& evals platform).Deploy quickly, with automatic updates and zero maintenance.\\n\\n‍\\n\\n**Hybrid** (SaaS control plane, self-hosted data plane). No data leaves your VPC. Provisioning and scaling is managed as a service.\\n\\n‍\\n\\n**Fully****Self-Hosted:**Deploy LangGraph entirely on your own infrastructure.\\n\\n‍\\n\\nIf you want to try out a basic version of our LangGraph server in your environment, you can also self-host on our Developer plan and get up to 100k nodes executed per month for free.Great for running hobbyist projects, with fewer features are available than in paid plans.\\n\\n‍\\n\\nIs LangGraph Platform open source?\\n\\nNo. LangGraph Platform is proprietary software.\\n\\n‍\\n\\nThere is a free, self-hosted version of LangGraph Platform with access to basic features. The Cloud SaaS deployment option is free while in beta, but will eventually be a paid service. We will always give ample notice before charging for a service and reward our early adopters with preferential pricing. The Bring Your Own Cloud (BYOC) and Self-Hosted Enterprise options are also paid services. [Contact our sales team](https://www.langchain.com/contact-sales) to learn more.\\n\\n‍\\n\\nFor more information, see our [LangGraph Platform pricing page](https://www.langchain.com/pricing-langgraph-platform).\\n\\nReady to start shipping reliable agents faster?\\n-----------------------------------------------\\n\\nGet started with tools from the LangChain product suite for every step of the agent development lifecycle.\\n\\n[Contact Us](https://www.langchain.com/contact-sales)[Sign Up](https://smith.langchain.com/)\\n\\nProducts\\n\\n[LangChain](https://www.langchain.com/langchain)[LangSmith](https://www.langchain.com/langsmith)[LangGraph](https://www.langchain.com/langgraph)[Agents](https://www.langchain.com/agents)[Evaluation](https://www.langchain.com/evaluation)[Retrieval](https://www.langchain.com/retrieval)\\n\\nResources\\n\\n[Python Docs](https://python.langchain.com/)[JS/TS Docs](https://js.langchain.com/docs/get_started/introduction/)[GitHub](https://github.com/langchain-ai)[Integrations](https://python.langchain.com/docs/integrations/providers/)[Changelog](https://changelog.langchain.com/)[Community](https://www.langchain.com/join-community)[LangSmith Trust Portal](https://trust.langchain.com/)\\n\\nCompany\\n\\n[About](https://www.langchain.com/about)[Careers](https://www.langchain.com/careers)[Blog](https://blog.langchain.com/)[Twitter](https://twitter.com/LangChainAI)[LinkedIn](https://www.linkedin.com/company/langchain/)[YouTube](https://www.youtube.com/@LangChain)[Marketing Assets](https://drive.google.com/drive/folders/17xybjzmVBdsQA-VxouuGLxF6bDsHDe80?usp=sharing)\\n\\nSign up for our newsletter to stay up to date\\n\\nThank you! Your submission has been received!\\n\\nOops! Something went wrong while submitting the form.\\n\\n![Image 70](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/65c6a38f9c53ec71f5fc73de_langchain-word.svg)\\n\\n[All systems operational](https://status.smith.langchain.com/)[Privacy Policy](https://www.langchain.com/privacy-policy)[Terms of Service](https://www.langchain.com/terms-of-service)\\n\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료는 다음과 같습니다:\n",
      "\n",
      "1. **LangGraph Studio**: LangGraph Studio는 LangGraph Server API 프로토콜을 구현하는 에이전트 시스템의 시각화, 상호작용 및 디버깅을 가능하게 하는 전문 IDE입니다. 이 스튜디오는 LangSmith와 통합되어 추적, 평가 및 프롬프트 엔지니어링을 지원합니다. [자세한 내용은 여기에서 확인하세요.](https://langchain-ai.lang.chat/langgraph/concepts/langgraph_studio/)\n",
      "\n",
      "2. **GitHub Repository**: LangGraph Studio의 소스 코드와 문서가 포함된 GitHub 리포지토리입니다. 여기에서 설치 방법, 사용법 및 기여 방법에 대한 정보를 찾을 수 있습니다. [GitHub에서 확인하기](https://github.com/langchain-ai/langgraph-studio)\n",
      "\n",
      "3. **LangGraph 소개**: LangGraph는 에이전트 기반 사용자 경험을 설계하고, 애플리케이션을 신속하게 배포 및 확장할 수 있는 API를 제공합니다. LangGraph 플랫폼은 에이전트 UX를 구축하기 위한 의견이 반영된 API와 통합 개발자 스튜디오를 제공합니다. [자세한 내용은 여기에서 확인하세요.](https://www.langchain.com/langgraph)\n",
      "\n",
      "이 자료들을 통해 LangGraph의 기능과 사용법에 대해 더 깊이 이해할 수 있을 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림에서 이벤트 수신\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 각 이벤트에 대한 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "내가 지금까지 배운 내용에 대해서 매우 친절하고 정성스럽게 답변해 주세요. 출처를 반드시 포함해 주세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "당신이 지금까지 배운 LangGraph에 대한 내용은 다음과 같습니다:\n",
      "\n",
      "1. **LangGraph Studio**: LangGraph Studio는 LangGraph Server API 프로토콜을 구현하는 에이전트 시스템을 시각화하고 상호작용하며 디버깅할 수 있는 전문 IDE입니다. 이 스튜디오는 LangSmith와 통합되어 있어, 에이전트의 실행을 추적하고 평가하며 프롬프트 엔지니어링을 지원합니다. LangGraph Studio는 두 가지 모드를 지원합니다:\n",
      "   - **Graph Mode**: 에이전트의 실행에 대한 자세한 정보를 제공하며, 노드 탐색, 중간 상태 및 LangSmith 통합을 포함합니다.\n",
      "   - **Chat Mode**: 비즈니스 사용자와 채팅 전용 에이전트를 테스트하는 데 유용한 간단한 UI를 제공합니다. [자세한 내용은 여기에서 확인하세요.](https://langchain-ai.lang.chat/langgraph/concepts/langgraph_studio/)\n",
      "\n",
      "2. **GitHub Repository**: LangGraph Studio의 소스 코드와 문서가 포함된 GitHub 리포지토리입니다. 이곳에서는 설치 방법, 사용법 및 기여 방법에 대한 정보를 찾을 수 있습니다. [GitHub에서 확인하기](https://github.com/langchain-ai/langgraph-studio)\n",
      "\n",
      "3. **LangGraph 소개**: LangGraph는 에이전트 기반 사용자 경험을 설계하고, 애플리케이션을 신속하게 배포 및 확장할 수 있는 API를 제공합니다. LangGraph 플랫폼은 에이전트 UX를 구축하기 위한 의견이 반영된 API와 통합 개발자 스튜디오를 제공합니다. LangGraph는 대화형 에이전트, 복잡한 작업 자동화 및 사용자 맞춤형 LLM 기반 경험을 구축하는 데 필요한 기반을 제공합니다. [자세한 내용은 여기에서 확인하세요.](https://www.langchain.com/langgraph)\n",
      "\n",
      "이 자료들은 LangGraph의 기능과 사용법에 대한 깊은 이해를 돕기 위해 제공되었습니다. 각 링크를 통해 더 많은 정보를 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 이벤트 스트림 생성\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"user\",\n",
    "            \"내가 지금까지 배운 내용에 대해서 매우 친절하고 정성스럽게 답변해 주세요. 출처를 반드시 포함해 주세요.\",\n",
    "        )\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "# 메시지 이벤트 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "당신이 지금까지 배운 LangGraph에 대한 내용은 다음과 같습니다:\n",
      "\n",
      "1. **LangGraph Studio**: LangGraph Studio는 LangGraph Server API 프로토콜을 구현하는 에이전트 시스템을 시각화하고 상호작용하며 디버깅할 수 있는 전문 IDE입니다. 이 스튜디오는 LangSmith와 통합되어 있어, 에이전트의 실행을 추적하고 평가하며 프롬프트 엔지니어링을 지원합니다. LangGraph Studio는 두 가지 모드를 지원합니다:\n",
      "   - **Graph Mode**: 에이전트의 실행에 대한 자세한 정보를 제공하며, 노드 탐색, 중간 상태 및 LangSmith 통합을 포함합니다.\n",
      "   - **Chat Mode**: 비즈니스 사용자와 채팅 전용 에이전트를 테스트하는 데 유용한 간단한 UI를 제공합니다. [자세한 내용은 여기에서 확인하세요.](https://langchain-ai.lang.chat/langgraph/concepts/langgraph_studio/)\n",
      "\n",
      "2. **GitHub Repository**: LangGraph Studio의 소스 코드와 문서가 포함된 GitHub 리포지토리입니다. 이곳에서는 설치 방법, 사용법 및 기여 방법에 대한 정보를 찾을 수 있습니다. [GitHub에서 확인하기](https://github.com/langchain-ai/langgraph-studio)\n",
      "\n",
      "3. **LangGraph 소개**: LangGraph는 에이전트 기반 사용자 경험을 설계하고, 애플리케이션을 신속하게 배포 및 확장할 수 있는 API를 제공합니다. LangGraph 플랫폼은 에이전트 UX를 구축하기 위한 의견이 반영된 API와 통합 개발자 스튜디오를 제공합니다. LangGraph는 대화형 에이전트, 복잡한 작업 자동화 및 사용자 맞춤형 LLM 기반 경험을 구축하는 데 필요한 기반을 제공합니다. [자세한 내용은 여기에서 확인하세요.](https://www.langchain.com/langgraph)\n",
      "\n",
      "이 자료들은 LangGraph의 기능과 사용법에 대한 깊은 이해를 돕기 위해 제공되었습니다. 각 링크를 통해 더 많은 정보를 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 최종 응답 \n",
    "# 최종 상태에서 `messages` 의 마지막 메시지로 확인 \n",
    "graph.get_state(config).values[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay\n",
    "\n",
    "- 지난 스냅샷을 확인 후 특정 노드로 되돌아가, State를 수정한 뒤 해당 노드부터 다시 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run--677ada2a-82e9-4699-8ccd-7edf30fdac63-0\n",
      "메시지 수:  6 다음 노드:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "c04622ca-489e-4bd0-81d7-4cf3703f5d65\n",
      "메시지 수:  5 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "run--cd009398-d88b-41ab-a801-dcae15d7cdcc-0\n",
      "메시지 수:  4 다음 노드:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "run--cd009398-d88b-41ab-a801-dcae15d7cdcc-0\n",
      "메시지 수:  4 다음 노드:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "2b6076c2-5947-4bb8-9c45-dd37842639a6\n",
      "메시지 수:  3 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "run--b458ab8c-e1ae-40c7-9f7b-7830ea3e40cb-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "run--b458ab8c-e1ae-40c7-9f7b-7830ea3e40cb-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "f046abd8-8851-42d5-b332-43b480d4fe14\n",
      "메시지 수:  1 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay_state = None\n",
    "\n",
    "# 상태 기록 가져오기\n",
    "for state in graph.get_state_history(config):\n",
    "\n",
    "    messages = state.values[\"messages\"]\n",
    "\n",
    "    if len(messages) > 0:\n",
    "        print(state.values[\"messages\"][-1].id)\n",
    "        # 메시지 수 및 다음 상태 출력\n",
    "        print(\"메시지 수: \", len(state.values[\"messages\"]), \"다음 노드: \", state.next)\n",
    "        print(\"-\" * 80)\n",
    "        # 특정 상태 선택 기준: 채팅 메시지 수\n",
    "        if len(state.values[\"messages\"]) == 2:\n",
    "            # 특정 메시지 ID 선택\n",
    "            to_replay_state = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[93mcontent\u001b[0m: \"\"\n",
      "    \u001b[93madditional_kwargs\u001b[0m:\n",
      "        \u001b[94mtool_calls\u001b[0m:\n",
      "            \u001b[94mindex [0]\u001b[0m\n",
      "                \u001b[92mid\u001b[0m: \"call_uR6h7jVBHy2hObv0r1l0JxYF\"\n",
      "                \u001b[92mfunction\u001b[0m: {\"arguments\": \"{\"query\":\"LangGraph\"}\", \"name\": \"tavily_web_search\"}\n",
      "                \u001b[92mtype\u001b[0m: \"function\"\n",
      "        \u001b[94mrefusal\u001b[0m: None\n",
      "    \u001b[93mresponse_metadata\u001b[0m:\n",
      "        \u001b[94mtoken_usage\u001b[0m:\n",
      "            \u001b[95mcompletion_tokens\u001b[0m: 18\n",
      "            \u001b[95mprompt_tokens\u001b[0m: 110\n",
      "            \u001b[95mtotal_tokens\u001b[0m: 128\n",
      "            \u001b[95mcompletion_tokens_details\u001b[0m: {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}\n",
      "            \u001b[95mprompt_tokens_details\u001b[0m: {\"audio_tokens\": 0, \"cached_tokens\": 0}\n",
      "        \u001b[94mmodel_name\u001b[0m: \"gpt-4o-mini-2024-07-18\"\n",
      "        \u001b[94msystem_fingerprint\u001b[0m: \"fp_62a23a81ef\"\n",
      "        \u001b[94mfinish_reason\u001b[0m: \"tool_calls\"\n",
      "        \u001b[94mlogprobs\u001b[0m: None\n",
      "    \u001b[93mtype\u001b[0m: \"ai\"\n",
      "    \u001b[93mname\u001b[0m: None\n",
      "    \u001b[93mid\u001b[0m: \"run--b458ab8c-e1ae-40c7-9f7b-7830ea3e40cb-0\"\n",
      "    \u001b[93mexample\u001b[0m: False\n",
      "    \u001b[93mtool_calls\u001b[0m:\n",
      "        \u001b[93mindex [0]\u001b[0m\n",
      "            \u001b[95mname\u001b[0m: \"tavily_web_search\"\n",
      "            \u001b[95margs\u001b[0m: {\"query\": \"LangGraph\"}\n",
      "            \u001b[95mid\u001b[0m: \"call_uR6h7jVBHy2hObv0r1l0JxYF\"\n",
      "            \u001b[95mtype\u001b[0m: \"tool_call\"\n",
      "    \u001b[93minvalid_tool_calls\u001b[0m:\n",
      "    \u001b[93musage_metadata\u001b[0m:\n",
      "        \u001b[94minput_tokens\u001b[0m: 110\n",
      "        \u001b[94moutput_tokens\u001b[0m: 18\n",
      "        \u001b[94mtotal_tokens\u001b[0m: 128\n",
      "        \u001b[94minput_token_details\u001b[0m: {\"audio\": 0, \"cache_read\": 0}\n",
      "        \u001b[94moutput_token_details\u001b[0m: {\"audio\": 0, \"reasoning\": 0}\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "# 선택한 메시지 가져오기\n",
    "existing_message = to_replay_state.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 트리 출력\n",
    "display_message_tree(existing_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph human-in-the-loop workflow site:reddit.com'},\n",
       " 'id': 'call_uR6h7jVBHy2hObv0r1l0JxYF',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검색 쿼리 업데이트 \n",
    "tool_call = existing_message.tool_calls[0].copy()\n",
    "tool_call[\"args\"] = {\"query\": \"LangGraph human-in-the-loop workflow site:reddit.com\"}\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'LangGraph human-in-the-loop workflow site:reddit.com'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트된 AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[tool_call],\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "# 수정한 메시지 출력\n",
    "new_message.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph'},\n",
       "  'id': 'call_uR6h7jVBHy2hObv0r1l0JxYF',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트 전 메시지 확인\n",
    "graph.get_state(to_replay_state.config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '429de3',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f052f88-2efb-6da6-8002-16e439dfc0d7'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상태 업데이트\n",
    "updated_state = graph.update_state(\n",
    "    to_replay_state.config,\n",
    "    {\"messages\": [new_message]},\n",
    ")\n",
    "updated_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_uR6h7jVBHy2hObv0r1l0JxYF)\n",
      " Call ID: call_uR6h7jVBHy2hObv0r1l0JxYF\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow site:reddit.com\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g\", \"score\": 0.98557, \"raw_content\": null}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Thank you. I've seen both of those examples before - the \\\"human-in-the-loop\\\" uses a linear chain (rather than agents). The \\\"human-as-a-tool\\\" is when a question can't be answered by the LLM / one of the supplied tools, so it asks a human to supplement with info.\", \"score\": 0.98236, \"raw_content\": null}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\", \"score\": 0.97973, \"raw_content\": null}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 아래에 추천드립니다:\n",
      "\n",
      "1. **[Human intervention in agent workflows](https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/)** - 이 글에서는 LangGraph를 사용하여 LLM 워크플로우에서 인간이 개입할 수 있는 노드를 구축하는 방법에 대해 논의합니다. 사용자 입력을 요청하는 Human-in-the-loop 구성 요소에 대한 설명이 포함되어 있습니다.\n",
      "\n",
      "2. **[Tool-calling agents: Human approval before tool invocation?](https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/)** - 이 글에서는 LLM이나 제공된 도구로 답변할 수 없는 질문에 대해 인간이 정보를 보충하는 방식에 대해 설명합니다. Human-in-the-loop의 개념이 어떻게 적용되는지에 대한 논의가 포함되어 있습니다.\n",
      "\n",
      "3. **[LangGraph Workflow for Quality Assurance](https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/)** - 이 글에서는 LangGraph를 사용하여 복잡한 법적 문서의 품질 보증(QA) 프로세스를 자동화하는 개념에 대해 설명합니다. AI를 활용하여 QA 프로세스의 특정 부분을 처리하는 방법에 대해 논의합니다.\n",
      "\n",
      "이 자료들을 통해 LangGraph의 다양한 활용 사례와 개념을 이해하는 데 도움이 될 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# config에 updated_state 전달\n",
    "for event in graph.stream(None, updated_state, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_uR6h7jVBHy2hObv0r1l0JxYF)\n",
      " Call ID: call_uR6h7jVBHy2hObv0r1l0JxYF\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow site:reddit.com\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"title\": \"Human intervention in agent workflows : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/\", \"content\": \"When building LLM workflows with LangChain/LangGraph what's the best way to build a node in the workflow where a human can validate/approve/reject a flow? I know there is a Human-in-the-loop component in LangGraph that will prompt the user for input. But what if I'm not creating a user-initiated chat conversation, but a flow that reacts to e.g\", \"score\": 0.98557, \"raw_content\": null}, {\"title\": \"Tool-calling agents: Human approval before tool invocation?\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/\", \"content\": \"Thank you. I've seen both of those examples before - the \\\"human-in-the-loop\\\" uses a linear chain (rather than agents). The \\\"human-as-a-tool\\\" is when a question can't be answered by the LLM / one of the supplied tools, so it asks a human to supplement with info.\", \"score\": 0.98236, \"raw_content\": null}, {\"title\": \"LangGraph Workflow for Quality Assurance : r/LangChain - Reddit\", \"url\": \"https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/\", \"content\": \"I've been working on a concept to automate the Quality Assurance (QA) process for complex legal documents using LangGraph, aiming to streamline the workflow, reduce manual effort, and improve compliance efficiency. Handling specific parts of the QA process using AI rather human reviews, from initial document submission to final approval.\", \"score\": 0.97973, \"raw_content\": null}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 아래에 추천드립니다:\n",
      "\n",
      "1. **[Human intervention in agent workflows](https://www.reddit.com/r/LangChain/comments/1bjnmu4/human_intervention_in_agent_workflows/)** - 이 글에서는 LangGraph를 사용하여 LLM 워크플로우에서 인간이 개입할 수 있는 노드를 구축하는 방법에 대해 논의합니다. 사용자 입력을 요청하는 Human-in-the-loop 구성 요소에 대한 설명이 포함되어 있습니다.\n",
      "\n",
      "2. **[Tool-calling agents: Human approval before tool invocation?](https://www.reddit.com/r/LangChain/comments/1ci3m0k/toolcalling_agents_human_approval_before_tool/)** - 이 글에서는 LLM이나 제공된 도구로 답변할 수 없는 질문에 대해 인간이 정보를 보충하는 방식에 대해 설명합니다. Human-in-the-loop의 개념이 어떻게 적용되는지에 대한 논의가 포함되어 있습니다.\n",
      "\n",
      "3. **[LangGraph Workflow for Quality Assurance](https://www.reddit.com/r/LangChain/comments/1bsblmu/langgraph_workflow_for_quality_assurance/)** - 이 글에서는 LangGraph를 사용하여 복잡한 법적 문서의 품질 보증(QA) 프로세스를 자동화하는 개념에 대해 설명합니다. AI를 활용하여 QA 프로세스의 특정 부분을 처리하는 방법에 대해 논의합니다.\n",
      "\n",
      "이 자료들을 통해 LangGraph의 다양한 활용 사례와 개념을 이해하는 데 도움이 될 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# 최종 결과 출력\n",
    "for msg in graph.get_state(config).values[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
