{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY Loading\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH21-LangGraph\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "\n",
    "logging.langsmith(\"CH21-LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Manual Update \n",
    "\n",
    "- LangGraph은 중간 단계의 State를 수동으로 업데이트 할 수 있는 방안을 제공함 \n",
    "- 이를 통해 에이전트 행동을 수정하여 경로를 제어할 수 있음 \n",
    "- 또한 에이전트의 실수를 수정하거나, 대체 경로를 탐색하는 것처럼 특정 목표에 따라 에이전트의 동작을 변경할 때 유용함 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_teddynote.graphs import visualize_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Visualize Graph Error: Failed to render the graph using the Mermaid.INK API. Status code: 204.\n"
     ]
    }
   ],
   "source": [
    "########## 1. State ##########\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "########## 2. TOOLS ##########\n",
    "# 도구 초기화\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "# 도구 목록 정의\n",
    "tools = [tool]\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# LLM + 도구 \n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "########## 3. NODE ##########\n",
    "# 챗봇 함수 정의\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# Graph\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 도구 노드 생성 및 추가\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Conditional Edge\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "\n",
    "########## 4. EDGE ##########\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "\n",
    "########## 5. MEMORY ##########\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "########## 6. COMPILE  ##########\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "########## 7. VISUALIZE ##########\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "               *              \n",
      "               *              \n",
      "               *              \n",
      "          +---------+         \n",
      "          | chatbot |         \n",
      "          +---------+         \n",
      "          .         .         \n",
      "        ..           ..       \n",
      "       .               .      \n",
      "+---------+         +-------+ \n",
      "| __end__ |         | tools | \n",
      "+---------+         +-------+ \n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"LangGraph 가 무엇인지 조사하여 알려주세요!\"\n",
    "\n",
    "# 초기 입력 상태를 정의\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "# config 설정\n",
    "config = RunnableConfig(\n",
    "    configurable={\"thread_id\": \"001\"},  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**channels**\n",
    "\n",
    "- LangGraph 내부에서 노드 간 데이터가 흐르는 경로(통로) \n",
    "- 각 노드의 입력과 출력을 연결하는 데이터 이동 경로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['messages',\n",
       " '__start__',\n",
       " 'chatbot',\n",
       " 'tools',\n",
       " 'branch:__start__:__self__:chatbot',\n",
       " 'branch:__start__:__self__:tools',\n",
       " 'branch:chatbot:__self__:chatbot',\n",
       " 'branch:chatbot:__self__:tools',\n",
       " 'branch:tools:__self__:chatbot',\n",
       " 'branch:tools:__self__:tools',\n",
       " 'start:chatbot',\n",
       " 'branch:chatbot:tools_condition:tools']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그래프 채널 목록 출력\n",
    "list(graph.channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 중단된 지점 찾기 (interrupt 상태 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 가 무엇인지 조사하여 알려주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_8t5QwQsD43oJC5H1rR9ztiuj)\n",
      " Call ID: call_8t5QwQsD43oJC5H1rR9ztiuj\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림 호출\n",
    "# 중단 지점(interrupt_before=[“tools”])에서 중간 상태 확인\n",
    "events = graph.stream(\n",
    "    input=input, \n",
    "    config=config, \n",
    "    interrupt_before=[\"tools\"], \n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    # 메시지가 이벤트에 포함된 경우\n",
    "    if \"messages\" in event:\n",
    "        # 마지막 메시지의 예쁜 출력\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_8t5QwQsD43oJC5H1rR9ztiuj)\n",
      " Call ID: call_8t5QwQsD43oJC5H1rR9ztiuj\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "# 그래프 상태 스냅샷 생성\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 가장 최근 메시지 추출\n",
    "last_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 출력\n",
    "last_message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 도구 결과 수동 수정하기\n",
    "\n",
    "- `TavilySearch` 도구에서 검색 결과 수정하여 새로운 ToolMessage 생성\n",
    "- tool_call_id를 기존 메시지에서 추출 후 동일 ID로 새 메시지 생성\n",
    "- 그래프 상태 업데이트 (graph.update_state)로 반영\n",
    "- 이후 흐름 계속 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "source": [
    "modified_search_result = \"\"\"[수정된 웹 검색 결과] \n",
    "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
    "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
    "\n",
    "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
    "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\"\"\"\n",
    "\n",
    "print(modified_search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_8t5QwQsD43oJC5H1rR9ztiuj\n"
     ]
    }
   ],
   "source": [
    "# 수정하고자 하는 `ToolMessage` 의 `tool_call_id` 추출\n",
    "tool_call_id = last_message.tool_calls[0][\"id\"]\n",
    "print(tool_call_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**메시지 타입**\n",
    "\n",
    "- HumanMessage : 사용자 입력 전달 \n",
    "- AIMessage : LLM의 텍스트 응답 메시지, 일반적인 대화 응답 \n",
    "- SystemMessage : 대화 설정 또는 시스템 프롬프트 \n",
    "- ToolMessage : 도구 실행 결과 메시지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n"
     ]
    }
   ],
   "source": [
    "new_messages = [\n",
    "    # LLM API의 도구 호출과 일치하는 ToolMessage 필요\n",
    "    ToolMessage(\n",
    "        content=modified_search_result,\n",
    "        tool_call_id=tool_call_id,\n",
    "    ),\n",
    "    # LLM의 응답에 직접적으로 내용 추가\n",
    "    # AIMessage(content=modified_search_result),\n",
    "]\n",
    "\n",
    "new_messages[-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수정된 상태 반영하기 (update_state)\n",
    "\n",
    "**StateGraph의 `update_state`**\n",
    "\n",
    "- `update_state` : 주어진 값으로 그래프의 상태를 업데이트\n",
    "- 마치 `as_node`에서 값이 온 것처럼 동작함\n",
    "\n",
    "**매개변수**\n",
    "\n",
    "- `config` (RunnableConfig): 실행 구성\n",
    "- `values` (Optional[Union[dict[str, Any], Any]]): 업데이트할 값들\n",
    "- `as_node` (Optional[str]): 값의 출처로 간주할 노드 이름. 기본값은 None\n",
    "\n",
    "**반환값**\n",
    "\n",
    "- RunnableConfig\n",
    "\n",
    "**주요 기능**\n",
    "\n",
    "1. 체크포인터를 통해 이전 상태를 로드하고 새로운 상태를 저장\n",
    "2. 서브그래프에 대한 상태 업데이트를 처리\n",
    "3. `as_node`가 지정되지 않은 경우, 마지막으로 상태를 업데이트한 노드를 찾음\n",
    "4. 지정된 노드의 writer들을 실행하여 상태를 업데이트\n",
    "5. 업데이트된 상태를 체크포인트에 저장\n",
    "\n",
    "**주요 로직**\n",
    "\n",
    "1. 체크포인터를 확인하고, 없으면 ValueError를 발생시킴\n",
    "2. 서브그래프에 대한 업데이트인 경우, 해당 서브그래프의 `update_state` 메서드를 호출\n",
    "3. 이전 체크포인트를 로드하고, 필요한 경우 `as_node`를 결정\n",
    "4. 지정된 노드의 writer들을 사용하여 상태를 업데이트\n",
    "5. 업데이트된 상태를 새로운 체크포인트로 저장\n",
    "\n",
    "**참고**\n",
    "\n",
    "- 이 메서드는 그래프의 상태를 수동으로 업데이트할 때 사용\n",
    "- 체크포인터를 사용하여 상태의 버전 관리와 지속성 보장\n",
    "- `as_node`를 지정하지 않으면 자동으로 결정되지만, 모호한 경우 오류가 발생할 수 있음\n",
    "- 상태 업데이트 중 SharedValues에 쓰기 작업은 허용되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(최근 1개의 메시지 출력)\n",
      "\n",
      "content='[수정된 웹 검색 결과] \\nLangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\\nLangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\\n\\n자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\\n[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.' id='dc67905c-7177-4a22-9747-50dc9ae9409e' tool_call_id='call_8t5QwQsD43oJC5H1rR9ztiuj'\n"
     ]
    }
   ],
   "source": [
    "graph.update_state(\n",
    "    # 업데이트할 상태 지정\n",
    "    config,\n",
    "    # 제공할 업데이트된 값. `State`의 메시지는 \"추가 전용\"으로 기존 상태에 추가됨\n",
    "    {\"messages\": new_messages},\n",
    "    as_node=\"tools\",\n",
    ")\n",
    "\n",
    "print(\"(최근 1개의 메시지 출력)\\n\")\n",
    "print(graph.get_state(config).values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatbot',)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 구축할 수 있도록 지원하는 오픈 소스 라이브러리입니다. 이 라이브러리는 LLM(대형 언어 모델)을 활용하여 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능 등을 제공합니다.\n",
      "\n",
      "더 자세한 정보와 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)과 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785)에서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 이벤트 반복 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "               *              \n",
      "               *              \n",
      "               *              \n",
      "          +---------+         \n",
      "          | chatbot |         \n",
      "          +---------+         \n",
      "          .         .         \n",
      "        ..           ..       \n",
      "       .               .      \n",
      "+---------+         +-------+ \n",
      "| __end__ |         | tools | \n",
      "+---------+         +-------+ \n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 가 무엇인지 조사하여 알려주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_8t5QwQsD43oJC5H1rR9ztiuj)\n",
      " Call ID: call_8t5QwQsD43oJC5H1rR9ztiuj\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "[수정된 웹 검색 결과] \n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 LLM을 활용해 구축할 수 있도록 지원합니다.\n",
      "LangGraph는 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능을 제공하는 오픈 소스 라이브러리입니다.\n",
      "\n",
      "자세한 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/) 과\n",
      "[랭체인 한국어 튜토리얼](https://wikidocs.net/233785) 을 참고하세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph는 상태 기반의 다중 액터 애플리케이션을 구축할 수 있도록 지원하는 오픈 소스 라이브러리입니다. 이 라이브러리는 LLM(대형 언어 모델)을 활용하여 사이클 흐름, 제어 가능성, 지속성, 클라우드 배포 기능 등을 제공합니다.\n",
      "\n",
      "더 자세한 정보와 튜토리얼은 [LangGraph 튜토리얼](https://langchain-ai.github.io/langgraph/tutorials/)과 [랭체인 한국어 튜토리얼](https://wikidocs.net/233785)에서 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# 최근 세 개의 메시지 출력\n",
    "for message in snapshot.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "# 다음 상태 출력\n",
    "print(snapshot.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 대화 메시지 직접 수정하기\n",
    "\n",
    "- `TavilySearch` 도구에서 검색 쿼리 수정\n",
    "- `thread_id` : 랜덤한 해시값을 생성하는 `generate_random_hash` 함수를 사용하여 적용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread_id: 74a3a6\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import generate_random_hash\n",
    "\n",
    "thread_id = generate_random_hash()\n",
    "print(f\"thread_id: {thread_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_cSCwDBfSVuCvWBVkDBdeclfB)\n",
      " Call ID: call_cSCwDBfSVuCvWBVkDBdeclfB\n",
      "  Args:\n",
      "    query: LangGraph\n"
     ]
    }
   ],
   "source": [
    "question = \"LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\"\n",
    "\n",
    "input = State(messages=[(\"user\", question)])\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "events = graph.stream(\n",
    "    input=input,\n",
    "    config=config,\n",
    "    interrupt_before=[\"tools\"],\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 를 복사\n",
    "config_copy = config.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message ID run-f5740685-6ec3-4fe6-b3b1-69d4addc253f-0\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 스냅샷 상태 \n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# messages 의 마지막 메시지 \n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"Message ID\", existing_message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph'}, 'id': 'call_cSCwDBfSVuCvWBVkDBdeclfB', 'type': 'tool_call'}\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 도구 호출 출력\n",
    "print(existing_message.tool_calls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph Studio'},\n",
       " 'id': 'call_cSCwDBfSVuCvWBVkDBdeclfB',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tool_calls 를 복사하여 새로운 도구 호출 생성\n",
    "new_tool_call = existing_message.tool_calls[0].copy()\n",
    "\n",
    "# 쿼리 매개변수 업데이트\n",
    "new_tool_call[\"args\"] = {\"query\": \"LangGraph Studio\"}\n",
    "new_tool_call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 메시지를 수정하고 싶은데...\n",
    "\n",
    "- LangGraph의 메시지 기록은 append-only만 허용 \n",
    "- 기존 메시지와 동일한 ID로 새 메시지를 만들고, 그걸 덯어쓰기 해야 함 \n",
    "\n",
    "id=existing_message.id\n",
    "\n",
    "- 기존 메시지와 같은 ID를 사용하여 새로운 메시지를 만들어서 \n",
    "- 시스템은 새 메시지가 기존 메시지를 대체(replace) 했다고 인식시킴 -> LangChain message overwrite trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-f5740685-6ec3-4fe6-b3b1-69d4addc253f-0\n"
     ]
    }
   ],
   "source": [
    "# AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[new_tool_call],\n",
    "    id=existing_message.id,  # ID는 메시지를 상태에 추가하는 대신 교체하는 방법으로 처리 (별5개)\n",
    ")\n",
    "\n",
    "print(new_message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_cSCwDBfSVuCvWBVkDBdeclfB)\n",
      " Call ID: call_cSCwDBfSVuCvWBVkDBdeclfB\n",
      "  Args:\n",
      "    query: LangGraph Studio\n"
     ]
    }
   ],
   "source": [
    "# 수정한 메시지 출력\n",
    "new_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'tavily_web_search', 'args': {'query': 'LangGraph Studio'}, 'id': 'call_cSCwDBfSVuCvWBVkDBdeclfB', 'type': 'tool_call'}\n",
      "\n",
      "Message ID run-f5740685-6ec3-4fe6-b3b1-69d4addc253f-0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '74a3a6',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f09dc0f-4625-6076-8002-89d485ed113e'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트된 도구 호출 출력\n",
    "print(new_message.tool_calls[0])\n",
    "\n",
    "# 메시지 ID 출력\n",
    "print(\"\\nMessage ID\", new_message.id)\n",
    "\n",
    "# 상태 업데이트\n",
    "graph.update_state(config, {\"messages\": [new_message]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph Studio'},\n",
       "  'id': 'call_cSCwDBfSVuCvWBVkDBdeclfB',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마지막 메시지의 도구 호출 가져오기\n",
    "graph.get_state(config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_cSCwDBfSVuCvWBVkDBdeclfB)\n",
      " Call ID: call_cSCwDBfSVuCvWBVkDBdeclfB\n",
      "  Args:\n",
      "    query: LangGraph Studio\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"url\": \"https://www.analyticsvidhya.com/blog/2025/06/langgraph-studio/\", \"title\": \"LangGraph Studio: A Visual Guide to Building AI Agents\", \"content\": \"LangGraph Studio is a specialised integrated development environment (IDE) that helps you build, visualise, and debug complex agentic AI applications using the LangGraph framework. LangGraph Studio is a tool that helps you build AI agents more easily. Generative AI| DeepSeek| OpenAI Agent SDK| LLM Applications using Prompt Engineering| DeepSeek from Scratch| Stability.AI| SSM & MAMBA| RAG Systems using LlamaIndex| Building LLMs for Code| Python| Microsoft Excel| Machine Learning| Deep Learning| Mastering Multimodal RAG| Introduction to Transformer Model| Bagging & Boosting| Loan Prediction| Time Series Forecasting| Tableau| Business Analytics| Vibe Coding in Windsurf| Model Deployment using FastAPI| Building Data Analyst AI Agent| Getting started with OpenAI o3-mini| Introduction to Transformers and Attention Mechanisms\", \"score\": 0.91936076, \"raw_content\": \"[Master Generative AI with 10+ Real-world Projects in 2025!\\n\\n* d\\n:* h\\n:* m\\n:* s](https://www.analyticsvidhya.com/pinnacleplus/pinnacleplus-projects?utm_source=blog_india&utm_medium=desktop_flashstrip&utm_campaign=15-Feb-2025||&utm_content=projects)\\n\\n\\n\\n[Interview Prep](https://www.analyticsvidhya.com/blog/category/interview-questions/?ref=category)\\n\\n[Prompt Engg](https://www.analyticsvidhya.com/blog/category/prompt-engineering/?ref=category)\\n\\n[AI Agents](https://www.analyticsvidhya.com/blog/category/ai-agent/?ref=category)\\n\\n[Machine Learning](https://www.analyticsvidhya.com/blog/category/machine-learning/?ref=category)\\n\\n[Deep Learning](https://www.analyticsvidhya.com/blog/category/deep-learning/?ref=category)\\n\\n[GenAI Tools](https://www.analyticsvidhya.com/blog/category/ai-tools/?ref=category)\\n\\n[AIML Projects](https://www.analyticsvidhya.com/blog/category/project/?ref=category)\\n\\n#### Reading list\\n\\n[What is Generative AI?](https://www.analyticsvidhya.com/blog/2023/04/what-is-generative-ai/)\\n\\n[Overview of generative AI applications and their impact](https://www.analyticsvidhya.com/blog/2023/11/beyond-the-buzz-exploring-the-practical-applications-of-generative-ai-in-industries/)\\n\\n[Introduction to No-code AI Development](https://www.analyticsvidhya.com/blog/2024/03/step-by-step-guide-to-training-ml-model-with-no-code/)\\n\\n[Introduction to LangChain, ChatGPT and Gemini Pro](https://www.analyticsvidhya.com/blog/2023/12/google-gemini-api/)\\n\\n[Introduction to Responsible AI](https://www.analyticsvidhya.com/blog/2023/08/responsible-ai/)\\n\\n[What are Large Language Models?](https://www.analyticsvidhya.com/blog/2023/03/an-introduction-to-large-language-models-llms/)[GPT models](https://www.analyticsvidhya.com/blog/2022/12/chatgpt-unlocking-the-potential-of-artificial-intelligence-for-human-like-conversation/)[Mistral](https://www.analyticsvidhya.com/blog/2024/07/mistral-large-2-powerful-enough-to-challenge-llama-3-1-405b/)[Llama](https://www.analyticsvidhya.com/blog/2023/08/getting-started-with-llama-2/)[Gemini](https://www.analyticsvidhya.com/blog/2023/12/what-is-google-gemini-features-usage-and-limitations/)[How to build diffferent LLM AppIications?](https://www.analyticsvidhya.com/blog/2023/07/building-llm-powered-applications-with-langchain/)\\n\\n[Introduction to Prompt Engineering](https://www.analyticsvidhya.com/blog/2023/05/what-is-prompt-engineering-guide/)[Best Practices and Guidelines for Prompt Engineering](https://www.analyticsvidhya.com/blog/2023/06/what-is-prompt-engineering/)[N shot prompting](https://www.analyticsvidhya.com/blog/2023/09/power-of-llms-zero-shot-and-few-shot-prompting/)[Chain of Thought](https://www.analyticsvidhya.com/blog/2023/12/what-is-chain-of-thought-prompting-and-its-benefits/)[Tree of Thoughts](https://www.analyticsvidhya.com/blog/2024/07/tree-of-thoughts/)[Skeleton of Thoughts](https://www.analyticsvidhya.com/blog/2024/07/skeleton-of-thoughts/)[Chain of Emotion](https://www.analyticsvidhya.com/blog/2024/07/chain-of-emotion-in-prompt-engineering/)\\n\\n[Introduction to Finetuning LLMs](https://www.analyticsvidhya.com/blog/2023/08/finetuning-large-language-models-llms/)[Parameter-Efficient Finetuning (PEFT)](https://www.analyticsvidhya.com/blog/2023/10/llm-fine-tuning-with-peft-techniques/)[LORA](https://www.analyticsvidhya.com/blog/2024/05/ludwig-a-comprehensive-guide-to-llm-fine-tuning-using-lora/)[QLORA](https://www.analyticsvidhya.com/blog/2023/08/lora-and-qlora/)[using Unsloth](https://www.analyticsvidhya.com/blog/2024/04/fine-tuning-google-gemma-with-unsloth/)[using Huggingface](https://www.analyticsvidhya.com/blog/2023/10/hugging-face-fine-tuning-tutorial/)\\n\\n[What do you mean by Training LLMs from Scratch?](https://www.analyticsvidhya.com/blog/2023/07/beginners-guide-to-build-large-language-models-from-scratch/)\\n\\n[Intro to the LangChain Ecosystem](https://www.analyticsvidhya.com/blog/2024/06/langchain-guide/)[Core Components of LangChain](https://www.analyticsvidhya.com/blog/2023/10/a-comprehensive-guide-to-using-chains-in-langchain/)[Applications of LCEL Chains](https://www.analyticsvidhya.com/blog/2024/06/langchain-expression-language/)[RAG using LangChain](https://www.analyticsvidhya.com/blog/2023/12/multi-modal-rag-pipeline-with-langchain/)[LangGraph](https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/)[LangSmith](https://www.analyticsvidhya.com/blog/2024/07/ultimate-langsmith-guide/)\\n\\n[Introduction to RAG systems](https://www.analyticsvidhya.com/blog/2023/09/retrieval-augmented-generation-rag-in-ai/)[Evaluation of RAG systems](https://www.analyticsvidhya.com/blog/2024/05/a-beginners-guide-to-evaluating-rag-pipelines-using-ragas/)\\n\\n[Getting Started with LlamaIndex](https://www.analyticsvidhya.com/blog/2023/07/llamaindex-qa-system/)[Components of LlamaIndex](https://www.analyticsvidhya.com/blog/2023/10/rag-pipeline-with-the-llama-index/)[Advanced approaches for powerful RAG system](https://www.analyticsvidhya.com/blog/2024/08/improving-real-world-rag-systems/)\\n\\n[Introduction to Stable Diffusion](https://www.analyticsvidhya.com/blog/2023/12/what-is-stable-diffusion/)[Generating image using Stable diffusion](https://www.analyticsvidhya.com/blog/2023/09/image-generation-using-stable-diffusion/)[Diffusion models](https://www.analyticsvidhya.com/blog/2024/09/what-are-diffusion-models/)[Prompt Engineering Concepts for Stable Diffusion](https://www.analyticsvidhya.com/blog/2023/05/how-to-generate-images-using-stable-diffusion/)[MidJourney](https://www.analyticsvidhya.com/blog/2023/10/how-to-use-midjourney-ai/)[Understanding Dalle 3](https://www.analyticsvidhya.com/blog/2024/07/dall-e3/)\\n\\n# LangGraph Studio\\n\\n[Janvi Kumari](https://www.analyticsvidhya.com/blog/author/janvikumari01/)   Last Updated : 20 Jun, 2025\\n\\n   6  min read\\n\\nHave you ever found it frustrating to build AI agents that perform multiple tasks? LangGraph Studio is here to solve this problem by offering a visual and interactive way to design, manage, and debug agents. Built on the LangGraph framework, this desktop tool lets you create agent workflows using a simple drag-and-drop interface. You can see each step live in a graph, pause and inspect the flow, and even update the agent while it runs. With support for memory, planning, and tool usage, plus easy integration with LangSmith, LangGraph Studio makes building complex agents much easier and more manageable.\\n\\n## Table of contents\\n\\n* [LangGraph Studio](#h-langgraph-studio)\\n* [Core Features and Capabilities](#h-core-features-and-capabilities)\\n* [How to Use LangGraph Studio](#h-how-to-use-langgraph-studio-nbsp)\\n* [Advantages of Using LangGraph](#h-advantages-of-using-langgraph)\\n* [Limitations of LangGraph Studio](#h-limitations-of-langgraph-studio)\\n* [Conclusion](#h-conclusion)\\n\\n## LangGraph Studio\\n\\nLangGraph Studio is a specialised integrated development environment (IDE) that helps you build, visualise, and debug complex agentic AI applications using the [LangGraph](https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/) framework. Unlike traditional IDEs, it gives us a visual and interactive way to work with AI agents. These agents can perform multi-step tasks, use different tools, and handle complex tasks using large language models.\\n\\n## Core Features and Capabilities\\n\\nLet’s see some of the features and capabilities of LangGraph Studio.\\n\\n### 1. Visual Graph Editor\\n\\nThe Visual Graph Editor lets you create agent workflows using a simple flowchart interface. Agent workflows can be built by simply dragging and dropping blocks, also known as nodes, and connecting them with lines, called edges, making it easy to understand how tasks flow from one to another. As you make changes to the code or settings, the entire workflow is displayed as a live visualization, where the graph is updated in real-time, allowing you to see how everything is connected and working together.\\n\\n### 2. Real-Time Debugging and Interaction\\n\\nStep-Through Execution helps in debugging the agents by letting you pause the process at each node. We can always check what’s happening at any point and then go back to earlier steps, and fix the issues using a “time travel” feature. With Interrupts, we can stop the execution before or after any step, change the agent state or response, and then continue with the new data. This is helpful when we want to test different results or try out new ideas. Human-in-the-Loop also allows us to add manual input or updates at any point, which is useful when human feedback is needed during the workflow.\\n\\n### 3. Interactive Testing and Iteration\\n\\nLive Testing lets us run agents directly from the screen, send questions or tasks, and see the answers in real time. We can also get the output in a clear format, like a structured API response. With Modify and Replay, we can quickly change the code or prompts in our editor (like VS Code), and those changes will show up right away in the Studio. This means that we don’t need to start over each time. Fork and Edit Threads let us change the state of a running task and create a new version from that point, so that we can try different ideas and test what works best.\\n\\n### 4. Collaboration and Integration\\n\\nIn LangGraph Studio, real-time editing and project sharing allow the team to work together on agent design and debugging. LangSmith integration allows us to connect for advanced observability, tracing, evaluation, prompt engineering, and dataset management, all from within the Studio. Also, LangGraph allows us to use built-in tools for version control, documentation, and project organisation.\\n\\n### 5. Advanced Agent Features\\n\\nWith Memory and State Management, we can build agents that remember our past conversations, plan next steps, and make smart decisions based on changing inputs. Assistant and Thread Management allow us to create and handle many assistants and conversation threads, which will keep track of long-term memory and test our agents using different datasets. Flexible Deployment means we can easily package and run the agents in different places, like the cloud or edge devices, and keep them updated without worrying about the platform.\\n\\n### 6. Modes for Different Users\\n\\nLangGraph Studio offers different modes like Graph Mode for a full-featured, detailed view for developers, exposing execution paths, node traversals, and intermediate agent states. Chat Mode, on the other hand, is a simplified interface for business users or those testing chat-specific agents and focusing on overall agent behaviour and conversation flow.\\n\\n## How to Use LangGraph Studio\\n\\nLangGraph Studio is a desktop app that is currently available only for Apple Silicon (MacBooks with M1, M2, or M3 chips). If you have a compatible device, then follow these instructions:\\n\\n### Install LangGraph Studio\\n\\nTo get started with LangGraph Studio, follow the steps below:\\n\\n1. **Download**: First, visit the GitHub repository to download the latest version of LangGraph Studio for your Operating System.\\n2. **Installation**: Once you have downloaded, run the installer and then follow the on-screen instructions to complete the installation.\\n\\n### Set Up LangGraph Studio\\n\\nNow, set up a LangGraph app within your project. You can clone an example repo that uses a requirements.txt file for dependencies:\\n\\n```\\ngit clone https://github.com/langchain-ai/langgraph-example.git\\n```\\n\\nNext, you can create and configure a .env file with your OpenAI, Anthropic, and Tavily keys:\\n\\n```\\ncp .env.example .env echo \\\"OPENAI_API_KEY=\\\\\\\"$OPENAI_API_KEY\\\\\\\"\\\" > .env echo \\\"ANTHROPIC_API_KEY=\\\\\\\"$ANTHROPIC_API_KEY\\\\\\\"\\\" >> .env echo \\\"TAVILY_API_KEY=\\\\\\\"$TAVILY_API_KEY\\\\\\\"\\\" >> .env\\n```\\n\\nSo, once your project is set up, you can start using it with LangGraph Studio.\\n\\nWhen you launch the LangGraph Studio desktop app for the first time, you will need to log in via [LangSmith](https://www.analyticsvidhya.com/blog/2024/07/ultimate-langsmith-guide/) to authenticate your session.\\n\\nNext, you will need a file called *langgraph.json*. This file tells LangGraph Studio where your agent is, what extra tools are needed, and which environment settings to use. You can create this file inside LangGraph Studio or add it manually to the folder. There are example folders on GitHub if you want to see how it’s done.\\n\\nOnce the folder is ready and opened, LangGraph Studio will set up everything needed to run the agent. After this, we will be able to see a visual graph showing the agent’s steps, and a box where we can talk to the agent.\\n\\nAnd as we use the agent, we will see it working step by step in real-time. It will show us which tool or function it is using and how it moves forward. If something goes wrong or the agent starts doing something we don’t want, we can pause it anytime. We can also turn on ‘debug mode’ where the agent stops after each step, so we can check and fix things as it goes.\\n\\n## Advantages of Using LangGraph\\n\\nHere are the advantages of using LangGraph:\\n\\n1. **Easy to design complex workflows:** This visual graph editor is very useful as it helps us to see and control how agent flows through nodes and edges, making it simpler to build and understand complex multi-step processes.\\n2. **Live debugging and state control:** We can always pause execution, inspect or change the agent state at any point, and then continue or rerun steps. So this makes it much easier for us to debug and test the agents.\\n3. **Powerful flexibility with full control:** As a low-level framework, it supports advanced flows like loops and parallel tasks. And we can also decide how exactly the agent should work, including tool calls and memory management.\\n4. **Great ecosystem and integrations:** LangGraph goes very well with LangChain tools such as LLMs, databases, APIs, and connects with LangSmith for tracking and debugging. We can also deploy agents to the cloud or serverless environments.\\n5. **Supports multi-agent coordination:** We can build systems where multiple agents can work together, which can be very useful for drafting, reviewing, tool use, retrieval, and more.\\n\\n## Limitations of LangGraph Studio\\n\\nHere are some of the limitations of LangGraph Studio:\\n\\n1. **Mac‑only support (for now):** LangGraph Studio only runs on Apple Silicon Macs, which means if you’re using Windows or a non-Mac system, you can’t use it yet.\\n2. **Steep learning curve & unclear docs:** It’s powerful, but many find it hard to learn, especially at first. The docs and tutorials aren’t always easy to follow, and beginners often get stuck.\\n3. **Too much for simple use cases:** If your agent workflow is pretty basic, LangGraph might overdo it. It needs a lot of setup graphs, states, and edges when a simple script or chain would do.\\n4. **Messy code structure & maintainability issues:** Users report that their agent logic can become hard to manage. There are often many layers of wrappers and explicit state definitions to maintain.\\n5. **Runtime issues and hallucination loops:** LangGraph can sometimes create weird loops where the agent talks to itself endlessly. That leads to higher costs, longer runtimes, and even reinforced hallucinations.\\n\\n## Conclusion\\n\\nLangGraph Studio is a tool that helps you build [AI](https://www.analyticsvidhya.com/blog/2021/09/introduction-to-artificial-intelligence-for-beginners/) agents more easily. It gives you a visual way to design and manage workflows. Now you can debug live, manage memory, and integrate tools quickly. This saves time on coding and lets you focus on the agent’s tasks. While there’s a learning curve, its real-time features make development smoother and easier. Whether your agent is simple or complex, LangGraph Studio simplifies the process.\\n\\n[Janvi Kumari](https://www.analyticsvidhya.com/blog/author/janvikumari01/)\\n\\nHi, I am Janvi, a passionate data science enthusiast currently working at Analytics Vidhya. My journey into the world of data began with a deep curiosity about how we can extract meaningful insights from complex datasets.\\n\\n[Beginner](https://www.analyticsvidhya.com/blog/category/beginner/)[Generative AI](https://www.analyticsvidhya.com/blog/category/generative-ai/)\\n\\n#### Login to continue reading and enjoy expert-curated content.\\n\\n## Free Courses\\n\\n[4.7\\n\\n#### Generative AI - A Way of Life\\n\\nExplore Generative AI for beginners: create text and images, use top AI tools, learn practical skills, and ethics.](https://www.analyticsvidhya.com/courses/genai-a-way-of-life/?ref=blog_freecourse)\\n\\n[4.5\\n\\n#### Getting Started with Large Language Models\\n\\nMaster Large Language Models (LLMs) with this course, offering clear guidance in NLP and model training made simple.](https://www.analyticsvidhya.com/courses/getting-started-with-llms/?ref=blog_freecourse)\\n\\n[4.6\\n\\n#### Building LLM Applications using Prompt Engineering\\n\\nThis free course guides you on building LLM apps, mastering prompt engineering, and developing chatbots with enterprise data.](https://www.analyticsvidhya.com/courses/building-llm-applications-using-prompt-engineering-free/?ref=blog_freecourse)\\n\\n[4.8\\n\\n#### Improving Real World RAG Systems: Key Challenges & Practical Solutions\\n\\nExplore practical solutions, advanced retrieval strategies, and agentic RAG systems to improve context, relevance, and accuracy in AI-driven applications.](https://www.analyticsvidhya.com/courses/improving-real-world-rag-systems-key-challenges/?ref=blog_freecourse)\\n\\n[4.7\\n\\n#### Microsoft Excel: Formulas & Functions\\n\\nMaster MS Excel for data analysis with key formulas, functions, and LookUp tools in this comprehensive course.](https://www.analyticsvidhya.com/courses/microsoft-excel-formulas-functions/?ref=blog_freecourse)\\n\\n#### Recommended Articles\\n\\n* [What is LangChain?](https://www.analyticsvidhya.com/blog/2024/06/langchain-guide/)\\n* [Top 7 Frameworks for Building AI Agents in 2025](https://www.analyticsvidhya.com/blog/2024/07/ai-agent-frameworks/)\\n* [LangGraph Tutorial for Beginners](https://www.analyticsvidhya.com/blog/2025/05/langgraph-tutorial-for-beginners/)\\n* [What is LangGraph?](https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/)\\n* [Build an AI Coding Agent with LangGraph by Lang...](https://www.analyticsvidhya.com/blog/2024/03/build-an-ai-coding-agent-with-langgraph-by-langchain/)\\n* [Agentic System for Self-documenting code using ...](https://www.analyticsvidhya.com/blog/2025/09/langgraph-agents/)\\n* [How to Create Your Personalized News Digest Usi...](https://www.analyticsvidhya.com/blog/2024/09/personalized-news-digest/)\\n* [Smolagents vs LangGraph: A Comprehensive Compar...](https://www.analyticsvidhya.com/blog/2025/01/smolagents-vs-langgraph/)\\n* [Agno Framework: A Lightweight Library for Build...](https://www.analyticsvidhya.com/blog/2025/03/agno-framework/)\\n* [n8n vs LangGraph: Which is Better?](https://www.analyticsvidhya.com/blog/2025/06/n8n-vs-langgraph/)\\n\\n### Responses From Readers\\n\\n[Cancel reply](/blog/2025/06/langgraph-studio/#respond)\\n\\n[## Become an Author\\n\\nShare insights, grow your voice, and inspire the data community.](https://www.analyticsvidhya.com/become-an-author) [* Reach a Global Audience\\n* Share Your Expertise with the World\\n* Build Your Brand & Audience\\n\\n* Join a Thriving AI Community\\n* Level Up Your AI Game\\n* Expand Your Influence in Genrative AI](https://www.analyticsvidhya.com/become-an-author)\\n\\n## Flagship Programs\\n\\n [GenAI Pinnacle Program](https://www.analyticsvidhya.com/genaipinnacle/?ref=footer)| [GenAI Pinnacle Plus Program](https://www.analyticsvidhya.com/pinnacleplus/?ref=blogflashstripfooter)| [AI/ML BlackBelt Program](https://www.analyticsvidhya.com/bbplus?ref=footer)| [Agentic AI Pioneer Program](https://www.analyticsvidhya.com/agenticaipioneer?ref=footer)\\n\\n## Free Courses\\n\\n [Generative AI](https://www.analyticsvidhya.com/courses/genai-a-way-of-life/?ref=footer)| [DeepSeek](https://www.analyticsvidhya.com/courses/getting-started-with-deepseek/?ref=footer)| [OpenAI Agent SDK](https://www.analyticsvidhya.com/courses/demystifying-openai-agents-sdk/?ref=footer)| [LLM Applications using Prompt Engineering](https://www.analyticsvidhya.com/courses/building-llm-applications-using-prompt-engineering-free/?ref=footer)| [DeepSeek from Scratch](https://www.analyticsvidhya.com/courses/deepseek-from-scratch/?ref=footer)| [Stability.AI](https://www.analyticsvidhya.com/courses/exploring-stability-ai/?ref=footer)| [SSM & MAMBA](https://www.analyticsvidhya.com/courses/building-smarter-llms-with-mamba-and-state-space-model/?ref=footer)| [RAG Systems using LlamaIndex](https://www.analyticsvidhya.com/courses/building-first-rag-systems-using-llamaindex/?ref=footer)| [Building LLMs for Code](https://www.analyticsvidhya.com/courses/building-large-language-models-for-code/?ref=footer)| [Python](https://www.analyticsvidhya.com/courses/introduction-to-data-science/?ref=footer)| [Microsoft Excel](https://www.analyticsvidhya.com/courses/microsoft-excel-formulas-functions/?ref=footer)| [Machine Learning](https://www.analyticsvidhya.com/courses/machine-learning-certification-program-beginners/?ref=footer)| [Deep Learning](https://www.analyticsvidhya.com/courses/getting-started-with-deep-learning/?ref=footer)| [Mastering Multimodal RAG](https://www.analyticsvidhya.com/courses/mastering-multimodal-rag-and-embeddings-with-amazon-nova-and-bedrock/?ref=footer)| [Introduction to Transformer Model](https://www.analyticsvidhya.com/courses/introduction-to-transformers-and-attention-mechanisms/?ref=footer)| [Bagging & Boosting](https://www.analyticsvidhya.com/courses/bagging-boosting-ML-Algorithms/?ref=footer)| [Loan Prediction](https://www.analyticsvidhya.com/courses/loan-prediction-practice-problem-using-python/?ref=footer)| [Time Series Forecasting](https://www.analyticsvidhya.com/courses/creating-time-series-forecast-using-python/?ref=footer)| [Tableau](https://www.analyticsvidhya.com/courses/tableau-for-beginners/?ref=footer)| [Business Analytics](https://www.analyticsvidhya.com/courses/introduction-to-analytics/?ref=footer)| [Vibe Coding in Windsurf](https://www.analyticsvidhya.com/courses/guide-to-vibe-coding-in-windsurf/?ref=footer)| [Model Deployment using FastAPI](https://www.analyticsvidhya.com/courses/model-deployment-using-fastapi/?ref=footer)| [Building Data Analyst AI Agent](https://www.analyticsvidhya.com/courses/building-data-analyst-AI-agent/?ref=footer)| [Getting started with OpenAI o3-mini](https://www.analyticsvidhya.com/courses/getting-started-with-openai-o3-mini/?ref=footer)| [Introduction to Transformers and Attention Mechanisms](https://www.analyticsvidhya.com/courses/introduction-to-transformers-and-attention-mechanisms/?ref=footer)\\n\\n## Popular Categories\\n\\n [AI Agents](https://www.analyticsvidhya.com/blog/category/ai-agent/?ref=footer)| [Generative AI](https://www.analyticsvidhya.com/blog/category/generative-ai/?ref=footer)| [Prompt Engineering](https://www.analyticsvidhya.com/blog/category/prompt-engineering/?ref=footer)| [Generative AI Application](https://www.analyticsvidhya.com/blog/category/generative-ai-application/?ref=footer)| [News](https://news.google.com/publications/CAAqBwgKMJiWzAswyLHjAw?hl=en-IN&gl=IN&ceid=IN%3Aen)| [Technical Guides](https://www.analyticsvidhya.com/blog/category/guide/?ref=footer)| [AI Tools](https://www.analyticsvidhya.com/blog/category/ai-tools/?ref=footer)| [Interview Preparation](https://www.analyticsvidhya.com/blog/category/interview-questions/?ref=footer)| [Research Papers](https://www.analyticsvidhya.com/blog/category/research-paper/?ref=footer)| [Success Stories](https://www.analyticsvidhya.com/blog/category/success-story/?ref=footer)| [Quiz](https://www.analyticsvidhya.com/blog/category/quiz/?ref=footer)| [Use Cases](https://www.analyticsvidhya.com/blog/category/use-cases/?ref=footer)| [Listicles](https://www.analyticsvidhya.com/blog/category/listicle/?ref=footer)\\n\\n## Generative AI Tools and Techniques\\n\\n [GANs](https://www.analyticsvidhya.com/blog/2021/10/an-end-to-end-introduction-to-generative-adversarial-networksgans/?ref=footer)| [VAEs](https://www.analyticsvidhya.com/blog/2023/07/an-overview-of-variational-autoencoders/?ref=footer)| [Transformers](https://www.analyticsvidhya.com/blog/2019/06/understanding-transformers-nlp-state-of-the-art-models?ref=footer)| [StyleGAN](https://www.analyticsvidhya.com/blog/2021/05/stylegan-explained-in-less-than-five-minutes/?ref=footer)| [Pix2Pix](https://www.analyticsvidhya.com/blog/2023/10/pix2pix-unleashed-transforming-images-with-creative-superpower?ref=footer)| [Autoencoders](https://www.analyticsvidhya.com/blog/2021/06/autoencoders-a-gentle-introduction?ref=footer)| [GPT](https://www.analyticsvidhya.com/blog/2022/10/generative-pre-training-gpt-for-natural-language-understanding/?ref=footer)| [BERT](https://www.analyticsvidhya.com/blog/2022/11/comprehensive-guide-to-bert/?ref=footer)| [Word2Vec](https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/?ref=footer)| [LSTM](https://www.analyticsvidhya.com/blog/2021/03/introduction-to-long-short-term-memory-lstm?ref=footer)| [Attention Mechanisms](https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/?ref=footer)| [Diffusion Models](https://www.analyticsvidhya.com/blog/2024/09/what-are-diffusion-models/?ref=footer)| [LLMs](https://www.analyticsvidhya.com/blog/2023/03/an-introduction-to-large-language-models-llms/?ref=footer)| [SLMs](https://www.analyticsvidhya.com/blog/2024/05/what-are-small-language-models-slms/?ref=footer)| [Encoder Decoder Models](https://www.analyticsvidhya.com/blog/2023/10/advanced-encoders-and-decoders-in-generative-ai/?ref=footer)| [Prompt Engineering](https://www.analyticsvidhya.com/blog/2023/06/what-is-prompt-engineering/?ref=footer)| [LangChain](https://www.analyticsvidhya.com/blog/2024/06/langchain-guide/?ref=footer)| [LlamaIndex](https://www.analyticsvidhya.com/blog/2023/10/rag-pipeline-with-the-llama-index/?ref=footer)| [RAG](https://www.analyticsvidhya.com/blog/2023/09/retrieval-augmented-generation-rag-in-ai/?ref=footer)| [Fine-tuning](https://www.analyticsvidhya.com/blog/2023/08/fine-tuning-large-language-models/?ref=footer)| [LangChain AI Agent](https://www.analyticsvidhya.com/blog/2024/07/langchains-agent-framework/?ref=footer)| [Multimodal Models](https://www.analyticsvidhya.com/blog/2023/12/what-are-multimodal-models/?ref=footer)| [RNNs](https://www.analyticsvidhya.com/blog/2022/03/a-brief-overview-of-recurrent-neural-networks-rnn/?ref=footer)| [DCGAN](https://www.analyticsvidhya.com/blog/2021/07/deep-convolutional-generative-adversarial-network-dcgan-for-beginners/?ref=footer)| [ProGAN](https://www.analyticsvidhya.com/blog/2021/05/progressive-growing-gan-progan/?ref=footer)| [Text-to-Image Models](https://www.analyticsvidhya.com/blog/2024/02/llm-driven-text-to-image-with-diffusiongpt/?ref=footer)| [DDPM](https://www.analyticsvidhya.com/blog/2024/08/different-components-of-diffusion-models/?ref=footer)| [Document Question Answering](https://www.analyticsvidhya.com/blog/2024/04/a-hands-on-guide-to-creating-a-pdf-based-qa-assistant-with-llama-and-llamaindex/?ref=footer)| [Imagen](https://www.analyticsvidhya.com/blog/2024/09/google-imagen-3/?ref=footer)| [T5 (Text-to-Text Transfer Transformer)](https://www.analyticsvidhya.com/blog/2024/05/text-summarization-using-googles-t5-base/?ref=footer)| [Seq2seq Models](https://www.analyticsvidhya.com/blog/2020/08/a-simple-introduction-to-sequence-to-sequence-models/?ref=footer)| [WaveNet](https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/?ref=footer)| [Attention Is All You Need (Transformer Architecture)](https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/?ref=footer) | [WindSurf](https://www.analyticsvidhya.com/blog/2024/11/windsurf-editor/?ref=footer)| [Cursor](https://www.analyticsvidhya.com/blog/2025/03/vibe-coding-with-cursor-ai/?ref=footer)\\n\\n## Popular GenAI Models\\n\\n [Llama 4](https://www.analyticsvidhya.com/blog/2025/04/meta-llama-4/?ref=footer)| [Llama 3.1](https://www.analyticsvidhya.com/blog/2024/07/meta-llama-3-1/?ref=footer)| [GPT 4.5](https://www.analyticsvidhya.com/blog/2025/02/openai-gpt-4-5/?ref=footer)| [GPT 4.1](https://www.analyticsvidhya.com/blog/2025/04/open-ai-gpt-4-1/?ref=footer)| [GPT 4o](https://www.analyticsvidhya.com/blog/2025/03/updated-gpt-4o/?ref=footer)| [o3-mini](https://www.analyticsvidhya.com/blog/2025/02/openai-o3-mini/?ref=footer)| [Sora](https://www.analyticsvidhya.com/blog/2024/12/openai-sora/?ref=footer)| [DeepSeek R1](https://www.analyticsvidhya.com/blog/2025/01/deepseek-r1/?ref=footer)| [DeepSeek V3](https://www.analyticsvidhya.com/blog/2025/01/ai-application-with-deepseek-v3/?ref=footer)| [Janus Pro](https://www.analyticsvidhya.com/blog/2025/01/deepseek-janus-pro-7b/?ref=footer)| [Veo 2](https://www.analyticsvidhya.com/blog/2024/12/googles-veo-2/?ref=footer)| [Gemini 2.5 Pro](https://www.analyticsvidhya.com/blog/2025/03/gemini-2-5-pro-experimental/?ref=footer)| [Gemini 2.0](https://www.analyticsvidhya.com/blog/2025/02/gemini-2-0-everything-you-need-to-know-about-googles-latest-llms/?ref=footer)| [Gemma 3](https://www.analyticsvidhya.com/blog/2025/03/gemma-3/?ref=footer)| [Claude Sonnet 3.7](https://www.analyticsvidhya.com/blog/2025/02/claude-sonnet-3-7/?ref=footer)| [Claude 3.5 Sonnet](https://www.analyticsvidhya.com/blog/2024/06/claude-3-5-sonnet/?ref=footer)| [Phi 4](https://www.analyticsvidhya.com/blog/2025/02/microsoft-phi-4-multimodal/?ref=footer)| [Phi 3.5](https://www.analyticsvidhya.com/blog/2024/09/phi-3-5-slms/?ref=footer)| [Mistral Small 3.1](https://www.analyticsvidhya.com/blog/2025/03/mistral-small-3-1/?ref=footer)| [Mistral NeMo](https://www.analyticsvidhya.com/blog/2024/08/mistral-nemo/?ref=footer)| [Mistral-7b](https://www.analyticsvidhya.com/blog/2024/01/making-the-most-of-mistral-7b-with-finetuning/?ref=footer)| [Bedrock](https://www.analyticsvidhya.com/blog/2024/02/building-end-to-end-generative-ai-models-with-aws-bedrock/?ref=footer)| [Vertex AI](https://www.analyticsvidhya.com/blog/2024/02/build-deploy-and-manage-ml-models-with-google-vertex-ai/?ref=footer)| [Qwen QwQ 32B](https://www.analyticsvidhya.com/blog/2025/03/qwens-qwq-32b/?ref=footer)| [Qwen 2](https://www.analyticsvidhya.com/blog/2024/06/qwen2/?ref=footer)| [Qwen 2.5 VL](https://www.analyticsvidhya.com/blog/2025/01/qwen2-5-vl-vision-model/?ref=footer)| [Qwen Chat](https://www.analyticsvidhya.com/blog/2025/03/qwen-chat/?ref=footer)| [Grok 3](https://www.analyticsvidhya.com/blog/2025/02/grok-3/?ref=footer)\\n\\n## AI Development Frameworks\\n\\n [n8n](https://www.analyticsvidhya.com/blog/2025/03/content-creator-agent-with-n8n/?ref=footer)| [LangChain](https://www.analyticsvidhya.com/blog/2024/06/langchain-guide/?ref=footer)| [Agent SDK](https://www.analyticsvidhya.com/blog/2025/03/open-ai-responses-api/?ref=footer)| [A2A by Google](https://www.analyticsvidhya.com/blog/2025/04/agent-to-agent-protocol/?ref=footer)| [SmolAgents](https://www.analyticsvidhya.com/blog/2025/01/smolagents/?ref=footer)| [LangGraph](https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/?ref=footer)| [CrewAI](https://www.analyticsvidhya.com/blog/2024/01/building-collaborative-ai-agents-with-crewai/?ref=footer)| [Agno](https://www.analyticsvidhya.com/blog/2025/03/agno-framework/?ref=footer)| [LangFlow](https://www.analyticsvidhya.com/blog/2023/06/langflow-ui-for-langchain-to-develop-applications-with-llms/?ref=footer)| [AutoGen](https://www.analyticsvidhya.com/blog/2023/11/launching-into-autogen-exploring-the-basics-of-a-multi-agent-framework/?ref=footer)| [LlamaIndex](https://www.analyticsvidhya.com/blog/2024/08/implementing-ai-agents-using-llamaindex/?ref=footer)| [Swarm](https://www.analyticsvidhya.com/blog/2024/12/managing-multi-agent-systems-with-openai-swarm/?ref=footer)| [AutoGPT](https://www.analyticsvidhya.com/blog/2023/05/learn-everything-about-autogpt/?ref=footer)\\n\\n## Data Science Tools and Techniques\\n\\n [Python](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-learn-data-science-python-scratch-2/?ref=footer)| [R](https://www.analyticsvidhya.com/blog/2016/02/complete-tutorial-learn-data-science-scratch/?ref=footer)| [SQL](https://www.analyticsvidhya.com/blog/2022/01/learning-sql-from-basics-to-advance/?ref=footer)| [Jupyter Notebooks](https://www.analyticsvidhya.com/blog/2018/05/starters-guide-jupyter-notebook/?ref=footer)| [TensorFlow](https://www.analyticsvidhya.com/blog/2021/11/tensorflow-for-beginners-with-examples-and-python-implementation/?ref=footer)| [Scikit-learn](https://www.analyticsvidhya.com/blog/2021/08/complete-guide-on-how-to-learn-scikit-learn-for-data-science/?ref=footer)| [PyTorch](https://www.analyticsvidhya.com/blog/2018/02/pytorch-tutorial/?ref=footer)| [Tableau](https://www.analyticsvidhya.com/blog/2021/09/a-complete-guide-to-tableau-for-beginners-in-data-visualization/?ref=footer)| [Apache Spark](https://www.analyticsvidhya.com/blog/2022/08/introduction-to-on-apache-spark-and-its-datasets/?ref=footer)| [Matplotlib](https://www.analyticsvidhya.com/blog/2021/10/introduction-to-matplotlib-using-python-for-beginners/?ref=footer)| [Seaborn](https://www.analyticsvidhya.com/blog/2021/02/a-beginners-guide-to-seaborn-the-simplest-way-to-learn/?ref=footer)| [Pandas](https://www.analyticsvidhya.com/blog/2021/03/pandas-functions-for-data-analysis-and-manipulation/?ref=footer)| [Hadoop](https://www.analyticsvidhya.com/blog/2022/05/an-introduction-to-hadoop-ecosystem-for-big-data/?ref=footer)| [Docker](https://www.analyticsvidhya.com/blog/2021/10/end-to-end-guide-to-docker-for-aspiring-data-engineers/?ref=footer)| [Git](https://www.analyticsvidhya.com/blog/2021/09/git-and-github-tutorial-for-beginners/?ref=footer)| [Keras](https://www.analyticsvidhya.com/blog/2016/10/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study/?ref=footer)| [Apache Kafka](https://www.analyticsvidhya.com/blog/2022/12/introduction-to-apache-kafka-fundamentals-and-working/?ref=footer)| [AWS](https://www.analyticsvidhya.com/blog/2020/09/what-is-aws-amazon-web-services-data-science/?ref=footer)| [NLP](https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/?ref=footer)| [Random Forest](https://www.analyticsvidhya.com/blog/2021/06/understanding-random-forest/?ref=footer)| [Computer Vision](https://www.analyticsvidhya.com/blog/2020/01/computer-vision-learning-path/?ref=footer)| [Data Visualization](https://www.analyticsvidhya.com/blog/2021/04/a-complete-beginners-guide-to-data-visualization/?ref=footer)| [Data Exploration](https://www.analyticsvidhya.com/blog/2016/01/guide-data-exploration/?ref=footer)| [Big Data](https://www.analyticsvidhya.com/blog/2021/05/what-is-big-data-introduction-uses-and-applications/?ref=footer)| [Common Machine Learning Algorithms](https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/?ref=footer)| [Machine Learning](https://www.analyticsvidhya.com/blog/category/Machine-Learning/?ref=footer)| [Google Data Science Agent](https://www.analyticsvidhya.com/blog/2025/03/gemini-data-science-agent/?ref=footer)\\n\\n## Continue your learning for FREE\\n\\n[Forgot your password?](https://id.analyticsvidhya.com/auth/password/reset/?utm_source=newhomepage)\\n\\n## Enter email address to continue\\n\\n## Enter OTP sent to\\n\\nWrong OTP.\\n\\n### Enter the OTP\\n\\nResend OTP\\n\\nResend OTP in 45s\\n\\n \"}, {\"url\": \"https://github.com/langchain-ai/langgraph-studio\", \"title\": \"langchain-ai/langgraph-studio: Desktop app for prototyping ...\", \"content\": \"# LangGraph Studio LangGraph Studio works for graphs that are deployed on LangGraph Platform or for graphs that are running locally via the LangGraph Server. Graph mode exposes the full feature-set of Studio and is useful when you would like as many details about the execution of your agent, including the nodes traversed, intermediate states, and LangSmith integrations (such as adding to datasets an playground). Please use the command-line interface (`langgraph up` or `langgraph dev`) to create a compatible server and interact with the studio. When running Studio with `langgraph dev`, you may see \\\"Failed to load assistants\\\" errors. When running Studio with `langgraph dev`, you may see \\\"Failed to load assistants\\\" errors.\", \"score\": 0.8790744, \"raw_content\": \"[Skip to content](#start-of-content)    \\n\\n\\n## Navigation Menu\\n\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Flanggraph-studio) \\n\\nAppearance settings\\n\\n# Search code, repositories, users, issues, pull requests...\\n\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\n\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Flanggraph-studio)\\n\\n [Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=langchain-ai%2Flanggraph-studio) \\n\\nAppearance settings\\n\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\n\\n{{ message }}\\n\\nThis repository was archived by the owner on Jul 29, 2025. It is now read-only.\\n\\n[langchain-ai](/langchain-ai)   /  **[langgraph-studio](/langchain-ai/langgraph-studio)**  Public archive\\n\\n* [Notifications](/login?return_to=%2Flangchain-ai%2Flanggraph-studio)  You must be signed in to change notification settings\\n* [Fork 222](/login?return_to=%2Flangchain-ai%2Flanggraph-studio)\\n* [Star  3.2k](/login?return_to=%2Flangchain-ai%2Flanggraph-studio)\\n\\nDesktop app for prototyping and debugging LangGraph applications locally.\\n\\n[studio.langchain.com](https://studio.langchain.com \\\"https://studio.langchain.com\\\")\\n\\n[3.2k stars](/langchain-ai/langgraph-studio/stargazers)   [222 forks](/langchain-ai/langgraph-studio/forks)   [Branches](/langchain-ai/langgraph-studio/branches)   [Tags](/langchain-ai/langgraph-studio/tags)   [Activity](/langchain-ai/langgraph-studio/activity)\\n\\n[Star](/login?return_to=%2Flangchain-ai%2Flanggraph-studio)\\n\\n[Notifications](/login?return_to=%2Flangchain-ai%2Flanggraph-studio)  You must be signed in to change notification settings\\n\\n# langchain-ai/langgraph-studio\\n\\n[Branches](/langchain-ai/langgraph-studio/branches)[Tags](/langchain-ai/langgraph-studio/tags)\\n\\nOpen more actions menu\\n\\n## Folders and files\\n\\n| Name | Name | Last commit message | Last commit date |\\n| --- | --- | --- | --- |\\n| Latest commit   History[58 Commits](/langchain-ai/langgraph-studio/commits/main/) |\\n| [img](/langchain-ai/langgraph-studio/tree/main/img \\\"img\\\") | [img](/langchain-ai/langgraph-studio/tree/main/img \\\"img\\\") |  |  |\\n| [README.md](/langchain-ai/langgraph-studio/blob/main/README.md \\\"README.md\\\") | [README.md](/langchain-ai/langgraph-studio/blob/main/README.md \\\"README.md\\\") |  |  |\\n| [cover.svg](/langchain-ai/langgraph-studio/blob/main/cover.svg \\\"cover.svg\\\") | [cover.svg](/langchain-ai/langgraph-studio/blob/main/cover.svg \\\"cover.svg\\\") |  |  |\\n|  |\\n\\n## Repository files navigation\\n\\n# LangGraph Studio\\n\\nLangGraph Studio is a specialized agent IDE that enables visualization, interaction, and debugging of agentic systems that implement the LangGraph Server API protocol. Studio also integrates with LangSmith to enable tracing, evaluation, and prompt engineering.\\n\\n## Features\\n\\nKey features of LangGraph Studio:\\n\\n* Visualize your graph architecture\\n* [Run and interact with your agent](https://langchain-ai.github.io/langgraph/cloud/how-tos/invoke_studio/)\\n* [Manage assistants](https://langchain-ai.github.io/langgraph/cloud/how-tos/studio/manage_assistants/)\\n* [Manage threads](https://langchain-ai.github.io/langgraph/cloud/how-tos/threads_studio/)\\n* [Iterate on prompts](https://langchain-ai.github.io/langgraph/cloud/how-tos/iterate_graph_studio/)\\n* [Run experiments over a dataset](https://langchain-ai.github.io/langgraph/cloud/how-tos/studio/run_evals/)\\n* Manage [long term memory](https://langchain-ai.github.io/langgraph/concepts/memory/)\\n* Debug agent state via [time travel](https://langchain-ai.github.io/langgraph/concepts/time-travel/)\\n\\nLangGraph Studio works for graphs that are deployed on [LangGraph Platform](https://langchain-ai.github.io/langgraph/cloud/quick_start/) or for graphs that are running locally via the [LangGraph Server](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/).\\n\\nStudio supports two modes:\\n\\n### Graph mode\\n\\nGraph mode exposes the full feature-set of Studio and is useful when you would like as many details about the execution of your agent, including the nodes traversed, intermediate states, and LangSmith integrations (such as adding to datasets an playground).\\n\\n### Chat mode\\n\\nChat mode is a simpler UI for iterating on and testing chat-specific agents. It is useful for business users and those who want to test overall agent behavior. Chat mode is only supported for graph's whose state includes or extends [`MessagesState`](https://langchain-ai.github.io/langgraph/how-tos/graph-api/#messagesstate).\\n\\n## Learn more\\n\\n* See this guide on how to [get started](http://127.0.0.1:8000/langgraph/cloud/how-tos/studio/quick_start/) with LangGraph Studio.\\n* See the full [LangGraph Platform docs](https://langchain-ai.github.io/langgraph/concepts/langgraph_platform/).\\n\\n## Troubleshooting\\n\\n### Desktop App (deprecated)\\n\\nNote: The MacOS Studio desktop app, which was previously the main way to run Studio, has now been deprecated. Please use the command-line interface (`langgraph up` or `langgraph dev`) to create a compatible server and interact with the studio. The CLI is compatible with MacOS, Windows, and Linux and supports a superset of the functionality originally built into this desktop app.\\n\\n#### How do I access local services and models such as Ollama, Chroma, etc?\\n\\nLangGraph Studio relies on Docker Compose to run the API, Redis and Postgres, which in turn creates its own network. Thus, to access local services you need to use `host.docker.internal` as the hostname instead of `localhost`. See [#112](https://github.com/langchain-ai/langgraph-studio/issues/112) for more details. 3\\n\\n### Failing to install native dependencies during build\\n\\nBy default, we try to make the image as small as possible, thus some dependencies such as `gcc` or `build-essentials` are missing from the base image. If you need to install additional dependencies, you can do so by adding additional Dockerfile instructions in the `dockerfile_lines` section of your `langgraph.json` file:\\n\\n```\\n{ \\\"dockerfile_lines\\\": [ \\\"RUN apt-get update && apt-get install -y gcc\\\" ] } \\n```\\n\\nSee [How to customize Dockerfile](https://langchain-ai.github.io/langgraph/cloud/deployment/custom_docker) for more details.\\n\\n### Safari Connection Issues\\n\\nSafari blocks plain-HTTP traffic on localhost. When running Studio with `langgraph dev`, you may see \\\"Failed to load assistants\\\" errors.\\n\\n#### Solution 1: Use Cloudflare Tunnel\\n\\n=== \\\"Python\\\"\\n\\n```\\n```shell pip install -U langgraph-cli>=0.2.6 langgraph dev --tunnel ``` \\n```\\n\\n=== \\\"JS\\\"\\n\\n```\\n```shell # Requires @langchain/langgraph-cli>=0.0.26 npx @langchain/langgraph-cli dev ``` \\n```\\n\\nThe command outputs a URL in this format:\\n\\n```\\n?\\n```\\n\\nUse this URL in Safari to load Studio. Here, the `baseUrl` parameter specifies your agent server endpoint.\\n\\n#### Solution 2: Use Chromium Browser\\n\\nChrome and other Chromium browsers allow HTTP on localhost. Use `langgraph dev` without additional configuration.\\n\\n### Brave Connection Issues\\n\\nBrave blocks plain-HTTP traffic on localhost when Brave Shields are enabled. When running Studio with `langgraph dev`, you may see \\\"Failed to load assistants\\\" errors.\\n\\n#### Solution 1: Disable Brave Shields\\n\\nDisable Brave Shields for LangSmith using the Brave icon in the URL bar.\\n\\n#### Solution 2: Use Cloudflare Tunnel\\n\\n=== \\\"Python\\\"\\n\\n```\\n```shell pip install -U langgraph-cli>=0.2.6 langgraph dev --tunnel ``` \\n```\\n\\n=== \\\"JS\\\"\\n\\n```\\n```shell # Requires @langchain/langgraph-cli>=0.0.26 npx @langchain/langgraph-cli dev ``` \\n```\\n\\nThe command outputs a URL in this format:\\n\\n```\\n?\\n```\\n\\nUse this URL in Brave to load Studio. Here, the `baseUrl` parameter specifies your agent server endpoint.\\n\\n### Graph Edge Issues\\n\\nUndefined conditional edges may show unexpected connections in your graph. This is because without proper definition, LangGraph Studio assumes the conditional edge could access all other nodes. To address this, explicitly define the routing paths using one of these methods:\\n\\n#### Solution 1: Path Map\\n\\nDefine a mapping between router outputs and target nodes:\\n\\n=== \\\"Python\\\"\\n\\n```\\n```python graph.add_conditional_edges(\\\"node_a\\\", routing_function, {True: \\\"node_b\\\", False: \\\"node_c\\\"}) ``` \\n```\\n\\n=== \\\"Javascript\\\"\\n\\n```\\n```ts graph.addConditionalEdges(\\\"node_a\\\", routingFunction, { true: \\\"node_b\\\", false: \\\"node_c\\\" }); ``` \\n```\\n\\n#### Solution 2: Router Type Definition (Python)\\n\\nSpecify possible routing destinations using Python's `Literal` type:\\n\\n```\\ndef routing_function state GraphState -> Literal \\\"node_b\\\" \\\"node_c\\\" if state 'some_condition' == True return \\\"node_b\\\" else return \\\"node_c\\\"\\n```\\n\\n## About\\n\\nDesktop app for prototyping and debugging LangGraph applications locally.\\n\\n[studio.langchain.com](https://studio.langchain.com \\\"https://studio.langchain.com\\\")\\n\\n### Topics\\n\\n[ai](/topics/ai \\\"Topic: ai\\\")   [desktop](/topics/desktop \\\"Topic: desktop\\\")   [agents](/topics/agents \\\"Topic: agents\\\")   [langgraph](/topics/langgraph \\\"Topic: langgraph\\\")\\n\\n### Resources\\n\\n### Uh oh!\\n\\nThere was an error while loading. Please reload this page.\\n\\n[Custom properties](/langchain-ai/langgraph-studio/custom-properties)\\n\\n### Stars\\n\\n[**3.2k** stars](/langchain-ai/langgraph-studio/stargazers)\\n\\n### Watchers\\n\\n[**31** watching](/langchain-ai/langgraph-studio/watchers)\\n\\n### Forks\\n\\n[**222** forks](/langchain-ai/langgraph-studio/forks)\\n\\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Flangchain-ai%2Flanggraph-studio&report=langchain-ai+%28user%29)\\n\\n## [Releases 31](/langchain-ai/langgraph-studio/releases)\\n\\n[0.0.37  Latest\\n\\nMar 11, 2025](/langchain-ai/langgraph-studio/releases/tag/v0.0.37)\\n\\n[+ 30 releases](/langchain-ai/langgraph-studio/releases)\\n\\n## [Contributors 11](/langchain-ai/langgraph-studio/graphs/contributors)\\n\\nYou can’t perform that action at this time.\\n\\n \"}, {\"url\": \"https://medium.com/@astropomeai/langgraph-studio-empowering-ai-agent-development-2a815fe13703\", \"title\": \"LangGraph Studio: Empowering AI Agent Development\", \"content\": \"# LangGraph Studio: Empowering AI Agent Development LangGraph, a library provided as part of the LangChain framework, serves as a powerful foundation for building AI Agent applications. The combination of LangGraph and LangGraph Studio creates a new paradigm in AI Agent application development. With LangGraph providing a robust construction foundation and LangGraph Studio visualizing and optimizing the development process, developers can now create advanced AI Agent applications more efficiently. ## GitHub - langchain-ai/langgraph-studio: Desktop app for prototyping and debugging LangGraph… - langchain-ai/langgraph-studio git clone https://github.com/langchain-ai/langgraph-example.gitcd langgraph-example clone cd LangGraph Studio is a powerful IDE that streamlines AI Agent development and assists in creating advanced applications. ### LangGraph is a powerful framework for building stateful, conversational AI applications.\", \"score\": 0.86413884, \"raw_content\": \"[Sitemap](/sitemap/sitemap.xml)\\n\\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F2a815fe13703&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40astropomeai%2Flanggraph-studio-empowering-ai-agent-development-2a815fe13703&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n[Sign in](/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40astropomeai%2Flanggraph-studio-empowering-ai-agent-development-2a815fe13703&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\\n\\n# LangGraph Studio: Empowering AI Agent Development\\n\\n3 min readAug 25, 2024\\n\\nLangGraph, a library provided as part of the LangChain framework, serves as a powerful foundation for building AI Agent applications. By utilizing graph structures, it enables efficient design and implementation of complex reasoning processes and multi-stage decision making. Developers can create flexible, reusable components and simplify state management.\\n\\nMeanwhile, LangGraph Studio is an IDE for visualizing and debugging applications created with LangGraph. It allows intuitive understanding of application structures and detailed examination of each processing step. Furthermore, it provides features to edit states during execution and test different scenarios, streamlining the development process.\\n\\nThe combination of LangGraph and LangGraph Studio creates a new paradigm in AI Agent application development. With LangGraph providing a robust construction foundation and LangGraph Studio visualizing and optimizing the development process, developers can now create advanced AI Agent applications more efficiently.\\n\\n[## GitHub - langchain-ai/langgraph-studio: Desktop app for prototyping and debugging LangGraph…\\n\\n### Desktop app for prototyping and debugging LangGraph applications locally. - langchain-ai/langgraph-studio\\n\\ngithub.com](https://github.com/langchain-ai/langgraph-studio?source=post_page-----2a815fe13703---------------------------------------)\\n\\n### Key Features of LangGraph Studio:\\n\\n* Graph Visualization  \\n   \\\\* Visually display the structure of applications created with LangGraph  \\n   \\\\* Intuitively understand the relationships between nodes and edges\\n* Interactive Execution  \\n   \\\\* Execute each node of the graph individually  \\n   \\\\* Run graphs with different inputs and settings  \\n   \\\\* Check execution results in real-time\\n* Thread Management  \\n   \\\\* Create and manage multiple execution threads  \\n   \\\\* Switch between and compare threads\\n* State Editing  \\n   \\\\* Dynamically edit the state of executing threads  \\n   \\\\* Fork new threads from edited states\\n* Interrupt Functionality  \\n   \\\\* Set interrupts for all nodes or specific nodes  \\n   \\\\* Enable step-by-step execution or stopping at specific points\\n* Human-in-the-Loop Support  \\n   \\\\* Support workflows requiring human intervention  \\n   \\\\* Allow manual input or decision-making at specific points\\n* Project Configuration Editing  \\n   \\\\* Edit langgraph.json file interactively via GUI  \\n   \\\\* Immediate reflection of setting changes and server restart\\n* Integration with Code Editing  \\n   \\\\* Integration with external editors like VS Code  \\n   \\\\* Automatic reload after code changes  \\n   \\\\* Re-execute changed nodes\\n* LangSmith Integration  \\n   \\\\* Login and authentication through LangSmith  \\n   \\\\* Facilitate team collaboration\\n\\n### Execution (local deploy)\\n\\n[## Quick Start\\n\\n### Build language agents as graphs\\n\\nlangchain-ai.github.io](https://langchain-ai.github.io/langgraph/cloud/quick_start/?source=post_page-----2a815fe13703---------------------------------------)\\n\\n**1. Install and Configure Docker**\\n\\n## Get Astropomeai’s stories in your inbox\\n\\nJoin Medium for free to get updates from this writer.\\n\\nInstall Docker Desktop (including docker-compose version 2.22.0+).\\n\\n[## Install Docker Engine\\n\\n### Learn how to choose the best method for you to install Docker Engine. This client-server application is available on…\\n\\ndocs.docker.com](https://docs.docker.com/engine/install/?source=post_page-----2a815fe13703---------------------------------------)\\n\\n**2. Clone the Repository**\\n\\n```\\ngit clone https://github.com/langchain-ai/langgraph-example.gitcd langgraph-example clone cd\\n```\\n\\n**3. Set Environment Variables**\\n\\nCopy .env.example file to .env:\\n\\n```\\ncp .env.example .env cp env\\n```\\n\\nOpen the .env file and add necessary API keys:\\n\\n* ANTHROPIC\\\\_API\\\\_KEY: [Anthropic for the LLM](https://console.anthropic.com/)\\n* TAVILY\\\\_API\\\\_KEY: [Tavily for the search engine](https://app.tavily.com/)\\n* LANGSMITH\\\\_API\\\\_KEY: [LangSmith for hosting](https://smith.langchain.com/)\\n\\n**4. Install LangGraph CLI**\\n\\n```\\npip install langgraph-cli\\n```\\n\\n**5. Start Local API Server**\\n\\n```\\nlanggraph up\\n```\\n\\nWhen successful, you’ll see a message like “Ready! — API: <http://localhost:8123>\\\".\\n\\n**6. Try Asking About Real-time Information (Weather)**\\n\\nYou can observe the agent using tavily\\\\_search\\\\_results\\\\_json to retrieve real-time information and create a response.\\n\\n### Conclusion\\n\\nLangGraph Studio is a powerful IDE that streamlines AI Agent development and assists in creating advanced applications. Combined with LangChain, it enables developers to develop AI Agents more quickly and effectively, contributing to business and society.\\n\\n[Llm](/tag/llm?source=post_page-----2a815fe13703---------------------------------------)\\n\\n[Langchain](/tag/langchain?source=post_page-----2a815fe13703---------------------------------------)\\n\\n[Langgraph](/tag/langgraph?source=post_page-----2a815fe13703---------------------------------------)\\n\\n[## Written by Astropomeai](/@astropomeai?source=post_page---post_author_info--2a815fe13703---------------------------------------)\\n\\n[183 followers](/@astropomeai/followers?source=post_page---post_author_info--2a815fe13703---------------------------------------)\\n\\n·[24 following](/@astropomeai/following?source=post_page---post_author_info--2a815fe13703---------------------------------------)\\n\\nChasing insights on the frontiers of science and technology🚀 <https://twitter.com/AstroPomeAi>\\n\\n## No responses yet\\n\\nWrite a response\\n\\n[What are your thoughts?](/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2F%40astropomeai%2Flanggraph-studio-empowering-ai-agent-development-2a815fe13703&source=---post_responses--2a815fe13703---------------------respond_sidebar------------------)\\n\\n## More from Astropomeai\\n\\n[Astropomeai](/@astropomeai?source=post_page---author_recirc--2a815fe13703----0---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\n[## Implementing Map-Reduce with LangGraph: Creating Flexible Branches for Parallel Execution\\n\\n### In this article, we’ll introduce the following LangChain post while implementing the previously discussed Tree of Thoughts algorithm using…](/@astropomeai/implementing-map-reduce-with-langgraph-creating-flexible-branches-for-parallel-execution-b6dc44327c0e?source=post_page---author_recirc--2a815fe13703----0---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\nJul 23, 2024\\n\\n[145\\n\\n5](/@astropomeai/implementing-map-reduce-with-langgraph-creating-flexible-branches-for-parallel-execution-b6dc44327c0e?source=post_page---author_recirc--2a815fe13703----0---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\n[Astropomeai](/@astropomeai?source=post_page---author_recirc--2a815fe13703----1---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\n[## LangMem: Long-Term Memory for AI Agents\\n\\n### What is LangMem?](/@astropomeai/langmem-long-term-memory-for-ai-agents-366d7256ddce?source=post_page---author_recirc--2a815fe13703----1---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\nMar 9\\n\\n[12](/@astropomeai/langmem-long-term-memory-for-ai-agents-366d7256ddce?source=post_page---author_recirc--2a815fe13703----1---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\n[Astropomeai](/@astropomeai?source=post_page---author_recirc--2a815fe13703----2---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\n[## Integrate OpenAI Agents SDK with Slack: Build an Agent to Operate Slack with Natural Language\\n\\n### Leverage the power of OpenAI’s Agents SDK and Slack to create intelligent bots that understand natural language and interact with your…](/@astropomeai/integrate-openai-agents-sdk-with-slack-build-an-agent-to-operate-slack-with-natural-language-f8f5144b566a?source=post_page---author_recirc--2a815fe13703----2---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\nApr 29\\n\\n[12](/@astropomeai/integrate-openai-agents-sdk-with-slack-build-an-agent-to-operate-slack-with-natural-language-f8f5144b566a?source=post_page---author_recirc--2a815fe13703----2---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\n[Astropomeai](/@astropomeai?source=post_page---author_recirc--2a815fe13703----3---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\n[## Implementing the Tree of Thoughts in LangChain’s Chain\\n\\n### Introduction](/@astropomeai/implementing-the-tree-of-thoughts-in-langchains-chain-f2ebc5864fac?source=post_page---author_recirc--2a815fe13703----3---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\nJul 11, 2023\\n\\n[143\\n\\n3](/@astropomeai/implementing-the-tree-of-thoughts-in-langchains-chain-f2ebc5864fac?source=post_page---author_recirc--2a815fe13703----3---------------------4b1f79d2_dca7_4b2a_aa35_07dc4e91f391--------------)\\n\\n[See all from Astropomeai](/@astropomeai?source=post_page---author_recirc--2a815fe13703---------------------------------------)\\n\\n## Recommended from Medium\\n\\nIn\\n\\n[Artificial Intelligence in Plain English](https://medium.com/ai-in-plain-english?source=post_page---read_next_recirc--2a815fe13703----0---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nby\\n\\n[Sajith K](/@sajith_k?source=post_page---read_next_recirc--2a815fe13703----0---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\n[## Using PostgreSQL with LangGraph for State Management and Vector Storage\\n\\n### LangGraph is a powerful framework for building stateful, conversational AI applications. When combined with PostgreSQL, it enables robust…](/ai-in-plain-english/using-postgresql-with-langgraph-for-state-management-and-vector-storage-df4ca9d9b89e?source=post_page---read_next_recirc--2a815fe13703----0---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nApr 27\\n\\n[64\\n\\n2](/ai-in-plain-english/using-postgresql-with-langgraph-for-state-management-and-vector-storage-df4ca9d9b89e?source=post_page---read_next_recirc--2a815fe13703----0---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nIn\\n\\n[𝐀𝐈 𝐦𝐨𝐧𝐤𝐬.𝐢𝐨](https://medium.com/aimonks?source=post_page---read_next_recirc--2a815fe13703----1---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nby\\n\\n[Prince Krampah](/@princekrampah?source=post_page---read_next_recirc--2a815fe13703----1---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\n[## Multi-agent System Design Patterns From Scratch In Python | ReAct Agents\\n\\n### Hello there guys, welcome back to another exciting article in our series on building AI agentic patterns from scratch using plain Python…](/aimonks/multi-agent-system-design-patterns-from-scratch-in-python-react-agents-e4480d099f38?source=post_page---read_next_recirc--2a815fe13703----1---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nMay 20\\n\\n[106\\n\\n1](/aimonks/multi-agent-system-design-patterns-from-scratch-in-python-react-agents-e4480d099f38?source=post_page---read_next_recirc--2a815fe13703----1---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nIn\\n\\n[Towards AI](https://medium.com/towards-artificial-intelligence?source=post_page---read_next_recirc--2a815fe13703----0---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nby\\n\\n[GenAI Lab](/@genai-lab?source=post_page---read_next_recirc--2a815fe13703----0---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\n[## LangGraph Introduction: Building Intelligent Workflows with OpenAI\\n\\n### Introduction](/towards-artificial-intelligence/langgraph-introduction-building-intelligent-workflows-with-openai-cf668004130d?source=post_page---read_next_recirc--2a815fe13703----0---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nJul 18\\n\\n[21](/towards-artificial-intelligence/langgraph-introduction-building-intelligent-workflows-with-openai-cf668004130d?source=post_page---read_next_recirc--2a815fe13703----0---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nIn\\n\\n[System Weakness](https://medium.com/system-weakness?source=post_page---read_next_recirc--2a815fe13703----1---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nby\\n\\n[Aditya Bhatt](/@adityabhatt3010?source=post_page---read_next_recirc--2a815fe13703----1---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\n[## BurpSuite Lab: Indirect Prompt Injection 💀🗿\\n\\n### Turned a product review into a silent assassin — Carlos never saw it coming.](/system-weakness/burpsuite-lab-indirect-prompt-injection-ede31eb75bee?source=post_page---read_next_recirc--2a815fe13703----1---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nAug 17\\n\\n[Yashwanth Sai](/@theyashwanthsai?source=post_page---read_next_recirc--2a815fe13703----2---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\n[## The DSPy Playbook: A Humble Introduction\\n\\n### A small part from my upcoming book on AI Agents. I’m building in public and sharing it as we go. Stay tuned!](/@theyashwanthsai/the-dspy-playbook-a-humble-introduction-7c8cedf0c044?source=post_page---read_next_recirc--2a815fe13703----2---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nJul 23\\n\\n[129](/@theyashwanthsai/the-dspy-playbook-a-humble-introduction-7c8cedf0c044?source=post_page---read_next_recirc--2a815fe13703----2---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\n[David Vasquez](/@dvasquez.422?source=post_page---read_next_recirc--2a815fe13703----3---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\n[## Building a Simple AI Agent](/@dvasquez.422/building-a-simple-ai-agent-1e2f2b369b25?source=post_page---read_next_recirc--2a815fe13703----3---------------------eb8471b5_3cec_4ae9_a680_dc979aab30f5--------------)\\n\\nJul 22\\n\\n[See more recommendations](/?source=post_page---read_next_recirc--2a815fe13703---------------------------------------)\\n\\n[Text to speech](https://speechify.com/medium?source=post_page-----2a815fe13703---------------------------------------)\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 아래에 추천드립니다:\n",
      "\n",
      "1. **[LangGraph Studio: A Visual Guide to Building AI Agents](https://www.analyticsvidhya.com/blog/2025/06/langgraph-studio/)**  \n",
      "   이 블로그 포스트는 LangGraph Studio의 기능과 사용법에 대해 자세히 설명하고 있습니다. LangGraph Studio는 AI 에이전트를 시각적으로 설계하고 디버깅할 수 있는 통합 개발 환경(IDE)입니다.\n",
      "\n",
      "2. **[GitHub - langchain-ai/langgraph-studio](https://github.com/langchain-ai/langgraph-studio)**  \n",
      "   LangGraph Studio의 공식 GitHub 저장소로, 설치 방법, 기능 및 사용법에 대한 문서가 포함되어 있습니다. 이곳에서 소스 코드를 확인하고 직접 실습해 볼 수 있습니다.\n",
      "\n",
      "3. **[LangGraph Studio: Empowering AI Agent Development](https://medium.com/@astropomeai/langgraph-studio-empowering-ai-agent-development-2a815fe13703)**  \n",
      "   Medium에서 작성된 이 글은 LangGraph와 LangGraph Studio의 결합이 AI 에이전트 개발에 어떻게 기여하는지를 설명합니다. 주요 기능과 개발 프로세스의 최적화 방법에 대해 다룹니다.\n",
      "\n",
      "이 자료들을 통해 LangGraph의 개념과 LangGraph Studio의 활용 방법을 깊이 있게 이해할 수 있을 것입니다.\n"
     ]
    }
   ],
   "source": [
    "# 그래프 스트림에서 이벤트 수신\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# 각 이벤트에 대한 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "내가 지금까지 배운 내용에 대해서 매우 친절하고 정성스럽게 답변해 주세요. 출처를 반드시 포함해 주세요.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "물론입니다! LangGraph와 LangGraph Studio에 대해 배운 내용을 정리해 드리겠습니다.\n",
      "\n",
      "### LangGraph\n",
      "LangGraph는 AI 에이전트 애플리케이션을 구축하기 위한 강력한 프레임워크입니다. 이 프레임워크는 그래프 구조를 활용하여 복잡한 추론 프로세스와 다단계 의사 결정을 효율적으로 설계하고 구현할 수 있도록 돕습니다. 개발자는 유연하고 재사용 가능한 구성 요소를 만들고 상태 관리를 간소화할 수 있습니다.\n",
      "\n",
      "### LangGraph Studio\n",
      "LangGraph Studio는 LangGraph로 구축된 애플리케이션을 시각화하고 디버깅할 수 있는 통합 개발 환경(IDE)입니다. 이 도구는 애플리케이션 구조를 직관적으로 이해하고 각 처리 단계를 자세히 검사할 수 있는 기능을 제공합니다. 또한, 실행 중 상태를 편집하고 다양한 시나리오를 테스트할 수 있는 기능을 통해 개발 프로세스를 간소화합니다.\n",
      "\n",
      "#### 주요 기능\n",
      "1. **그래프 시각화**: LangGraph로 생성된 애플리케이션의 구조를 시각적으로 표시하여 노드와 엣지 간의 관계를 직관적으로 이해할 수 있습니다.\n",
      "2. **인터랙티브 실행**: 그래프의 각 노드를 개별적으로 실행하고, 다양한 입력과 설정으로 그래프를 실행하여 실시간으로 실행 결과를 확인할 수 있습니다.\n",
      "3. **스레드 관리**: 여러 실행 스레드를 생성하고 관리할 수 있으며, 스레드 간 전환 및 비교가 가능합니다.\n",
      "4. **상태 편집**: 실행 중인 스레드의 상태를 동적으로 편집하고, 편집된 상태에서 새로운 스레드를 포크할 수 있습니다.\n",
      "5. **인간 개입 지원**: 특정 지점에서 수동 입력이나 의사 결정을 요구하는 워크플로우를 지원합니다.\n",
      "6. **LangSmith 통합**: 팀 협업을 촉진하기 위해 LangSmith를 통해 로그인 및 인증을 지원합니다.\n",
      "\n",
      "이러한 기능들은 LangGraph Studio가 AI 에이전트 개발을 보다 효율적으로 만들어 주며, 복잡한 애플리케이션을 쉽게 관리하고 디버깅할 수 있도록 돕습니다.\n",
      "\n",
      "### 출처\n",
      "- [LangGraph Studio: A Visual Guide to Building AI Agents](https://www.analyticsvidhya.com/blog/2025/06/langgraph-studio/)\n",
      "- [GitHub - langchain-ai/langgraph-studio](https://github.com/langchain-ai/langgraph-studio)\n",
      "- [LangGraph Studio: Empowering AI Agent Development](https://medium.com/@astropomeai/langgraph-studio-empowering-ai-agent-development-2a815fe13703)\n",
      "\n",
      "이 정보를 통해 LangGraph와 LangGraph Studio의 개념과 기능을 잘 이해하셨기를 바랍니다! 추가적인 질문이 있으시면 언제든지 말씀해 주세요.\n"
     ]
    }
   ],
   "source": [
    "# 이벤트 스트림 생성\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"user\",\n",
    "            \"내가 지금까지 배운 내용에 대해서 매우 친절하고 정성스럽게 답변해 주세요. 출처를 반드시 포함해 주세요.\",\n",
    "        )\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "# 메시지 이벤트 처리\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "물론입니다! LangGraph와 LangGraph Studio에 대해 배운 내용을 정리해 드리겠습니다.\n",
      "\n",
      "### LangGraph\n",
      "LangGraph는 AI 에이전트 애플리케이션을 구축하기 위한 강력한 프레임워크입니다. 이 프레임워크는 그래프 구조를 활용하여 복잡한 추론 프로세스와 다단계 의사 결정을 효율적으로 설계하고 구현할 수 있도록 돕습니다. 개발자는 유연하고 재사용 가능한 구성 요소를 만들고 상태 관리를 간소화할 수 있습니다.\n",
      "\n",
      "### LangGraph Studio\n",
      "LangGraph Studio는 LangGraph로 구축된 애플리케이션을 시각화하고 디버깅할 수 있는 통합 개발 환경(IDE)입니다. 이 도구는 애플리케이션 구조를 직관적으로 이해하고 각 처리 단계를 자세히 검사할 수 있는 기능을 제공합니다. 또한, 실행 중 상태를 편집하고 다양한 시나리오를 테스트할 수 있는 기능을 통해 개발 프로세스를 간소화합니다.\n",
      "\n",
      "#### 주요 기능\n",
      "1. **그래프 시각화**: LangGraph로 생성된 애플리케이션의 구조를 시각적으로 표시하여 노드와 엣지 간의 관계를 직관적으로 이해할 수 있습니다.\n",
      "2. **인터랙티브 실행**: 그래프의 각 노드를 개별적으로 실행하고, 다양한 입력과 설정으로 그래프를 실행하여 실시간으로 실행 결과를 확인할 수 있습니다.\n",
      "3. **스레드 관리**: 여러 실행 스레드를 생성하고 관리할 수 있으며, 스레드 간 전환 및 비교가 가능합니다.\n",
      "4. **상태 편집**: 실행 중인 스레드의 상태를 동적으로 편집하고, 편집된 상태에서 새로운 스레드를 포크할 수 있습니다.\n",
      "5. **인간 개입 지원**: 특정 지점에서 수동 입력이나 의사 결정을 요구하는 워크플로우를 지원합니다.\n",
      "6. **LangSmith 통합**: 팀 협업을 촉진하기 위해 LangSmith를 통해 로그인 및 인증을 지원합니다.\n",
      "\n",
      "이러한 기능들은 LangGraph Studio가 AI 에이전트 개발을 보다 효율적으로 만들어 주며, 복잡한 애플리케이션을 쉽게 관리하고 디버깅할 수 있도록 돕습니다.\n",
      "\n",
      "### 출처\n",
      "- [LangGraph Studio: A Visual Guide to Building AI Agents](https://www.analyticsvidhya.com/blog/2025/06/langgraph-studio/)\n",
      "- [GitHub - langchain-ai/langgraph-studio](https://github.com/langchain-ai/langgraph-studio)\n",
      "- [LangGraph Studio: Empowering AI Agent Development](https://medium.com/@astropomeai/langgraph-studio-empowering-ai-agent-development-2a815fe13703)\n",
      "\n",
      "이 정보를 통해 LangGraph와 LangGraph Studio의 개념과 기능을 잘 이해하셨기를 바랍니다! 추가적인 질문이 있으시면 언제든지 말씀해 주세요.\n"
     ]
    }
   ],
   "source": [
    "# 최종 응답 \n",
    "# 최종 상태에서 `messages` 의 마지막 메시지로 확인 \n",
    "graph.get_state(config).values[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장된 상태에서 재실행하기 (Replay)\n",
    "\n",
    "- 지난 스냅샷을 확인 후 특정 노드로 되돌아가, State를 수정한 뒤 해당 노드부터 다시 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-e63fa7d0-53b9-4892-b37d-1ea05d24528c-0\n",
      "메시지 수:  6 다음 노드:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "bf751591-ee2b-4024-8cd3-3880e25d5eab\n",
      "메시지 수:  5 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-844f5dfd-77a7-428c-b497-43dd257b1bdd-0\n",
      "메시지 수:  4 다음 노드:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-844f5dfd-77a7-428c-b497-43dd257b1bdd-0\n",
      "메시지 수:  4 다음 노드:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "c1450465-b878-4e00-a20c-31522c8f0f2c\n",
      "메시지 수:  3 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-f5740685-6ec3-4fe6-b3b1-69d4addc253f-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "run-f5740685-6ec3-4fe6-b3b1-69d4addc253f-0\n",
      "메시지 수:  2 다음 노드:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "d215d184-a945-4ba7-aae8-8a1b596402dc\n",
      "메시지 수:  1 다음 노드:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay_state = None\n",
    "\n",
    "# 상태 기록 가져오기\n",
    "for state in graph.get_state_history(config):\n",
    "\n",
    "    messages = state.values[\"messages\"]\n",
    "\n",
    "    if len(messages) > 0:\n",
    "        print(state.values[\"messages\"][-1].id)\n",
    "        # 메시지 수 및 다음 상태 출력\n",
    "        print(\"메시지 수: \", len(state.values[\"messages\"]), \"다음 노드: \", state.next)\n",
    "        print(\"-\" * 80)\n",
    "        # 특정 상태 선택 기준: 채팅 메시지 수\n",
    "        if len(state.values[\"messages\"]) == 2:\n",
    "            # 특정 메시지 ID 선택\n",
    "            to_replay_state = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[93mcontent\u001b[0m: \"\"\n",
      "    \u001b[93madditional_kwargs\u001b[0m:\n",
      "        \u001b[94mtool_calls\u001b[0m:\n",
      "            \u001b[94mindex [0]\u001b[0m\n",
      "                \u001b[92mid\u001b[0m: \"call_cSCwDBfSVuCvWBVkDBdeclfB\"\n",
      "                \u001b[92mfunction\u001b[0m: {\"arguments\": \"{\"query\":\"LangGraph\"}\", \"name\": \"tavily_web_search\"}\n",
      "                \u001b[92mtype\u001b[0m: \"function\"\n",
      "        \u001b[94mrefusal\u001b[0m: None\n",
      "    \u001b[93mresponse_metadata\u001b[0m:\n",
      "        \u001b[94mtoken_usage\u001b[0m:\n",
      "            \u001b[95mcompletion_tokens\u001b[0m: 18\n",
      "            \u001b[95mprompt_tokens\u001b[0m: 110\n",
      "            \u001b[95mtotal_tokens\u001b[0m: 128\n",
      "            \u001b[95mcompletion_tokens_details\u001b[0m: {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}\n",
      "            \u001b[95mprompt_tokens_details\u001b[0m: {\"audio_tokens\": 0, \"cached_tokens\": 0}\n",
      "        \u001b[94mmodel_name\u001b[0m: \"gpt-4o-mini-2024-07-18\"\n",
      "        \u001b[94msystem_fingerprint\u001b[0m: \"fp_560af6e559\"\n",
      "        \u001b[94mfinish_reason\u001b[0m: \"tool_calls\"\n",
      "        \u001b[94mlogprobs\u001b[0m: None\n",
      "    \u001b[93mtype\u001b[0m: \"ai\"\n",
      "    \u001b[93mname\u001b[0m: None\n",
      "    \u001b[93mid\u001b[0m: \"run-f5740685-6ec3-4fe6-b3b1-69d4addc253f-0\"\n",
      "    \u001b[93mexample\u001b[0m: False\n",
      "    \u001b[93mtool_calls\u001b[0m:\n",
      "        \u001b[93mindex [0]\u001b[0m\n",
      "            \u001b[95mname\u001b[0m: \"tavily_web_search\"\n",
      "            \u001b[95margs\u001b[0m: {\"query\": \"LangGraph\"}\n",
      "            \u001b[95mid\u001b[0m: \"call_cSCwDBfSVuCvWBVkDBdeclfB\"\n",
      "            \u001b[95mtype\u001b[0m: \"tool_call\"\n",
      "    \u001b[93minvalid_tool_calls\u001b[0m:\n",
      "    \u001b[93musage_metadata\u001b[0m: {\"input_tokens\": 110, \"output_tokens\": 18, \"total_tokens\": 128}\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "# 선택한 메시지 가져오기\n",
    "existing_message = to_replay_state.values[\"messages\"][-1]\n",
    "\n",
    "# 메시지 트리 출력\n",
    "display_message_tree(existing_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_web_search',\n",
       " 'args': {'query': 'LangGraph human-in-the-loop workflow site:reddit.com'},\n",
       " 'id': 'call_cSCwDBfSVuCvWBVkDBdeclfB',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검색 쿼리 업데이트 \n",
    "tool_call = existing_message.tool_calls[0].copy()\n",
    "tool_call[\"args\"] = {\"query\": \"LangGraph human-in-the-loop workflow site:reddit.com\"}\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'LangGraph human-in-the-loop workflow site:reddit.com'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트된 AIMessage 생성\n",
    "new_message = AIMessage(\n",
    "    content=existing_message.content,\n",
    "    tool_calls=[tool_call],\n",
    "    id=existing_message.id,\n",
    ")\n",
    "\n",
    "# 수정한 메시지 출력\n",
    "new_message.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_web_search',\n",
       "  'args': {'query': 'LangGraph'},\n",
       "  'id': 'call_cSCwDBfSVuCvWBVkDBdeclfB',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 업데이트 전 메시지 확인\n",
    "graph.get_state(to_replay_state.config).values[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '74a3a6',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f09dc11-1d38-69fe-8002-86edf2ad82b0'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상태 업데이트\n",
    "updated_state = graph.update_state(\n",
    "    to_replay_state.config,\n",
    "    {\"messages\": [new_message]},\n",
    ")\n",
    "updated_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_cSCwDBfSVuCvWBVkDBdeclfB)\n",
      " Call ID: call_cSCwDBfSVuCvWBVkDBdeclfB\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow site:reddit.com\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"url\": \"https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/\", \"title\": \"LangGraph's human-in-the-loop - Overview\", \"content\": \"* Key capabilities * Patterns hil human-in-the-loop overview   # Human-in-the-loop¶ ## Key capabilities¶ This supports asynchronous human review or input without time constraints. * **Flexible integration points**: Human-in-the-loop logic can be introduced at any point in the workflow. This allows targeted human involvement, such as approving API calls, correcting outputs, or guiding conversations. This pattern often involves routing the graph based on the human's input. * Edit graph state: Pause the graph to review and edit the graph state. This is useful for correcting mistakes or updating the state with additional information. This pattern often involves updating the state with the human's input. * Validate human input: Pause the graph to validate human input before proceeding with the next step.\", \"score\": 0.9073207, \"raw_content\": \"[Skip to content](#human-in-the-loop)\\n\\n\\n\\n* [Key capabilities](#key-capabilities)\\n* [Patterns](#patterns)\\n\\nhil human-in-the-loop overview  \\n\\n# Human-in-the-loop[¶](#human-in-the-loop \\\"Permanent link\\\")\\n\\nTo review, edit, and approve tool calls in an agent or workflow, [use LangGraph's human-in-the-loop features](../../how-tos/human_in_the_loop/add-human-in-the-loop/) to enable human intervention at any point in a workflow. This is especially useful in large language model (LLM)-driven applications where model output may require validation, correction, or additional context.\\n\\nTip\\n\\nFor information on how to use human-in-the-loop, see [Enable human intervention](../../how-tos/human_in_the_loop/add-human-in-the-loop/) and [Human-in-the-loop using Server API](../../cloud/how-tos/add-human-in-the-loop/).\\n\\n## Key capabilities[¶](#key-capabilities \\\"Permanent link\\\")\\n\\n* **Persistent execution state**: Interrupts use LangGraph's [persistence](../persistence/) layer, which saves the graph state, to indefinitely pause graph execution until you resume. This is possible because LangGraph checkpoints the graph state after each step, which allows the system to persist execution context and later resume the workflow, continuing from where it left off. This supports asynchronous human review or input without time constraints.\\n\\n  There are two ways to pause a graph:\\n\\n  + [Dynamic interrupts](../../how-tos/human_in_the_loop/add-human-in-the-loop/#pause-using-interrupt): Use `interrupt` to pause a graph from inside a specific node, based on the current state of the graph.\\n  + [Static interrupts](../../how-tos/human_in_the_loop/add-human-in-the-loop/#debug-with-interrupts): Use `interrupt_before` and `interrupt_after` to pause the graph at pre-defined points, either before or after a node executes.\\n* **Flexible integration points**: Human-in-the-loop logic can be introduced at any point in the workflow. This allows targeted human involvement, such as approving API calls, correcting outputs, or guiding conversations.\\n\\n## Patterns[¶](#patterns \\\"Permanent link\\\")\\n\\nThere are four typical design patterns that you can implement using `interrupt` and `Command`:\\n\\n* [Approve or reject](../../how-tos/human_in_the_loop/add-human-in-the-loop/#approve-or-reject): Pause the graph before a critical step, such as an API call, to review and approve the action. If the action is rejected, you can prevent the graph from executing the step, and potentially take an alternative action. This pattern often involves routing the graph based on the human's input.\\n* [Edit graph state](../../how-tos/human_in_the_loop/add-human-in-the-loop/#review-and-edit-state): Pause the graph to review and edit the graph state. This is useful for correcting mistakes or updating the state with additional information. This pattern often involves updating the state with the human's input.\\n* [Review tool calls](../../how-tos/human_in_the_loop/add-human-in-the-loop/#review-tool-calls): Pause the graph to review and edit tool calls requested by the LLM before tool execution.\\n* [Validate human input](../../how-tos/human_in_the_loop/add-human-in-the-loop/#validate-human-input): Pause the graph to validate human input before proceeding with the next step.\\n\\n \"}, {\"url\": \"https://www.reddit.com/r/LangGraph/comments/1ldiqtg/i_am_struggling_with_langgraphs_humanintheloop/\", \"title\": \"I am Struggling with LangGraph's Human-in-the-Loop ... - Reddit\", \"content\": \"I am Struggling with LangGraph’s Human-in-the-Loop. : r/LangGraph Skip to main contentI am Struggling with LangGraph’s Human-in-the-Loop. : r/LangGraph Open menu Open navigationGo to Reddit Home r/LangGraph A chip A close button Image 1: r/LangGraph icon Go to LangGraph r/LangGraph Image 2: r/LangGraph iconr/LangGraph LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. The documentation can be found at https://langchain-ai.github.io/langgraph/ I am Struggling with LangGraph’s Human-in-the-Loop. I’ve tried using LangGraph’s interrupt() and the HIL patterns, but I keep running into issues: Has anyone here managed to get a robust, production-ready HIL workflow with LangGraph? Examples of Human-in-the-Loop in LangGraph Innovative uses for LangGraph in AI projects New to Reddit?\", \"score\": 0.8727061, \"raw_content\": \"I am Struggling with LangGraph’s Human-in-the-Loop. Anyone Managed Reliable Approval Workflows? : r/LangGraph\\n\\n===============\\n[Skip to main content](https://www.reddit.com/r/LangGraph/comments/1ldiqtg/i_am_struggling_with_langgraphs_humanintheloop/#main-content)I am Struggling with LangGraph’s Human-in-the-Loop. Anyone Managed Reliable Approval Workflows? : r/LangGraph\\n\\nOpen menu Open navigation[](https://www.reddit.com/)Go to Reddit Home\\n\\nr/LangGraph A chip A close button\\n\\n[Log In](https://www.reddit.com/login/)Log in to Reddit\\n\\nExpand user menu Open settings menu\\n\\n[![Image 1: r/LangGraph icon](https://styles.redditmedia.com/t5_chievx/styles/communityIcon_xw7nx20lekpd1.jpeg?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=019a4fabe250c6b04671f35836b80f199b2ec051) Go to LangGraph](https://www.reddit.com/r/LangGraph/)\\n\\n[r/LangGraph](https://www.reddit.com/r/LangGraph/)\\n\\n![Image 2: r/LangGraph icon](https://styles.redditmedia.com/t5_chievx/styles/communityIcon_xw7nx20lekpd1.jpeg?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=019a4fabe250c6b04671f35836b80f199b2ec051)[r/LangGraph](https://www.reddit.com/r/LangGraph/)\\n\\nLangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. The documentation can be found at https://langchain-ai.github.io/langgraph/\\n\\n* * *\\n\\n2.4K Members Online\\n\\n•3 mo. ago\\n\\n[techblooded](https://www.reddit.com/user/techblooded/)\\n\\nI am Struggling with LangGraph’s Human-in-the-Loop. Anyone Managed Reliable Approval Workflows?\\n===============================================================================================\\n\\nI’m building an agent that needs to pause for human approval before executing sensitive actions (like sending emails or making API calls). I’ve tried using LangGraph’s interrupt() and the HIL patterns, but I keep running into issues:\\n\\n-The graph sometimes resumes from the wrong point\\n\\n-State updates after resuming are inconsistent.\\n\\n-The API for handling interruptions is confusing and poorly documented\\n\\nHas anyone here managed to get a robust, production-ready HIL workflow with LangGraph? Any best practices or workarounds for these pain points? Would love to see code snippets or architecture diagrams if you’re willing to share!\\n\\n Read more \\n\\n Share \\n\\nRelated Answers Section\\n=======================\\n\\n Related Answers \\n\\n[LangGraph interrupt() usage tips](https://www.reddit.com/answers/15c3829c-f404-4d53-9492-2dd27dd33588/?q=LangGraph%20interrupt()%20usage%20tips&source=PDP)\\n\\n[Examples of Human-in-the-Loop in LangGraph](https://www.reddit.com/answers/497c5c4c-7bd9-4204-8b7f-8dc266fe01ac/?q=Examples%20of%20Human-in-the-Loop%20in%20LangGraph&source=PDP)\\n\\n[Innovative uses for LangGraph in AI projects](https://www.reddit.com/answers/928f8929-371b-4aae-a9ba-3b4501232945/?q=Innovative%20uses%20for%20LangGraph%20in%20AI%20projects&source=PDP)\\n\\n[Best practices for multi-agent workflows](https://www.reddit.com/answers/3731a305-3715-45b2-922f-aed150d990a4/?q=Best%20practices%20for%20multi-agent%20workflows&source=PDP)\\n\\n[Challenges in building stateful applications](https://www.reddit.com/answers/a27b4d10-d552-40ab-808d-0896d0ccddc3/?q=Challenges%20in%20building%20stateful%20applications&source=PDP)\\n\\nNew to Reddit? \\nCreate your account and connect with a world of communities.\\n\\n Continue with Email \\n\\n Continue With Phone Number \\n\\nBy continuing, you agree to our[User Agreement](https://www.redditinc.com/policies/user-agreement)and acknowledge that you understand the[Privacy Policy](https://www.redditinc.com/policies/privacy-policy). \\n\\n Public \\n\\nAnyone can view, post, and comment to this community\\n\\n0 0\\n\\n[Reddit Rules](https://www.redditinc.com/policies/content-policy)[Privacy Policy](https://www.reddit.com/policies/privacy-policy)[User Agreement](https://www.redditinc.com/policies/user-agreement)[Accessibility](https://support.reddithelp.com/hc/sections/38303584022676-Accessibility)[Reddit, Inc. © 2025. All rights reserved.](https://redditinc.com/)\\n\\nExpand Navigation Collapse Navigation\\n\\n![Image 3](https://id.rlcdn.com/472486.gif)\"}, {\"url\": \"https://blog.langchain.com/making-it-easier-to-build-human-in-the-loop-agents-with-interrupt/\", \"title\": \"Making it easier to build human-in-the-loop agents with interrupt\", \"content\": \"# Making it easier to build human-in-the-loop agents with interrupt Today, we’re excited to announce a new method to more easily include human-in-the-loop steps in your LangGraph agents: `interrupt` ## How we built LangGraph for human-in-the-loop workflows ## `interrupt`: a new developer experience for human-in-the-loop We’ve had a few ways of building human in the loop interactions before (breakpoints, NodeInterrupt). When building human-in-the-loop into Python programs, one common way to do this is with the `input` function. A human can review and edit the state of the graph. We are building LangGraph to be the best agent framework for human-in-the-loop interaction patterns. We’ve updated all of our examples that use human-in-the-loop to use this new functionality.\", \"score\": 0.84183896, \"raw_content\": \"[Skip to content](#main)\\n\\n# Making it easier to build human-in-the-loop agents with interrupt\\n\\nWhile agents can be powerful, they are not perfect. This often makes it important to keep the human “in the loop” when building agents. For example, in our [fireside chat](https://www.youtube.com/watch?v=ViykMqljjxU&ref=blog.langchain.com) we did with Michele Catasta (President of Replit) on their Replit Agent, he speaks several times about the human-in-the-loop component being crucial to their agent design.\\n\\nFrom the start, we designed LangGraph with this in mind, and it’s one of the key reasons [many](https://blog.langchain.com/customers-rexera/) [companies](https://blog.langchain.com/customers-openrecovery/) [choose](https://blog.langchain.com/customers-replit/) [to build](https://blog.langchain.com/customers-tradestack/) on LangGraph. Today, we’re excited to announce a new method to more easily include human-in-the-loop steps in your LangGraph agents: `interrupt`\\n\\n## How we built LangGraph for human-in-the-loop workflows\\n\\nOne of the differentiating aspects of LangGraph is that we built it for human-in-the-loop workflows. We think these workflows are incredibly important when building agents, and so we built in first class support for them in LangGraph.\\n\\nWe did this by making [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/?ref=blog.langchain.com) a first class citizen in LangGraph. Every step of the graph, it reads from and then writes to a checkpoint of that graph state. That graph state stores everything the agent needs to do its work.\\n\\nThis makes it possible to pause execution of the graph half way through, and then resume after some time - because that checkpoint is there, and we can just pick right back up from there.\\n\\nIt also makes it possible to pause, let the human edit the checkpoint, and then resume from that new updated checkpoint.\\n\\nIn some ways, you can think of this persistence layer as a scratchpad for human/agent collaboration.\\n\\n## `interrupt`: a new developer experience for human-in-the-loop\\n\\nWe’ve had a few ways of building human in the loop interactions before (breakpoints, NodeInterrupt). Over the past few months, we’ve seen developers want to do more and more complicated things, and so we’ve added a new tool to help with this.\\n\\nWhen building human-in-the-loop into Python programs, one common way to do this is with [the `input` function](https://www.w3schools.com/python/ref_func_input.asp?ref=blog.langchain.com). With this, your program pauses, a text box pops up in your terminal, and whatever you type is then used as the response to that function. You use it like the below:\\n\\n```\\nresponse = input(\\\"Your question here\\\")\\n\\n```\\n\\nThat is a pretty easy and intuitive way to add human-in-the-loop functionality. The downside to this is that it is synchronous and blocks the process and doesn’t really work outside the command line (or notebooks). So this won’t work in production at all.\\n\\nWe’ve tried to emulate this developer experience by adding a new function to LangGraph: `interrupt`. You can use this in much the same way as `input`:\\n\\n```\\nresponse = interrupt(\\\"Your question here\\\")\\n\\n```\\n\\nThis is designed to work in production settings. When you do this, it will pause execution of the graph, mark the thread you are running as `interrupted`, and put whatever you passed as an input to `interrupt` into the persistence layer. This way, you can check the thread status, see that it’s interrupted, check the message, and then based on that invoke the graph again (in a special way) to pass your response back in:\\n\\n```\\ngraph.invoke(Command(resume=\\\"Your response here\\\"), thread)\\n\\n```\\n\\nNote that it doesn’t function exactly the same as `input` (it reruns any work in that node done before this is called, but no previous nodes). This ensures interrupted threads don’t take up any resources (beyond storage space), and can be resumed many months later, on a different machine, etc.\\n\\nFor more information, see the [Python](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/?ref=blog.langchain.com) and [Javascript](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/?ref=blog.langchain.com) documentation.\\n\\n## Common human-in-the-loop workflows\\n\\nThere are a few different human-in-the-loop workflows that we see being implemented.\\n\\n[**Approve or Reject**](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/review-tool-calls/?ref=blog.langchain.com)\\n\\nPause the graph before a critical step, such as an API call, to review and approve the action. If the action is rejected, you can prevent the graph from executing the step, and potentially take an alternative action.\\n\\n[**Review & Edit State**](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/?ref=blog.langchain.com)\\n\\nA human can review and edit the state of the graph. This is useful for correcting mistakes or updating the state with additional information.\\n\\n[**Review Tool Calls**](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/review-tool-calls/?ref=blog.langchain.com)\\n\\nA human can review and edit the output from the LLM before proceeding. This is particularly critical in applications where the tool calls requested by the LLM may be sensitive or require human oversight.\\n\\n[**Multi-turn conversation in a multi-agent setup**](https://langchain-ai.github.io/langgraph/how-tos/multi-agent-multi-turn-convo/?ref=blog.langchain.com)\\n\\nA **multi-turn conversation** involves multiple back-and-forth interactions between an agent and a human, which can allow the agent to gather additional information from the human in a conversational manner.\\n\\nThis design pattern is useful in an LLM application consisting of [multiple agents](https://langchain-ai.github.io/langgraph/concepts/multi_agent/?ref=blog.langchain.com). One or more agents may need to carry out multi-turn conversations with a human, where the human provides input or feedback at different stages of the conversation. For simplicity, the agent implementation below is illustrated as a single node, but in reality it may be part of a larger graph consisting of multiple nodes and include a conditional edge.\\n\\n## Conclusion\\n\\nWe are building LangGraph to be the best agent framework for human-in-the-loop interaction patterns. We think `interrupt` makes this easier than ever. We’ve updated all of our examples that use human-in-the-loop to use this new functionality. We hope to release some more end-to-end projects that demonstrate this in real-world action soon.\\n\\nSee our [YouTube walkthrough](https://youtu.be/6t7YJcEFUIY?ref=blog.langchain.com) for more information\\n\\nWe’re excited to see what you build!\\n\\n### Join our newsletter\\n\\nUpdates from the LangChain team and community\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 아래에 정리했습니다. 이 자료들은 LangGraph의 기능과 사용법, 특히 \"Human-in-the-Loop\" 워크플로우에 대한 내용을 포함하고 있습니다.\n",
      "\n",
      "1. **LangGraph의 Human-in-the-Loop 개요**  \n",
      "   [LangGraph's human-in-the-loop - Overview](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)  \n",
      "   이 문서에서는 LangGraph의 Human-in-the-Loop 기능에 대해 설명하고 있습니다. 비동기적인 인간 검토 및 입력을 지원하며, 워크플로우의 어느 지점에서든 인간의 개입을 유연하게 통합할 수 있는 방법을 다룹니다.\n",
      "\n",
      "2. **Reddit 토론**  \n",
      "   [I am Struggling with LangGraph's Human-in-the-Loop ... - Reddit](https://www.reddit.com/r/LangGraph/comments/1ldiqtg/i_am_struggling_with_langgraphs_humanintheloop/)  \n",
      "   이 Reddit 스레드는 LangGraph의 Human-in-the-Loop 기능을 사용하면서 겪는 문제에 대한 사용자들의 경험과 조언을 공유합니다. 실제 사용 사례와 문제 해결 방법을 찾는 데 유용할 수 있습니다.\n",
      "\n",
      "3. **Human-in-the-Loop 에이전트 구축을 위한 새로운 방법**  \n",
      "   [Making it easier to build human-in-the-loop agents with interrupt](https://blog.langchain.com/making-it-easier-to-build-human-in-the-loop-agents-with-interrupt/)  \n",
      "   이 블로그 포스트에서는 LangGraph에서 Human-in-the-Loop 단계를 더 쉽게 포함할 수 있는 새로운 방법인 `interrupt` 기능에 대해 설명합니다. 이 기능을 통해 개발자는 에이전트의 실행을 일시 중지하고 인간의 입력을 받을 수 있습니다.\n",
      "\n",
      "이 자료들을 통해 LangGraph의 기능과 Human-in-the-Loop 워크플로우에 대한 이해를 높일 수 있을 것입니다. 추가적인 질문이 있으면 언제든지 물어보세요!\n"
     ]
    }
   ],
   "source": [
    "# config에 updated_state 전달\n",
    "for event in graph.stream(None, updated_state, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LangGraph 에 대해서 배워보고 싶습니다. 유용한 자료를 추천해 주세요!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_web_search (call_cSCwDBfSVuCvWBVkDBdeclfB)\n",
      " Call ID: call_cSCwDBfSVuCvWBVkDBdeclfB\n",
      "  Args:\n",
      "    query: LangGraph human-in-the-loop workflow site:reddit.com\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_web_search\n",
      "\n",
      "[{\"url\": \"https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/\", \"title\": \"LangGraph's human-in-the-loop - Overview\", \"content\": \"* Key capabilities * Patterns hil human-in-the-loop overview   # Human-in-the-loop¶ ## Key capabilities¶ This supports asynchronous human review or input without time constraints. * **Flexible integration points**: Human-in-the-loop logic can be introduced at any point in the workflow. This allows targeted human involvement, such as approving API calls, correcting outputs, or guiding conversations. This pattern often involves routing the graph based on the human's input. * Edit graph state: Pause the graph to review and edit the graph state. This is useful for correcting mistakes or updating the state with additional information. This pattern often involves updating the state with the human's input. * Validate human input: Pause the graph to validate human input before proceeding with the next step.\", \"score\": 0.9073207, \"raw_content\": \"[Skip to content](#human-in-the-loop)\\n\\n\\n\\n* [Key capabilities](#key-capabilities)\\n* [Patterns](#patterns)\\n\\nhil human-in-the-loop overview  \\n\\n# Human-in-the-loop[¶](#human-in-the-loop \\\"Permanent link\\\")\\n\\nTo review, edit, and approve tool calls in an agent or workflow, [use LangGraph's human-in-the-loop features](../../how-tos/human_in_the_loop/add-human-in-the-loop/) to enable human intervention at any point in a workflow. This is especially useful in large language model (LLM)-driven applications where model output may require validation, correction, or additional context.\\n\\nTip\\n\\nFor information on how to use human-in-the-loop, see [Enable human intervention](../../how-tos/human_in_the_loop/add-human-in-the-loop/) and [Human-in-the-loop using Server API](../../cloud/how-tos/add-human-in-the-loop/).\\n\\n## Key capabilities[¶](#key-capabilities \\\"Permanent link\\\")\\n\\n* **Persistent execution state**: Interrupts use LangGraph's [persistence](../persistence/) layer, which saves the graph state, to indefinitely pause graph execution until you resume. This is possible because LangGraph checkpoints the graph state after each step, which allows the system to persist execution context and later resume the workflow, continuing from where it left off. This supports asynchronous human review or input without time constraints.\\n\\n  There are two ways to pause a graph:\\n\\n  + [Dynamic interrupts](../../how-tos/human_in_the_loop/add-human-in-the-loop/#pause-using-interrupt): Use `interrupt` to pause a graph from inside a specific node, based on the current state of the graph.\\n  + [Static interrupts](../../how-tos/human_in_the_loop/add-human-in-the-loop/#debug-with-interrupts): Use `interrupt_before` and `interrupt_after` to pause the graph at pre-defined points, either before or after a node executes.\\n* **Flexible integration points**: Human-in-the-loop logic can be introduced at any point in the workflow. This allows targeted human involvement, such as approving API calls, correcting outputs, or guiding conversations.\\n\\n## Patterns[¶](#patterns \\\"Permanent link\\\")\\n\\nThere are four typical design patterns that you can implement using `interrupt` and `Command`:\\n\\n* [Approve or reject](../../how-tos/human_in_the_loop/add-human-in-the-loop/#approve-or-reject): Pause the graph before a critical step, such as an API call, to review and approve the action. If the action is rejected, you can prevent the graph from executing the step, and potentially take an alternative action. This pattern often involves routing the graph based on the human's input.\\n* [Edit graph state](../../how-tos/human_in_the_loop/add-human-in-the-loop/#review-and-edit-state): Pause the graph to review and edit the graph state. This is useful for correcting mistakes or updating the state with additional information. This pattern often involves updating the state with the human's input.\\n* [Review tool calls](../../how-tos/human_in_the_loop/add-human-in-the-loop/#review-tool-calls): Pause the graph to review and edit tool calls requested by the LLM before tool execution.\\n* [Validate human input](../../how-tos/human_in_the_loop/add-human-in-the-loop/#validate-human-input): Pause the graph to validate human input before proceeding with the next step.\\n\\n \"}, {\"url\": \"https://www.reddit.com/r/LangGraph/comments/1ldiqtg/i_am_struggling_with_langgraphs_humanintheloop/\", \"title\": \"I am Struggling with LangGraph's Human-in-the-Loop ... - Reddit\", \"content\": \"I am Struggling with LangGraph’s Human-in-the-Loop. : r/LangGraph Skip to main contentI am Struggling with LangGraph’s Human-in-the-Loop. : r/LangGraph Open menu Open navigationGo to Reddit Home r/LangGraph A chip A close button Image 1: r/LangGraph icon Go to LangGraph r/LangGraph Image 2: r/LangGraph iconr/LangGraph LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. The documentation can be found at https://langchain-ai.github.io/langgraph/ I am Struggling with LangGraph’s Human-in-the-Loop. I’ve tried using LangGraph’s interrupt() and the HIL patterns, but I keep running into issues: Has anyone here managed to get a robust, production-ready HIL workflow with LangGraph? Examples of Human-in-the-Loop in LangGraph Innovative uses for LangGraph in AI projects New to Reddit?\", \"score\": 0.8727061, \"raw_content\": \"I am Struggling with LangGraph’s Human-in-the-Loop. Anyone Managed Reliable Approval Workflows? : r/LangGraph\\n\\n===============\\n[Skip to main content](https://www.reddit.com/r/LangGraph/comments/1ldiqtg/i_am_struggling_with_langgraphs_humanintheloop/#main-content)I am Struggling with LangGraph’s Human-in-the-Loop. Anyone Managed Reliable Approval Workflows? : r/LangGraph\\n\\nOpen menu Open navigation[](https://www.reddit.com/)Go to Reddit Home\\n\\nr/LangGraph A chip A close button\\n\\n[Log In](https://www.reddit.com/login/)Log in to Reddit\\n\\nExpand user menu Open settings menu\\n\\n[![Image 1: r/LangGraph icon](https://styles.redditmedia.com/t5_chievx/styles/communityIcon_xw7nx20lekpd1.jpeg?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=019a4fabe250c6b04671f35836b80f199b2ec051) Go to LangGraph](https://www.reddit.com/r/LangGraph/)\\n\\n[r/LangGraph](https://www.reddit.com/r/LangGraph/)\\n\\n![Image 2: r/LangGraph icon](https://styles.redditmedia.com/t5_chievx/styles/communityIcon_xw7nx20lekpd1.jpeg?width=96&height=96&frame=1&auto=webp&crop=96%3A96%2Csmart&s=019a4fabe250c6b04671f35836b80f199b2ec051)[r/LangGraph](https://www.reddit.com/r/LangGraph/)\\n\\nLangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. The documentation can be found at https://langchain-ai.github.io/langgraph/\\n\\n* * *\\n\\n2.4K Members Online\\n\\n•3 mo. ago\\n\\n[techblooded](https://www.reddit.com/user/techblooded/)\\n\\nI am Struggling with LangGraph’s Human-in-the-Loop. Anyone Managed Reliable Approval Workflows?\\n===============================================================================================\\n\\nI’m building an agent that needs to pause for human approval before executing sensitive actions (like sending emails or making API calls). I’ve tried using LangGraph’s interrupt() and the HIL patterns, but I keep running into issues:\\n\\n-The graph sometimes resumes from the wrong point\\n\\n-State updates after resuming are inconsistent.\\n\\n-The API for handling interruptions is confusing and poorly documented\\n\\nHas anyone here managed to get a robust, production-ready HIL workflow with LangGraph? Any best practices or workarounds for these pain points? Would love to see code snippets or architecture diagrams if you’re willing to share!\\n\\n Read more \\n\\n Share \\n\\nRelated Answers Section\\n=======================\\n\\n Related Answers \\n\\n[LangGraph interrupt() usage tips](https://www.reddit.com/answers/15c3829c-f404-4d53-9492-2dd27dd33588/?q=LangGraph%20interrupt()%20usage%20tips&source=PDP)\\n\\n[Examples of Human-in-the-Loop in LangGraph](https://www.reddit.com/answers/497c5c4c-7bd9-4204-8b7f-8dc266fe01ac/?q=Examples%20of%20Human-in-the-Loop%20in%20LangGraph&source=PDP)\\n\\n[Innovative uses for LangGraph in AI projects](https://www.reddit.com/answers/928f8929-371b-4aae-a9ba-3b4501232945/?q=Innovative%20uses%20for%20LangGraph%20in%20AI%20projects&source=PDP)\\n\\n[Best practices for multi-agent workflows](https://www.reddit.com/answers/3731a305-3715-45b2-922f-aed150d990a4/?q=Best%20practices%20for%20multi-agent%20workflows&source=PDP)\\n\\n[Challenges in building stateful applications](https://www.reddit.com/answers/a27b4d10-d552-40ab-808d-0896d0ccddc3/?q=Challenges%20in%20building%20stateful%20applications&source=PDP)\\n\\nNew to Reddit? \\nCreate your account and connect with a world of communities.\\n\\n Continue with Email \\n\\n Continue With Phone Number \\n\\nBy continuing, you agree to our[User Agreement](https://www.redditinc.com/policies/user-agreement)and acknowledge that you understand the[Privacy Policy](https://www.redditinc.com/policies/privacy-policy). \\n\\n Public \\n\\nAnyone can view, post, and comment to this community\\n\\n0 0\\n\\n[Reddit Rules](https://www.redditinc.com/policies/content-policy)[Privacy Policy](https://www.reddit.com/policies/privacy-policy)[User Agreement](https://www.redditinc.com/policies/user-agreement)[Accessibility](https://support.reddithelp.com/hc/sections/38303584022676-Accessibility)[Reddit, Inc. © 2025. All rights reserved.](https://redditinc.com/)\\n\\nExpand Navigation Collapse Navigation\\n\\n![Image 3](https://id.rlcdn.com/472486.gif)\"}, {\"url\": \"https://blog.langchain.com/making-it-easier-to-build-human-in-the-loop-agents-with-interrupt/\", \"title\": \"Making it easier to build human-in-the-loop agents with interrupt\", \"content\": \"# Making it easier to build human-in-the-loop agents with interrupt Today, we’re excited to announce a new method to more easily include human-in-the-loop steps in your LangGraph agents: `interrupt` ## How we built LangGraph for human-in-the-loop workflows ## `interrupt`: a new developer experience for human-in-the-loop We’ve had a few ways of building human in the loop interactions before (breakpoints, NodeInterrupt). When building human-in-the-loop into Python programs, one common way to do this is with the `input` function. A human can review and edit the state of the graph. We are building LangGraph to be the best agent framework for human-in-the-loop interaction patterns. We’ve updated all of our examples that use human-in-the-loop to use this new functionality.\", \"score\": 0.84183896, \"raw_content\": \"[Skip to content](#main)\\n\\n# Making it easier to build human-in-the-loop agents with interrupt\\n\\nWhile agents can be powerful, they are not perfect. This often makes it important to keep the human “in the loop” when building agents. For example, in our [fireside chat](https://www.youtube.com/watch?v=ViykMqljjxU&ref=blog.langchain.com) we did with Michele Catasta (President of Replit) on their Replit Agent, he speaks several times about the human-in-the-loop component being crucial to their agent design.\\n\\nFrom the start, we designed LangGraph with this in mind, and it’s one of the key reasons [many](https://blog.langchain.com/customers-rexera/) [companies](https://blog.langchain.com/customers-openrecovery/) [choose](https://blog.langchain.com/customers-replit/) [to build](https://blog.langchain.com/customers-tradestack/) on LangGraph. Today, we’re excited to announce a new method to more easily include human-in-the-loop steps in your LangGraph agents: `interrupt`\\n\\n## How we built LangGraph for human-in-the-loop workflows\\n\\nOne of the differentiating aspects of LangGraph is that we built it for human-in-the-loop workflows. We think these workflows are incredibly important when building agents, and so we built in first class support for them in LangGraph.\\n\\nWe did this by making [persistence](https://langchain-ai.github.io/langgraph/concepts/persistence/?ref=blog.langchain.com) a first class citizen in LangGraph. Every step of the graph, it reads from and then writes to a checkpoint of that graph state. That graph state stores everything the agent needs to do its work.\\n\\nThis makes it possible to pause execution of the graph half way through, and then resume after some time - because that checkpoint is there, and we can just pick right back up from there.\\n\\nIt also makes it possible to pause, let the human edit the checkpoint, and then resume from that new updated checkpoint.\\n\\nIn some ways, you can think of this persistence layer as a scratchpad for human/agent collaboration.\\n\\n## `interrupt`: a new developer experience for human-in-the-loop\\n\\nWe’ve had a few ways of building human in the loop interactions before (breakpoints, NodeInterrupt). Over the past few months, we’ve seen developers want to do more and more complicated things, and so we’ve added a new tool to help with this.\\n\\nWhen building human-in-the-loop into Python programs, one common way to do this is with [the `input` function](https://www.w3schools.com/python/ref_func_input.asp?ref=blog.langchain.com). With this, your program pauses, a text box pops up in your terminal, and whatever you type is then used as the response to that function. You use it like the below:\\n\\n```\\nresponse = input(\\\"Your question here\\\")\\n\\n```\\n\\nThat is a pretty easy and intuitive way to add human-in-the-loop functionality. The downside to this is that it is synchronous and blocks the process and doesn’t really work outside the command line (or notebooks). So this won’t work in production at all.\\n\\nWe’ve tried to emulate this developer experience by adding a new function to LangGraph: `interrupt`. You can use this in much the same way as `input`:\\n\\n```\\nresponse = interrupt(\\\"Your question here\\\")\\n\\n```\\n\\nThis is designed to work in production settings. When you do this, it will pause execution of the graph, mark the thread you are running as `interrupted`, and put whatever you passed as an input to `interrupt` into the persistence layer. This way, you can check the thread status, see that it’s interrupted, check the message, and then based on that invoke the graph again (in a special way) to pass your response back in:\\n\\n```\\ngraph.invoke(Command(resume=\\\"Your response here\\\"), thread)\\n\\n```\\n\\nNote that it doesn’t function exactly the same as `input` (it reruns any work in that node done before this is called, but no previous nodes). This ensures interrupted threads don’t take up any resources (beyond storage space), and can be resumed many months later, on a different machine, etc.\\n\\nFor more information, see the [Python](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/?ref=blog.langchain.com) and [Javascript](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/?ref=blog.langchain.com) documentation.\\n\\n## Common human-in-the-loop workflows\\n\\nThere are a few different human-in-the-loop workflows that we see being implemented.\\n\\n[**Approve or Reject**](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/review-tool-calls/?ref=blog.langchain.com)\\n\\nPause the graph before a critical step, such as an API call, to review and approve the action. If the action is rejected, you can prevent the graph from executing the step, and potentially take an alternative action.\\n\\n[**Review & Edit State**](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/wait-user-input/?ref=blog.langchain.com)\\n\\nA human can review and edit the state of the graph. This is useful for correcting mistakes or updating the state with additional information.\\n\\n[**Review Tool Calls**](https://langchain-ai.github.io/langgraph/how-tos/human_in_the_loop/review-tool-calls/?ref=blog.langchain.com)\\n\\nA human can review and edit the output from the LLM before proceeding. This is particularly critical in applications where the tool calls requested by the LLM may be sensitive or require human oversight.\\n\\n[**Multi-turn conversation in a multi-agent setup**](https://langchain-ai.github.io/langgraph/how-tos/multi-agent-multi-turn-convo/?ref=blog.langchain.com)\\n\\nA **multi-turn conversation** involves multiple back-and-forth interactions between an agent and a human, which can allow the agent to gather additional information from the human in a conversational manner.\\n\\nThis design pattern is useful in an LLM application consisting of [multiple agents](https://langchain-ai.github.io/langgraph/concepts/multi_agent/?ref=blog.langchain.com). One or more agents may need to carry out multi-turn conversations with a human, where the human provides input or feedback at different stages of the conversation. For simplicity, the agent implementation below is illustrated as a single node, but in reality it may be part of a larger graph consisting of multiple nodes and include a conditional edge.\\n\\n## Conclusion\\n\\nWe are building LangGraph to be the best agent framework for human-in-the-loop interaction patterns. We think `interrupt` makes this easier than ever. We’ve updated all of our examples that use human-in-the-loop to use this new functionality. We hope to release some more end-to-end projects that demonstrate this in real-world action soon.\\n\\nSee our [YouTube walkthrough](https://youtu.be/6t7YJcEFUIY?ref=blog.langchain.com) for more information\\n\\nWe’re excited to see what you build!\\n\\n### Join our newsletter\\n\\nUpdates from the LangChain team and community\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph에 대한 유용한 자료를 아래에 정리했습니다. 이 자료들은 LangGraph의 기능과 사용법, 특히 \"Human-in-the-Loop\" 워크플로우에 대한 내용을 포함하고 있습니다.\n",
      "\n",
      "1. **LangGraph의 Human-in-the-Loop 개요**  \n",
      "   [LangGraph's human-in-the-loop - Overview](https://langchain-ai.github.io/langgraph/concepts/human_in_the_loop/)  \n",
      "   이 문서에서는 LangGraph의 Human-in-the-Loop 기능에 대해 설명하고 있습니다. 비동기적인 인간 검토 및 입력을 지원하며, 워크플로우의 어느 지점에서든 인간의 개입을 유연하게 통합할 수 있는 방법을 다룹니다.\n",
      "\n",
      "2. **Reddit 토론**  \n",
      "   [I am Struggling with LangGraph's Human-in-the-Loop ... - Reddit](https://www.reddit.com/r/LangGraph/comments/1ldiqtg/i_am_struggling_with_langgraphs_humanintheloop/)  \n",
      "   이 Reddit 스레드는 LangGraph의 Human-in-the-Loop 기능을 사용하면서 겪는 문제에 대한 사용자들의 경험과 조언을 공유합니다. 실제 사용 사례와 문제 해결 방법을 찾는 데 유용할 수 있습니다.\n",
      "\n",
      "3. **Human-in-the-Loop 에이전트 구축을 위한 새로운 방법**  \n",
      "   [Making it easier to build human-in-the-loop agents with interrupt](https://blog.langchain.com/making-it-easier-to-build-human-in-the-loop-agents-with-interrupt/)  \n",
      "   이 블로그 포스트에서는 LangGraph에서 Human-in-the-Loop 단계를 더 쉽게 포함할 수 있는 새로운 방법인 `interrupt` 기능에 대해 설명합니다. 이 기능을 통해 개발자는 에이전트의 실행을 일시 중지하고 인간의 입력을 받을 수 있습니다.\n",
      "\n",
      "이 자료들을 통해 LangGraph의 기능과 Human-in-the-Loop 워크플로우에 대한 이해를 높일 수 있을 것입니다. 추가적인 질문이 있으면 언제든지 물어보세요!\n"
     ]
    }
   ],
   "source": [
    "# 최종 결과 출력\n",
    "for msg in graph.get_state(config).values[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "** End of Documents **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-t0JhnSEV-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
